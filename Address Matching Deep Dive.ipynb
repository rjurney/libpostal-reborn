{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d0f6845-e53f-4e9b-be24-0e376269f522",
   "metadata": {},
   "source": [
    "# Address Matching Deep Dive\n",
    "\n",
    "This notebook experiments with different ways of comparing addresses in order to demonstrate the power of parsed address comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8feab8c8-a116-40f9-a882-5a932140af26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "from numbers import Number\n",
    "from typing import Callable, Dict, List, Literal, Sequence, Tuple, Union\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow.dataset as ds\n",
    "import pycountry\n",
    "import pytest\n",
    "import random\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import wandb\n",
    "from datasets import Dataset\n",
    "from fuzzywuzzy import fuzz\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.globals import set_llm_cache\n",
    "from langchain_core.caches import InMemoryCache\n",
    "from langchain_core.outputs import Generation\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core._api.deprecation import LangChainDeprecationWarning\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    ")\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from openai import APIConnectionError, RateLimitError\n",
    "from postal.parser import parse_address\n",
    "from scipy.spatial import distance\n",
    "from sklearn.metrics import accuracy_score, precision_recall_curve, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sentence_transformers import InputExample, SentenceTransformer, SentencesDataset, SentenceTransformerTrainer, losses\n",
    "from sentence_transformers.cross_encoder import CrossEncoder\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator, SimilarityFunction, BinaryClassificationEvaluator\n",
    "from sentence_transformers.model_card import SentenceTransformerModelCardData\n",
    "from sentence_transformers.training_args import BatchSamplers, SentenceTransformerTrainingArguments\n",
    "from tenacity import retry\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.autonotebook import tqdm\n",
    "from transformers import AutoTokenizer, AutoModel, EarlyStoppingCallback, TrainingArguments, Trainer\n",
    "from transformers.integrations import WandbCallback\n",
    "from transformers.optimization import get_linear_schedule_with_warmup\n",
    "\n",
    "from utils import augment_gold_labels, compute_metrics, gold_label_report, to_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e508b00c-0011-4845-a4d6-cd131ec5b6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(stream=sys.stderr, level=logging.ERROR)\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51aa3b1-fbec-4eb7-8ff9-b2022d78b56b",
   "metadata": {},
   "source": [
    "#### Squelch All `warnings`\n",
    "\n",
    "[Langchain](https://python.langchain.com/v0.2/docs/introduction/) produces many deprecation warnings as its API is constantly improving. Let's squash them all!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba0bb08e-fdc5-454a-a7be-879cf92be6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=LangChainDeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ba8945-a02c-4661-a865-c03ee6eecebe",
   "metadata": {},
   "source": [
    "#### Configure Weights & Biases\n",
    "\n",
    "`wandb` needs some environment variables to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9491984a-c9fb-40d5-8fb0-743b77d15c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_LOG_MODEL\"] = \"end\"\n",
    "os.environ[\"WANDB_WATCH\"] = \"all\"\n",
    "os.environ[\"WANDB_PROJECT\"] = \"libpostal-reborn\"\n",
    "os.environ[\"WANDB_DISABLED\"] = \"false\"\n",
    "os.environ[\"WANDB_IGNORE_GLOBS\"] = \".env\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e1d411-e2a5-4824-9309-ff50861a0e19",
   "metadata": {},
   "source": [
    "#### Configure Huggingface APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62d0d44b-c38a-48ca-a3b1-895b5b8c320b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HF_ENDPOINT\"] = \"https://huggingface.co/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7462e0-b3d1-4d76-bd7a-803cbd2f3446",
   "metadata": {},
   "source": [
    "#### Configure Huggingface APIs\n",
    "\n",
    "Squash any warnings..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5fcde550-79a6-4333-967e-c80d555de5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42913e46-e5db-4eff-9410-5a8449d4cbf6",
   "metadata": {},
   "source": [
    "#### Configure Pandas to Show More Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2d4cb15-b201-4f34-8917-d292dd2a1876",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad42226-1abc-4c29-b68d-659d330ba1f9",
   "metadata": {},
   "source": [
    "### Use CUDA or MPS if Avaialable\n",
    "\n",
    "CPU training and even inference with sentence transformers and deep learning models is quite slow. Since all machine learning in this library is based on [PyTorch](https://pytorch.org/get-started/locally/), we can assign all ML operations to a GPU in this one block of code. Otherwise we default to CPU without acceleration. The notebook is still workable in this mode, you just may need to grab a cup of tea or coffee while you wait for it to train the Sentence-BERT model below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1051aa37-26b7-496a-8182-f10cfa1f5f6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for CUDA or MPS availability and set the device\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    logger.debug(\"Using Apple GPU acceleration\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    logger.debug(\"Using NVIDIA CUDA GPU acceleration\")\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    logger.debug(\"Using CPU for ML\")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921a41eb-4e6b-4d64-a3b4-46013524e37c",
   "metadata": {},
   "source": [
    "### Use Weights & Biases for Logging Metrics\n",
    "\n",
    "Weights & Biases has a free account for individuals with public projects. Using it will produce charts during our training runs that anyone can view. You can create your own project for this notebook and login with that key to log your own training runs.\n",
    "\n",
    "You may need to run the following command from your shell before the next cell, otherwise you will have to paste your project key into the \n",
    "\n",
    "```bash\n",
    "wandb login\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d98cdf2f-fcb9-495e-9201-80f9e07d9070",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrjurney\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Login to wandb. Comment out if you already haven't via `wandb login` from a CLI\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85701b19-a5e1-42c4-9ace-8d88d96f893f",
   "metadata": {},
   "source": [
    "## Implementing a Structured Address Matcher\n",
    "\n",
    "Let's start our exercise by using the structured address data provided by [Libpostal](https://github.com/openvenues/libpostal) to parse them for matching. We write a function for each address part to deal with missing fields without duplicating a lot of logic.\n",
    "\n",
    "We start with something quite literal and basic. We'll improve it as we go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44031098-15b5-45ef-b1d0-8a51a9838bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_match_address(address1: str, address2: str) -> Literal[0, 1]:\n",
    "    \"\"\"parse_match_address implements address matching using the precise, parsed structure of addresses.\"\"\"\n",
    "    address1 = to_dict(parse_address(address1))\n",
    "    address2 = to_dict(parse_address(address2))\n",
    "\n",
    "    def match_road(address1: Dict, address2: Dict) -> Literal[0, 1]:\n",
    "        \"\"\"match_road - literal road matching, negative if either lacks a road\"\"\"\n",
    "        if (\"road\" in address1) and (\"road\" in address2):\n",
    "            if address1[\"road\"] == address2[\"road\"]:\n",
    "                logger.debug(\"road match\")\n",
    "                return 1\n",
    "            else:\n",
    "                logger.debug(\"road mismatch\")\n",
    "                return 0\n",
    "        logger.debug(\"road mismatch\")\n",
    "        return 0\n",
    "\n",
    "    def match_house_number(address1: Dict, address2: Dict) -> Literal[0, 1]:\n",
    "        \"\"\"match_house_number - literal house number matching, negative if either lacks a house_number\"\"\"\n",
    "        if (\"house_number\" in address1) and (\"house_number\" in address2):\n",
    "            if address1[\"house_number\"] == address2[\"house_number\"]:\n",
    "                logger.debug(\"house_number match\")\n",
    "                return 1\n",
    "            else:\n",
    "                logger.debug(\"house_number mismatch\")\n",
    "                return 0\n",
    "        logger.debug(\"house_number mistmatch\")\n",
    "        return 0\n",
    "\n",
    "    def match_unit(address1: Dict, address2: Dict) -> Literal[0, 1]:\n",
    "        \"\"\"match_unit - note a missing unit in both is a match\"\"\"\n",
    "        if \"unit\" in address1:\n",
    "            if \"unit\" in address2:\n",
    "                logger.debug(\"unit match\")\n",
    "                return 1 if (address1[\"unit\"] == address2[\"unit\"]) else 0\n",
    "            else:\n",
    "                logger.debug(\"unit mismatch\")\n",
    "                return 0\n",
    "        if \"unit\" in address2:\n",
    "            if \"unit\" in address1:\n",
    "                logger.debug(\"unit match\")\n",
    "                return 1 if (address1[\"unit\"] == address2[\"unit\"]) else 0\n",
    "            else:\n",
    "                logger.debug(\"unit mismatch\")\n",
    "                return 0\n",
    "        # Neither address has a unit, which is a default match\n",
    "        return 1\n",
    "\n",
    "    def match_postcode(address1: Dict, address2: Dict) -> Literal[0, 1]:\n",
    "        \"\"\"match_postcode - literal matching, negative if either lacks a postal code\"\"\"\n",
    "        if (\"postcode\" in address1) and (\"postcode\" in address2):\n",
    "            if address1[\"postcode\"] == address2[\"postcode\"]:\n",
    "                logger.debug(\"postcode match\")\n",
    "                return 1\n",
    "            else:\n",
    "                logger.debug(\"postcode mismatch\")\n",
    "                return 0\n",
    "        logger.debug(\"postcode mismatch\")\n",
    "        return 0\n",
    "\n",
    "    def match_country(address1: Dict, address2: Dict) -> Literal[0, 1]:\n",
    "        \"\"\"match_country - literal country matching - pass if both don't have one\"\"\"\n",
    "        if (\"country\" in address1) and (\"country\" in address2):\n",
    "            if address1[\"country\"] == address2[\"country\"]:\n",
    "                logger.debug(\"country match\")\n",
    "                return 1\n",
    "            else:\n",
    "                logger.debug(\"country mismatch\")\n",
    "                return 0\n",
    "        # One or none countries should match\n",
    "        logger.debug(\"country match\")\n",
    "        return 1\n",
    "\n",
    "    # Combine the above to get a complete address matcher\n",
    "    if (\n",
    "        match_road(address1, address2)\n",
    "        and match_house_number(address1, address2)\n",
    "        and match_unit(address1, address2)\n",
    "        and match_postcode(address1, address2)\n",
    "        and match_country(address1, address2)\n",
    "    ):\n",
    "        logger.debug(\"overall match\")\n",
    "        return 1\n",
    "    else:\n",
    "        logger.debug(\"overall mismatch\")\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9f67113-6f5f-45cb-9f4c-4ee0a4362de1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Yup down to house_number ...\n",
    "parse_match_address(\n",
    "    \"3413 Sean Way, Lawrenceville, GA 30044\",\n",
    "    \"3413 Sean Way Lawrenceville, GA, 30044\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "797ace98-a912-4c45-b178-6c6201f58bf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Yup down to unit ...\n",
    "parse_match_address(\n",
    "    \"120 Ralph McGill Blvd, Apt 101, Atlanta, GA 30308, USA\",\n",
    "    \"120 Ralph McGill Blvd, Apt 101, Atlanta GA 30308\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b949ebe-8889-498c-a601-904c2c5c1433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nope if only one uses an abbreviation ...\n",
    "parse_match_address(\n",
    "    \"120 Ralph McGill Blvd, Apt 333, Atlanta, GA 30308\",\n",
    "    \"120 Ralph McGill Boulevard, Apt 333, Atlanta, GA 30308\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "498ab13c-1457-4c4c-95ff-2f691f697738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nope if one character in the streetname is off ...\n",
    "parse_match_address(\n",
    "    \"120 Ralp McGill Blvd, Apt 333, Atlanta, GA 30308\",\n",
    "    \"120 Ralph McGill Blvd, Apt 333, Atlanta, GA 30308\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f1a4c5-0bcd-4c52-b5d7-7be7ad1932ea",
   "metadata": {},
   "source": [
    "### Literal is Too Precise!\n",
    "\n",
    "While it is useful to parse addresses and implement literal matching logic as we did above, as the third example indicates, an abbreviation or a single typo results in a mistmatch. We're going to write a more complex, approximate logical matcher below using string distance and text embeddings.\n",
    "\n",
    "Depending on your application you might relax this criteria to include corner cases such as missing postcodes. Before we get into that, let's create some training and evaluation data using hand-labeled data with an LLM data augmentation strategy to generate a lot of labeled records."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15895b85-1d0f-441c-9d20-0849b3db3b22",
   "metadata": {},
   "source": [
    "## Create a Dataset of Labeled Address Pairs for Training and Evaluation of Address Matchers\n",
    "\n",
    "Before improving our precise structured address matcher or trying other approaches, let's create a dataset that enables a more rigorous test of address matching methods. I created two sets of pairs of addresses. Each pair is a `Tuple`, including a description and pair of addresses it describes.\n",
    "\n",
    "1. `matched_address_pairs` - addresses that look different but that represent the same location. These are matched pairs.\n",
    "2. `mistmatched_address_pairs` - addresses that look similar but represent different locations. The are mismatched pairs.\n",
    "\n",
    "These are combined into a global `address_pairs` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f243685-3968-40b7-8a72-a5a693b9a849",
   "metadata": {},
   "outputs": [],
   "source": [
    "matched_address_pairs: List[Tuple[str, str, str]] = [\n",
    "    (\n",
    "        \"Different directional prefix formats for same address should match\",\n",
    "        \"2024 NW 5th Ave, Miami, FL 33127\",\n",
    "        \"2024 Northwest 5th Avenue, Miami, Florida 33127\",\n",
    "    ),\n",
    "    (\n",
    "        \"Abbreviated street type for same address should match\",\n",
    "        \"10200 NE 12th St, Bellevue, WA 98003\",\n",
    "        \"10200 NE 12th Street, Bellevue, WA 98003\",\n",
    "    ),\n",
    "    (\n",
    "        \"Common misspellings for same address should match\",\n",
    "        \"1600 Pennsylvna Ave NW, Washington, DC 20500\",\n",
    "        \"1600 Pennsylvania Avenue NW, Washington, DC 20500\",\n",
    "    ),\n",
    "    (\n",
    "        \"Different directional prefix formats for same address should match\",\n",
    "        \"550 S Hill St, Los Angeles, CA\",\n",
    "        \"550 South Hill Street, Los Angeles, California\",\n",
    "    ),\n",
    "    (\n",
    "        \"Incomplete address vs full address may match\",\n",
    "        \"1020 SW 2nd Ave, Portland\",\n",
    "        \"1020 SW 2nd Ave, Portland, OR 97204\",\n",
    "    ),\n",
    "    (\n",
    "        \"Numerical variations for same address should match\",\n",
    "        \"Third Ave, New York, NY\",\n",
    "        \"3rd Avenue, New York, New York\")\n",
    "    ,\n",
    "    (\n",
    "        \"Variant format of same address should match\",\n",
    "        \"350 Fifth Avenue, New York, NY 10118\",\n",
    "        \"Empire State Bldg, 350 5th Ave, NY, NY 10118\",\n",
    "    ),\n",
    "    (\n",
    "        \"Variant format of same address should match\",\n",
    "        \"Çırağan Caddesi No: 32, 34349 Beşiktaş, Istanbul, Turkey\",\n",
    "        \"Ciragan Palace Hotel, Ciragan Street 32, Besiktas, Istanbul, TR\",\n",
    "    ),\n",
    "    (\n",
    "        \"Different character sets for same address should match\",\n",
    "        \"北京市朝阳区建国路88号\",\n",
    "        \"Běijīng Shì Cháoyáng Qū Jiànguó Lù 88 Hào\",\n",
    "    ),\n",
    "    (\n",
    "        \"Variant formats of same address should match\",\n",
    "        \"上海市黄浦区南京东路318号\",\n",
    "        \"上海黄浦南京东路318号\"\n",
    "    ),\n",
    "    (\n",
    "        \"Variant formats of same address should match\",\n",
    "        \"Shànghǎi Shì Huángpǔ Qū Nánjīng Dōng Lù 318 Hào\",\n",
    "        \"Shànghǎi Huángpǔ Nánjīng Dōng Lù 318 Hào\",\n",
    "    ),\n",
    "    (\n",
    "        \"Formal and localized format of same address should match\",\n",
    "        \"B-14, Connaught Place, New Delhi, Delhi 110001, India\",\n",
    "        \"B-14, CP, ND, DL 110001\",\n",
    "    ),\n",
    "    (\n",
    "        \"Different character sets for same address should match\",\n",
    "        \"16, MG Road, Bangalore, Karnataka 560001, India\",\n",
    "        \"16, एमजी रोड, बैंगलोर, कर्नाटक 560001\",\n",
    "    ),\n",
    "    (\n",
    "        \"Missing state but has postal code and country for same address should match\",\n",
    "        \"Pariser Platz 2, 10117 Berlin, Germany\",\n",
    "        \"Pariser Platz 2, 10117 Berlin, Berlin, Germany\",\n",
    "    ),\n",
    "    (\n",
    "        \"Missing state but has postal code and country for same address should match\",\n",
    "        \"Marienplatz 1, 80331 Munich, Germany\",\n",
    "        \"Marienplatz 1, 80331 Munich, Bavaria, Germany\"\n",
    "    ),\n",
    "    (\n",
    "        \"Abbreviated vs. full street names for same address should match\",\n",
    "        \"123 Main St, Springfield, IL\",\n",
    "        \"123 Main Street, Springfield, IL\",\n",
    "    ),\n",
    "    (\n",
    "        \"Different languages for same address should match\",\n",
    "        \"北京市东城区东长安街16号\",\n",
    "        \"16 Dongchang'an St, Dongcheng, Beijing, China\",\n",
    "    ),\n",
    "    (\n",
    "        \"Same address with and without country should match\",\n",
    "        \"1600 Amphitheatre Parkway, Mountain View, CA 94043, USA\",\n",
    "        \"1600 Amphitheatre Parkway, Mountain View, CA 94043\",\n",
    "    ),\n",
    "    (\n",
    "        \"Same address with and without country should match\",\n",
    "        \"3413 Sean Way, Lawrenceville, GA 30044, U.S.A.\",\n",
    "        \"3413 Sean Way, Lawrenceville, Georgia, 30044\",\n",
    "    ),\n",
    "    (\n",
    "        \"Different levels of detail for the same address may match\",\n",
    "        \"221B Baker Street, London, NW1 6XE, UK\",\n",
    "        \"221B Baker St, Marylebone, London NW1 6XE\",\n",
    "    ),\n",
    "    (\n",
    "        \"Same address with and without district / neighborhood names should match\",\n",
    "        \"1600 Amphitheatre Parkway, Mountain View, CA 94043, USA\",\n",
    "        \"1600 Amphitheatre Parkway, Shoreline, Mountain View, CA 94043, USA\",\n",
    "    ),\n",
    "    (\n",
    "        \"Including and excluding building names for same address should match\",\n",
    "        \"The Empire State Building, 350 5th Ave, New York, NY 10118\",\n",
    "        \"350 5th Ave, New York, NY 10118\",\n",
    "    ),\n",
    "    (\n",
    "        \"Floor bumbers included or excluded for same address should match\",\n",
    "        \"350 5th Ave, 86th Floor, New York, NY 10118\",\n",
    "        \"350 5th Ave, New York, NY 10118\",\n",
    "    ),\n",
    "    (\n",
    "        \"Same address incorporates business name or not should match\",\n",
    "        \"Google, 1600 Amphitheatre Parkway, Mountain View, CA 94043\",\n",
    "        \"1600 Amphitheatre Parkway, Mountain View, CA 94043\",\n",
    "    ),\n",
    "    (\n",
    "        \"Intersection vs addresss for same location should match\",\n",
    "        \"1600 Amphitheatre Parkway at Charleston Road, Mountain View, CA 94043\",\n",
    "        \"1600 Amphitheatre Parkway, Mountain View, CA 94043\",\n",
    "    ),\n",
    "    (\n",
    "        \"Local vs. international formatting for same address should match\",\n",
    "        \"221B Baker Street, London, NW1 6XE, UK\",\n",
    "        \"221B Baker Street, Marylebone, London, NW1 6XE, United Kingdom\",\n",
    "    ),\n",
    "    (\n",
    "        \"Addition of parenthetical details for same address should match\",\n",
    "        \"Building 4 (East Wing), 123 Tech Park, Silicon Valley, CA 94301\",\n",
    "        \"Building 4, 123 Tech Park, Silicon Valley, CA 94301\",\n",
    "    ),\n",
    "    (\n",
    "        \"Synonyms for street types for same address should match\",\n",
    "        \"456 Elm St, Springfield, IL 62704\",\n",
    "        \"456 Elm Street, Springfield, IL 62704\",\n",
    "    ),\n",
    "    (\n",
    "        \"Different language versions of same address should match\",\n",
    "        \"16 Rue de la Paix, 75002 Paris, France\",\n",
    "        \"16 Peace Street, 75002 Paris, France\",\n",
    "    ),\n",
    "    (\n",
    "        \"Different terms for unit number for same address should match\",\n",
    "        \"500 Fifth Avenue, Apt. 20, New York, NY 10110\",\n",
    "        \"500 Fifth Avenue, Suite 20, New York, NY 10110\",\n",
    "    ),\n",
    "    (\n",
    "        \"Including a business name or not, in same address should match\",\n",
    "        \"123 Main St, Springfield, IL\",\n",
    "        \"Company ABC, 123 Main St, Springfield, IL\",\n",
    "    ),\n",
    "    (\n",
    "        \"Typographical errors in street name of same address should match\",\n",
    "        \"1600 Amphitheatre Parkway, Mountain View, CA\",\n",
    "        \"1600 Amptheatre Parkway, Mountain View, CA\",\n",
    "    ),\n",
    "    (\n",
    "        \"Typographical errors in same address with country should match\",\n",
    "        \"Calle Mayor, 10, 28013 Madrid, España\",\n",
    "        \"Calle Mayor, 10, 28013 Madird, España\",\n",
    "    ),\n",
    "    (\n",
    "        \"Typographical errors in city of same address should match\",\n",
    "        \"16 Rue de la Paix, 75002 Paris, France\",\n",
    "        \"16 Rue de la Paix, 75002 Pariss, France\",\n",
    "    ),\n",
    "    (\n",
    "        \"Typographical errors in city of same address should match\",\n",
    "        \"Alexanderplatz 1, 10178 Berlin, Deutschland\",\n",
    "        \"Alexanderplatz 1, 10178 Berin, Deutschland\",\n",
    "    ),\n",
    "    (\n",
    "        \"Common typographical errors in same address should match\",\n",
    "        \"北京市东城区东长安街1号, 中国\",\n",
    "        \"北京市东城区东长安街1号, 中囯\",\n",
    "    ),\n",
    "    (\n",
    "        \"Numeric or written street number for same address should match\",\n",
    "        \"123 4th St, Springfield, IL\",\n",
    "        \"123 Fourth St, Springfield, IL\",\n",
    "    ),\n",
    "    (\n",
    "        \"Punctuation or not in abbreviations for same address should match\",\n",
    "        \"10350 NE 12th St, Bellevue, WA 98003\",\n",
    "        \"10350 N.E. 12th St., Bellevue, WA 98003\",\n",
    "    ),\n",
    "    (\n",
    "        \"Normal vs formal country names for same address should match\",\n",
    "        \"456 Coastal Lane, Benaulim, Goa, 403716, India\",\n",
    "        \"456 Coastal Lane, Benaulim, Goa, 403716, Republic of India\",\n",
    "    ),\n",
    "    (\n",
    "        \"Normal vs abbreviated country name for same address should match\",\n",
    "        \"456 Coastal Lane, Benaulim, Goa, 403716, India\",\n",
    "        \"456 Coastal Lane, Benaulim, Goa, 403716, IN\",\n",
    "    ),\n",
    "    (\n",
    "        \"Missing country in one record can match\",\n",
    "        \"3413 Sean Way, Lawrenceville, GA 30044\",\n",
    "        \"3413 Sean Way, Lawrenceville, GA 30044, USA\",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ee9046b-077d-4187-94fa-6db47b0eb154",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mismatched_address_pairs: List[Tuple[str, str, str]] = [\n",
    "    (\n",
    "        \"Different street numbers means different address\",\n",
    "        \"101 Oak Lane, Marietta, GA 30008\",\n",
    "        \"102 Oak Lane, Marietta, GA 30008\",\n",
    "    ),\n",
    "    (\n",
    "        \"Different street names means different address\",\n",
    "        \"101 Market Square, Seattle, WA 98039\",\n",
    "        \"101 Davis Place, Seattle, WA 98039\",\n",
    "    ),\n",
    "    (\n",
    "        \"Different street name endings means different address\",\n",
    "        \"100 Oak Lane, Atlanta, GA 30306\",\n",
    "        \"100 Oak Place, Atlanta, GA 30306\",\n",
    "    ),\n",
    "    (\n",
    "        \"Different cities means different address\",\n",
    "        \"2754 Ralph McGill Blvd, Atlanta, GA\",\n",
    "        \"2754 Ralph McGill Blvd, Macon, GA\",\n",
    "    ),\n",
    "    (\n",
    "        \"Different states means different address\",\n",
    "        \"361 Oakhurst Ave., Rome, GA 30149\",\n",
    "        \"361 Oakhurst Ave., Rome, NY, 13308\",\n",
    "    ),\n",
    "    (\n",
    "        \"Different postal codes means different address\",\n",
    "        \"76 Providence St, Providence, RI, 02860\",\n",
    "        \"76 Providence St, Providence, RI, 02861\",\n",
    "    ),\n",
    "    (\n",
    "        \"Similar cities in different states, postal codes or countries means different address\",\n",
    "        \"100 Main Street, Springfield, IL 62701\",\n",
    "        \"100 Main Street, Springfield, MA 01103\",\n",
    "    ),\n",
    "    (\n",
    "        \"Similar street names with different directions means different address\",\n",
    "        \"200 1st Ave, Seattle, WA 98109\",\n",
    "        \"200 1st Ave N, Seattle, WA 98109\",\n",
    "    ),\n",
    "    (\n",
    "        \"Adjacent or nearby building numbers means different address\",\n",
    "        \"4800 Oak Street, Kansas City, MO 64112\",\n",
    "        \"4800 W Oak Street, Kansas City, MO 64112\",\n",
    "    ),\n",
    "    (\n",
    "        \"Similar international locations in different countries means different address\",\n",
    "        \"33 Queen Street, Auckland 1010, New Zealand\",\n",
    "        \"33 Queen Street, Brisbane QLD 4000, Australia\",\n",
    "    ),\n",
    "    (\n",
    "        \"Close numerical variants are different addresses\",\n",
    "        \"75 West 50th Street, New York, NY 10112\",\n",
    "        \"50 West 75th Street, New York, NY 10023\",\n",
    "    ),\n",
    "    (\n",
    "        \"Similar road names can be different addresses\",\n",
    "        \"北京市朝阳区朝阳门外大街6号\",\n",
    "        \"北京市朝阳区朝阳门内大街6号\"\n",
    "    ),\n",
    "    (\n",
    "        \"Similar road names can be different addresses\",\n",
    "        \"Běijīng Shì Cháoyáng Qū Cháoyángmén Wài Dàjiē 6 Hào\",\n",
    "        \"Běijīng Shì Cháoyáng Qū Cháoyángmén Nèi Dàjiē 6 Hào\",\n",
    "    ),\n",
    "    (\n",
    "        \"Similar building names can be different addresses\",\n",
    "        \"上海市徐汇区中山西路200号\",\n",
    "        \"上海市长宁区中山西路200号\",\n",
    "    ),\n",
    "    (\n",
    "        \"Similar but different building names means different address\",\n",
    "        \"Shànghǎi Shì Xúhuì Qū Zhōngshān Xī Lù 200 Hào\",\n",
    "        \"Shànghǎi Shì Chángníng Qū Zhōngshān Xī Lù 200 Hào\",\n",
    "    ),\n",
    "    (\n",
    "        \"Different unit numbers means different address\",\n",
    "        \"27 Peachtree St, Apt 101, Atlanta, GA 30307\",\n",
    "        \"27 Peachtree St, Apt 1213, Atlanta, GA 30307\",\n",
    "    ),\n",
    "    (\n",
    "        \"Missing unit number in match means different address\",\n",
    "        \"27 Peachtree St., Apt 101, Atlanta, GA 30308\",\n",
    "        \"27 Peachtree St., Atlanta, GA 30308\",\n",
    "    ),\n",
    "    (\n",
    "        \"Missing street suffix can mean different address\",\n",
    "        \"1020 SW 2nd, Portland, OR 97204\",\n",
    "        \"1020 SW 2nd Ave, Portland, OR 97204\",\n",
    "    ),\n",
    "    (\n",
    "        \"Missing postal code can mean different address\",\n",
    "        \"Bouillon Racine: 3, rue Racine, 75006 Paris\",\n",
    "        \"Bouillon Racine: 3, rue Racine, Paris\",\n",
    "    ),\n",
    "    (\n",
    "        \"Different postal codes means different address\",\n",
    "        \"1 Infinite Loop, Cupertino, CA 95014\",\n",
    "        \"1 Infinite Loop, Cupertino, CA 95015\",\n",
    "    ),\n",
    "    (\n",
    "        \"Different units in a building means different address\",\n",
    "        \"500 Fifth Avenue, Apt. 2A, New York, NY 10110\",\n",
    "        \"500 Fifth Avenue, Apt. 2-B, New York, NY 10110\",\n",
    "    ),\n",
    "    (\n",
    "        \"Street type variations means different address\",\n",
    "        \"456 Elm St, Springfield, IL 62704\",\n",
    "        \"456 Elm Rd, Springfield, IL 62704\",\n",
    "    ),\n",
    "    (\n",
    "        \"Different street suffixes means different address\",\n",
    "        \"123 Main St, Springfield, IL\",\n",
    "        \"123 Main Ave, Springfield, IL\",\n",
    "    ),\n",
    "    (\n",
    "        \"Different states means different address\",\n",
    "        \"Alexanderstraße 7, 10178 Berlin, Germany\",\n",
    "        \"Alexanderstraße 7, 20099 Hamburg, Germany\",\n",
    "    ),\n",
    "    (\n",
    "        \"Different states means different address\",\n",
    "        \"200 George St, Sydney, NSW 2000, Australia\",\n",
    "        \"200 George St, Melbourne, VIC 3000, Australia\",\n",
    "    ),\n",
    "    (\n",
    "        \"Different states means different address\",\n",
    "        \"100 King St W, Toronto, ON M5X 1A9, Canada\",\n",
    "        \"100 King St W, Vancouver, BC V6B 1H8, Canada\",\n",
    "    ),\n",
    "    (\n",
    "        \"Different street numbers means different address\",\n",
    "        \"Unter den Linden 4, 10117 Berlin, Germany\",\n",
    "        \"Unter den Linden 5, 10117 Berlin, Germany\",\n",
    "    ),\n",
    "    (\n",
    "        \"Different street numbers means different address\",\n",
    "        \"Avenida Paulista 1000, Bela Vista, São Paulo - SP, 01310-100\",\n",
    "        \"Avenida Paulista 200, Bela Vista, São Paulo - SP, 01310-100\",\n",
    "    ),\n",
    "    (\n",
    "        \"Different countries means different address\",\n",
    "        \"123 Main Street, Vancouver, BC V5K 0A1, Canada\",\n",
    "        \"123 Main Street, Vancouver, WA 98660, USA\",\n",
    "    ),\n",
    "    # Some widely diverging examples\n",
    "    (\n",
    "        \"Completely different addresses that don't match\",\n",
    "        \"110 Sejong-daero, Jung-gu, Seoul, South Korea\",\n",
    "        \"Avenue Colonel Mondjiba 372, Kinshasa, Gombe, Democratic Republic of the Congo\",\n",
    "    ),\n",
    "    (\n",
    "        \"Different addresses in the same country that don't match\",\n",
    "        \"1234 Manor Plaza, Pacifica, CA 94044\",\n",
    "        \"1234 Bly Manor, Pacific Heights, WA 98003\",\n",
    "    ),\n",
    "    (\n",
    "        \"Different addresses in the same country that don't match\",\n",
    "        \"350 5th Ave, New York, NY 10118\",\n",
    "        \"1350 El Prado, San Diego, CA 92101\",\n",
    "    ),\n",
    "    (\n",
    "        \"Completely different addresses that don't match\",\n",
    "        \"Rue de la Loi 175, 1040 Brussels\",\n",
    "        \"1 Macquarie Street, Sydney, NSW 2000\",\n",
    "    ),\n",
    "    (\n",
    "        \"Different street names means different address\",\n",
    "        \"market Square\",\n",
    "        \"davis Place\",\n",
    "    ),\n",
    "    (\n",
    "        \"Similar but different street numbers\",\n",
    "        \"10101 Tensor St.\",\n",
    "        \"11010 Tensor St.\",\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ba62d6b-f8bf-41ba-a8e5-fdb0bab3e893",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched label address pairs: 41\n",
      "Mismatched label address pairs: 35\n",
      "Total label address pairs: 76\n"
     ]
    }
   ],
   "source": [
    "address_pairs = matched_address_pairs + mismatched_address_pairs\n",
    "\n",
    "print(f\"Matched label address pairs: {len(matched_address_pairs):,}\")\n",
    "print(f\"Mismatched label address pairs: {len(mismatched_address_pairs):,}\")\n",
    "print(f\"Total label address pairs: {len(address_pairs):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b094a4-c051-401d-aafa-e6350aa740e3",
   "metadata": {},
   "source": [
    "### Create a `pandas.DataFrame` of Hand Labeled Records\n",
    "\n",
    "We create separate `pd.DataFrames`, `match_df` and `mismatch_df`, to set their labels as 1 or 0. Then we combine them into `combined_df`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cd14d8ff-fe5c-431d-8baa-78e96224d569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Address1</th>\n",
       "      <th>Address2</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Different directional prefix formats for same ...</td>\n",
       "      <td>2024 NW 5th Ave, Miami, FL 33127</td>\n",
       "      <td>2024 Northwest 5th Avenue, Miami, Florida 33127</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abbreviated street type for same address shoul...</td>\n",
       "      <td>10200 NE 12th St, Bellevue, WA 98003</td>\n",
       "      <td>10200 NE 12th Street, Bellevue, WA 98003</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Common misspellings for same address should match</td>\n",
       "      <td>1600 Pennsylvna Ave NW, Washington, DC 20500</td>\n",
       "      <td>1600 Pennsylvania Avenue NW, Washington, DC 20500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Different directional prefix formats for same ...</td>\n",
       "      <td>550 S Hill St, Los Angeles, CA</td>\n",
       "      <td>550 South Hill Street, Los Angeles, California</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Incomplete address vs full address may match</td>\n",
       "      <td>1020 SW 2nd Ave, Portland</td>\n",
       "      <td>1020 SW 2nd Ave, Portland, OR 97204</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Numerical variations for same address should m...</td>\n",
       "      <td>Third Ave, New York, NY</td>\n",
       "      <td>3rd Avenue, New York, New York</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Variant format of same address should match</td>\n",
       "      <td>350 Fifth Avenue, New York, NY 10118</td>\n",
       "      <td>Empire State Bldg, 350 5th Ave, NY, NY 10118</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Variant format of same address should match</td>\n",
       "      <td>Çırağan Caddesi No: 32, 34349 Beşiktaş, Istanb...</td>\n",
       "      <td>Ciragan Palace Hotel, Ciragan Street 32, Besik...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Different character sets for same address shou...</td>\n",
       "      <td>北京市朝阳区建国路88号</td>\n",
       "      <td>Běijīng Shì Cháoyáng Qū Jiànguó Lù 88 Hào</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Variant formats of same address should match</td>\n",
       "      <td>上海市黄浦区南京东路318号</td>\n",
       "      <td>上海黄浦南京东路318号</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Variant formats of same address should match</td>\n",
       "      <td>Shànghǎi Shì Huángpǔ Qū Nánjīng Dōng Lù 318 Hào</td>\n",
       "      <td>Shànghǎi Huángpǔ Nánjīng Dōng Lù 318 Hào</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Formal and localized format of same address sh...</td>\n",
       "      <td>B-14, Connaught Place, New Delhi, Delhi 110001...</td>\n",
       "      <td>B-14, CP, ND, DL 110001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Different character sets for same address shou...</td>\n",
       "      <td>16, MG Road, Bangalore, Karnataka 560001, India</td>\n",
       "      <td>16, एमजी रोड, बैंगलोर, कर्नाटक 560001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Missing state but has postal code and country ...</td>\n",
       "      <td>Pariser Platz 2, 10117 Berlin, Germany</td>\n",
       "      <td>Pariser Platz 2, 10117 Berlin, Berlin, Germany</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Missing state but has postal code and country ...</td>\n",
       "      <td>Marienplatz 1, 80331 Munich, Germany</td>\n",
       "      <td>Marienplatz 1, 80331 Munich, Bavaria, Germany</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Abbreviated vs. full street names for same add...</td>\n",
       "      <td>123 Main St, Springfield, IL</td>\n",
       "      <td>123 Main Street, Springfield, IL</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Different languages for same address should match</td>\n",
       "      <td>北京市东城区东长安街16号</td>\n",
       "      <td>16 Dongchang'an St, Dongcheng, Beijing, China</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Same address with and without country should m...</td>\n",
       "      <td>1600 Amphitheatre Parkway, Mountain View, CA 9...</td>\n",
       "      <td>1600 Amphitheatre Parkway, Mountain View, CA 9...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Same address with and without country should m...</td>\n",
       "      <td>3413 Sean Way, Lawrenceville, GA 30044, U.S.A.</td>\n",
       "      <td>3413 Sean Way, Lawrenceville, Georgia, 30044</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Different levels of detail for the same addres...</td>\n",
       "      <td>221B Baker Street, London, NW1 6XE, UK</td>\n",
       "      <td>221B Baker St, Marylebone, London NW1 6XE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Description  \\\n",
       "0   Different directional prefix formats for same ...   \n",
       "1   Abbreviated street type for same address shoul...   \n",
       "2   Common misspellings for same address should match   \n",
       "3   Different directional prefix formats for same ...   \n",
       "4        Incomplete address vs full address may match   \n",
       "5   Numerical variations for same address should m...   \n",
       "6         Variant format of same address should match   \n",
       "7         Variant format of same address should match   \n",
       "8   Different character sets for same address shou...   \n",
       "9        Variant formats of same address should match   \n",
       "10       Variant formats of same address should match   \n",
       "11  Formal and localized format of same address sh...   \n",
       "12  Different character sets for same address shou...   \n",
       "13  Missing state but has postal code and country ...   \n",
       "14  Missing state but has postal code and country ...   \n",
       "15  Abbreviated vs. full street names for same add...   \n",
       "16  Different languages for same address should match   \n",
       "17  Same address with and without country should m...   \n",
       "18  Same address with and without country should m...   \n",
       "19  Different levels of detail for the same addres...   \n",
       "\n",
       "                                             Address1  \\\n",
       "0                    2024 NW 5th Ave, Miami, FL 33127   \n",
       "1                10200 NE 12th St, Bellevue, WA 98003   \n",
       "2        1600 Pennsylvna Ave NW, Washington, DC 20500   \n",
       "3                      550 S Hill St, Los Angeles, CA   \n",
       "4                           1020 SW 2nd Ave, Portland   \n",
       "5                             Third Ave, New York, NY   \n",
       "6                350 Fifth Avenue, New York, NY 10118   \n",
       "7   Çırağan Caddesi No: 32, 34349 Beşiktaş, Istanb...   \n",
       "8                                        北京市朝阳区建国路88号   \n",
       "9                                      上海市黄浦区南京东路318号   \n",
       "10    Shànghǎi Shì Huángpǔ Qū Nánjīng Dōng Lù 318 Hào   \n",
       "11  B-14, Connaught Place, New Delhi, Delhi 110001...   \n",
       "12    16, MG Road, Bangalore, Karnataka 560001, India   \n",
       "13             Pariser Platz 2, 10117 Berlin, Germany   \n",
       "14               Marienplatz 1, 80331 Munich, Germany   \n",
       "15                       123 Main St, Springfield, IL   \n",
       "16                                      北京市东城区东长安街16号   \n",
       "17  1600 Amphitheatre Parkway, Mountain View, CA 9...   \n",
       "18     3413 Sean Way, Lawrenceville, GA 30044, U.S.A.   \n",
       "19             221B Baker Street, London, NW1 6XE, UK   \n",
       "\n",
       "                                             Address2  Label  \n",
       "0     2024 Northwest 5th Avenue, Miami, Florida 33127      1  \n",
       "1            10200 NE 12th Street, Bellevue, WA 98003      1  \n",
       "2   1600 Pennsylvania Avenue NW, Washington, DC 20500      1  \n",
       "3      550 South Hill Street, Los Angeles, California      1  \n",
       "4                 1020 SW 2nd Ave, Portland, OR 97204      1  \n",
       "5                      3rd Avenue, New York, New York      1  \n",
       "6        Empire State Bldg, 350 5th Ave, NY, NY 10118      1  \n",
       "7   Ciragan Palace Hotel, Ciragan Street 32, Besik...      1  \n",
       "8           Běijīng Shì Cháoyáng Qū Jiànguó Lù 88 Hào      1  \n",
       "9                                        上海黄浦南京东路318号      1  \n",
       "10           Shànghǎi Huángpǔ Nánjīng Dōng Lù 318 Hào      1  \n",
       "11                            B-14, CP, ND, DL 110001      1  \n",
       "12              16, एमजी रोड, बैंगलोर, कर्नाटक 560001      1  \n",
       "13     Pariser Platz 2, 10117 Berlin, Berlin, Germany      1  \n",
       "14      Marienplatz 1, 80331 Munich, Bavaria, Germany      1  \n",
       "15                   123 Main Street, Springfield, IL      1  \n",
       "16      16 Dongchang'an St, Dongcheng, Beijing, China      1  \n",
       "17  1600 Amphitheatre Parkway, Mountain View, CA 9...      1  \n",
       "18       3413 Sean Way, Lawrenceville, Georgia, 30044      1  \n",
       "19          221B Baker St, Marylebone, London NW1 6XE      1  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_df = pd.DataFrame(matched_address_pairs, columns=[\"Description\", \"Address1\", \"Address2\"])\n",
    "match_df[\"Label\"] = 1\n",
    "\n",
    "match_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a06e93c0-5888-4ee1-b1f6-10b210d31333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Address1</th>\n",
       "      <th>Address2</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Different street numbers means different address</td>\n",
       "      <td>101 Oak Lane, Marietta, GA 30008</td>\n",
       "      <td>102 Oak Lane, Marietta, GA 30008</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Different street names means different address</td>\n",
       "      <td>101 Market Square, Seattle, WA 98039</td>\n",
       "      <td>101 Davis Place, Seattle, WA 98039</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Different street name endings means different ...</td>\n",
       "      <td>100 Oak Lane, Atlanta, GA 30306</td>\n",
       "      <td>100 Oak Place, Atlanta, GA 30306</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Different cities means different address</td>\n",
       "      <td>2754 Ralph McGill Blvd, Atlanta, GA</td>\n",
       "      <td>2754 Ralph McGill Blvd, Macon, GA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Different states means different address</td>\n",
       "      <td>361 Oakhurst Ave., Rome, GA 30149</td>\n",
       "      <td>361 Oakhurst Ave., Rome, NY, 13308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Different postal codes means different address</td>\n",
       "      <td>76 Providence St, Providence, RI, 02860</td>\n",
       "      <td>76 Providence St, Providence, RI, 02861</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Similar cities in different states, postal cod...</td>\n",
       "      <td>100 Main Street, Springfield, IL 62701</td>\n",
       "      <td>100 Main Street, Springfield, MA 01103</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Similar street names with different directions...</td>\n",
       "      <td>200 1st Ave, Seattle, WA 98109</td>\n",
       "      <td>200 1st Ave N, Seattle, WA 98109</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Adjacent or nearby building numbers means diff...</td>\n",
       "      <td>4800 Oak Street, Kansas City, MO 64112</td>\n",
       "      <td>4800 W Oak Street, Kansas City, MO 64112</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Similar international locations in different c...</td>\n",
       "      <td>33 Queen Street, Auckland 1010, New Zealand</td>\n",
       "      <td>33 Queen Street, Brisbane QLD 4000, Australia</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Close numerical variants are different addresses</td>\n",
       "      <td>75 West 50th Street, New York, NY 10112</td>\n",
       "      <td>50 West 75th Street, New York, NY 10023</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Similar road names can be different addresses</td>\n",
       "      <td>北京市朝阳区朝阳门外大街6号</td>\n",
       "      <td>北京市朝阳区朝阳门内大街6号</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Similar road names can be different addresses</td>\n",
       "      <td>Běijīng Shì Cháoyáng Qū Cháoyángmén Wài Dàjiē ...</td>\n",
       "      <td>Běijīng Shì Cháoyáng Qū Cháoyángmén Nèi Dàjiē ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Similar building names can be different addresses</td>\n",
       "      <td>上海市徐汇区中山西路200号</td>\n",
       "      <td>上海市长宁区中山西路200号</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Similar but different building names means dif...</td>\n",
       "      <td>Shànghǎi Shì Xúhuì Qū Zhōngshān Xī Lù 200 Hào</td>\n",
       "      <td>Shànghǎi Shì Chángníng Qū Zhōngshān Xī Lù 200 Hào</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Different unit numbers means different address</td>\n",
       "      <td>27 Peachtree St, Apt 101, Atlanta, GA 30307</td>\n",
       "      <td>27 Peachtree St, Apt 1213, Atlanta, GA 30307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Missing unit number in match means different a...</td>\n",
       "      <td>27 Peachtree St., Apt 101, Atlanta, GA 30308</td>\n",
       "      <td>27 Peachtree St., Atlanta, GA 30308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Missing street suffix can mean different address</td>\n",
       "      <td>1020 SW 2nd, Portland, OR 97204</td>\n",
       "      <td>1020 SW 2nd Ave, Portland, OR 97204</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Missing postal code can mean different address</td>\n",
       "      <td>Bouillon Racine: 3, rue Racine, 75006 Paris</td>\n",
       "      <td>Bouillon Racine: 3, rue Racine, Paris</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Different postal codes means different address</td>\n",
       "      <td>1 Infinite Loop, Cupertino, CA 95014</td>\n",
       "      <td>1 Infinite Loop, Cupertino, CA 95015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Description  \\\n",
       "0    Different street numbers means different address   \n",
       "1      Different street names means different address   \n",
       "2   Different street name endings means different ...   \n",
       "3            Different cities means different address   \n",
       "4            Different states means different address   \n",
       "5      Different postal codes means different address   \n",
       "6   Similar cities in different states, postal cod...   \n",
       "7   Similar street names with different directions...   \n",
       "8   Adjacent or nearby building numbers means diff...   \n",
       "9   Similar international locations in different c...   \n",
       "10   Close numerical variants are different addresses   \n",
       "11      Similar road names can be different addresses   \n",
       "12      Similar road names can be different addresses   \n",
       "13  Similar building names can be different addresses   \n",
       "14  Similar but different building names means dif...   \n",
       "15     Different unit numbers means different address   \n",
       "16  Missing unit number in match means different a...   \n",
       "17   Missing street suffix can mean different address   \n",
       "18     Missing postal code can mean different address   \n",
       "19     Different postal codes means different address   \n",
       "\n",
       "                                             Address1  \\\n",
       "0                    101 Oak Lane, Marietta, GA 30008   \n",
       "1                101 Market Square, Seattle, WA 98039   \n",
       "2                     100 Oak Lane, Atlanta, GA 30306   \n",
       "3                 2754 Ralph McGill Blvd, Atlanta, GA   \n",
       "4                   361 Oakhurst Ave., Rome, GA 30149   \n",
       "5             76 Providence St, Providence, RI, 02860   \n",
       "6              100 Main Street, Springfield, IL 62701   \n",
       "7                      200 1st Ave, Seattle, WA 98109   \n",
       "8              4800 Oak Street, Kansas City, MO 64112   \n",
       "9         33 Queen Street, Auckland 1010, New Zealand   \n",
       "10            75 West 50th Street, New York, NY 10112   \n",
       "11                                     北京市朝阳区朝阳门外大街6号   \n",
       "12  Běijīng Shì Cháoyáng Qū Cháoyángmén Wài Dàjiē ...   \n",
       "13                                     上海市徐汇区中山西路200号   \n",
       "14      Shànghǎi Shì Xúhuì Qū Zhōngshān Xī Lù 200 Hào   \n",
       "15        27 Peachtree St, Apt 101, Atlanta, GA 30307   \n",
       "16       27 Peachtree St., Apt 101, Atlanta, GA 30308   \n",
       "17                    1020 SW 2nd, Portland, OR 97204   \n",
       "18        Bouillon Racine: 3, rue Racine, 75006 Paris   \n",
       "19               1 Infinite Loop, Cupertino, CA 95014   \n",
       "\n",
       "                                             Address2  Label  \n",
       "0                    102 Oak Lane, Marietta, GA 30008      0  \n",
       "1                  101 Davis Place, Seattle, WA 98039      0  \n",
       "2                    100 Oak Place, Atlanta, GA 30306      0  \n",
       "3                   2754 Ralph McGill Blvd, Macon, GA      0  \n",
       "4                  361 Oakhurst Ave., Rome, NY, 13308      0  \n",
       "5             76 Providence St, Providence, RI, 02861      0  \n",
       "6              100 Main Street, Springfield, MA 01103      0  \n",
       "7                    200 1st Ave N, Seattle, WA 98109      0  \n",
       "8            4800 W Oak Street, Kansas City, MO 64112      0  \n",
       "9       33 Queen Street, Brisbane QLD 4000, Australia      0  \n",
       "10            50 West 75th Street, New York, NY 10023      0  \n",
       "11                                     北京市朝阳区朝阳门内大街6号      0  \n",
       "12  Běijīng Shì Cháoyáng Qū Cháoyángmén Nèi Dàjiē ...      0  \n",
       "13                                     上海市长宁区中山西路200号      0  \n",
       "14  Shànghǎi Shì Chángníng Qū Zhōngshān Xī Lù 200 Hào      0  \n",
       "15       27 Peachtree St, Apt 1213, Atlanta, GA 30307      0  \n",
       "16                27 Peachtree St., Atlanta, GA 30308      0  \n",
       "17                1020 SW 2nd Ave, Portland, OR 97204      0  \n",
       "18              Bouillon Racine: 3, rue Racine, Paris      0  \n",
       "19               1 Infinite Loop, Cupertino, CA 95015      0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mismatch_df = pd.DataFrame(mismatched_address_pairs, columns=[\"Description\", \"Address1\", \"Address2\"])\n",
    "mismatch_df[\"Label\"] = 0\n",
    "\n",
    "mismatch_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c54db2-afb6-47cd-ae5b-f2f3b879bb13",
   "metadata": {},
   "source": [
    "### Establish a Gold Labeled Dataset\n",
    "\n",
    "These are records we have hand-labeled and will use to score our matching models and algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9a978a4c-3aea-4870-a619-6a4e5a030523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Address1</th>\n",
       "      <th>Address2</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Different directional prefix formats for same ...</td>\n",
       "      <td>2024 NW 5th Ave, Miami, FL 33127</td>\n",
       "      <td>2024 Northwest 5th Avenue, Miami, Florida 33127</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abbreviated street type for same address shoul...</td>\n",
       "      <td>10200 NE 12th St, Bellevue, WA 98003</td>\n",
       "      <td>10200 NE 12th Street, Bellevue, WA 98003</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Common misspellings for same address should match</td>\n",
       "      <td>1600 Pennsylvna Ave NW, Washington, DC 20500</td>\n",
       "      <td>1600 Pennsylvania Avenue NW, Washington, DC 20500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Different directional prefix formats for same ...</td>\n",
       "      <td>550 S Hill St, Los Angeles, CA</td>\n",
       "      <td>550 South Hill Street, Los Angeles, California</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Incomplete address vs full address may match</td>\n",
       "      <td>1020 SW 2nd Ave, Portland</td>\n",
       "      <td>1020 SW 2nd Ave, Portland, OR 97204</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Different addresses in the same country that d...</td>\n",
       "      <td>1234 Manor Plaza, Pacifica, CA 94044</td>\n",
       "      <td>1234 Bly Manor, Pacific Heights, WA 98003</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Different addresses in the same country that d...</td>\n",
       "      <td>350 5th Ave, New York, NY 10118</td>\n",
       "      <td>1350 El Prado, San Diego, CA 92101</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Completely different addresses that don't match</td>\n",
       "      <td>Rue de la Loi 175, 1040 Brussels</td>\n",
       "      <td>1 Macquarie Street, Sydney, NSW 2000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Different street names means different address</td>\n",
       "      <td>market Square</td>\n",
       "      <td>davis Place</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Similar but different street numbers</td>\n",
       "      <td>10101 Tensor St.</td>\n",
       "      <td>11010 Tensor St.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Description  \\\n",
       "0   Different directional prefix formats for same ...   \n",
       "1   Abbreviated street type for same address shoul...   \n",
       "2   Common misspellings for same address should match   \n",
       "3   Different directional prefix formats for same ...   \n",
       "4        Incomplete address vs full address may match   \n",
       "..                                                ...   \n",
       "71  Different addresses in the same country that d...   \n",
       "72  Different addresses in the same country that d...   \n",
       "73    Completely different addresses that don't match   \n",
       "74     Different street names means different address   \n",
       "75               Similar but different street numbers   \n",
       "\n",
       "                                        Address1  \\\n",
       "0               2024 NW 5th Ave, Miami, FL 33127   \n",
       "1           10200 NE 12th St, Bellevue, WA 98003   \n",
       "2   1600 Pennsylvna Ave NW, Washington, DC 20500   \n",
       "3                 550 S Hill St, Los Angeles, CA   \n",
       "4                      1020 SW 2nd Ave, Portland   \n",
       "..                                           ...   \n",
       "71          1234 Manor Plaza, Pacifica, CA 94044   \n",
       "72               350 5th Ave, New York, NY 10118   \n",
       "73              Rue de la Loi 175, 1040 Brussels   \n",
       "74                                 market Square   \n",
       "75                              10101 Tensor St.   \n",
       "\n",
       "                                             Address2  Label  \n",
       "0     2024 Northwest 5th Avenue, Miami, Florida 33127      1  \n",
       "1            10200 NE 12th Street, Bellevue, WA 98003      1  \n",
       "2   1600 Pennsylvania Avenue NW, Washington, DC 20500      1  \n",
       "3      550 South Hill Street, Los Angeles, California      1  \n",
       "4                 1020 SW 2nd Ave, Portland, OR 97204      1  \n",
       "..                                                ...    ...  \n",
       "71          1234 Bly Manor, Pacific Heights, WA 98003      0  \n",
       "72                 1350 El Prado, San Diego, CA 92101      0  \n",
       "73               1 Macquarie Street, Sydney, NSW 2000      0  \n",
       "74                                        davis Place      0  \n",
       "75                                   11010 Tensor St.      0  \n",
       "\n",
       "[76 rows x 4 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold_df = pd.concat([match_df, mismatch_df], ignore_index=True)\n",
    "\n",
    "gold_df.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6f7651-167e-4621-aa4c-dde5c70a6b1c",
   "metadata": {},
   "source": [
    "### Save our Gold Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "99388a80-6cc9-4e45-8877-5f5980bcc5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_df.to_csv(\"data/gold.csv\", header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8bbf4f-e383-4b08-a7a3-e0ed38db1031",
   "metadata": {},
   "source": [
    "## Data Augmentation with GPT4o - Multiplying Training Data\n",
    "\n",
    "We only have 64 training records, but they aren't just random examples. They cover a range of corner cases that should give a model trained via supervised learning clues about the semantics of addresses.\n",
    "\n",
    "### Human in the Loop Fine-Tuning\n",
    "\n",
    "We may have enough diversity of examples to generate sufficient training data to cover most addresses (at least North American ones). To improve performance, we can create new hand-labeled examples that fix the errors in `match_df` and `mismatch_df` and re-run the data augmentation pipeline to then re-train and evaluate our matching models. **This gives product managers of AI products a means of product managing their models' predictions.**\n",
    "\n",
    "### Not Enough Data: Data Augmentation to the Rescue!\n",
    "\n",
    "Hand labeling is a slow way to create labeled datasets. We need a lot more data than we have, and I can't spare the time to label thousands of records. We could use \"mechanical turks\" to do this work, but instead we're going to use a data augmentation strategy to use Large Language Models (LLMs) to create semantically similar duplicates for each of our original 29 labeled pairs. The address pair descriptions, along with the match/mis-match label, will guide the LLM in creating semantically similar labeled address pairs. \n",
    "\n",
    "### OpenAI GPT4o for Data Augmentation\n",
    "\n",
    "We are going to use the OpenAI API for GPT4o to ask the model to generate similar records for each record we show it that match the semantics of the description of each pair. This can multiply the number of records by 10, 100 even 1,000 times.\n",
    "\n",
    "We set the temporature of the LLM high to ensure we get a diverse set of records. 100 records is as many as we can request at once, so we're going to loop 5 times to get approximately 10,000 labeled address pairs.\n",
    "\n",
    "### How many Record Clones per Existing Example?\n",
    "\n",
    "For each hand-labeled record, we execute 1 request for 100 records each - giving us about 5,000 examples for each hand-labeled address pair."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a37788e2-0c0e-4153-8090-c100190c90c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLONES_PER_RUN = 100\n",
    "RUNS_PER_EXAMPLE = 1\n",
    "\n",
    "# Append clones per run and runs per example as columns\n",
    "gold_df[\"Clones\"] = CLONES_PER_RUN\n",
    "gold_df[\"Runs\"] = RUNS_PER_EXAMPLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6e8d97da-7232-4ef1-85ff-ec6d3af79f5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Address1</th>\n",
       "      <th>Address2</th>\n",
       "      <th>Label</th>\n",
       "      <th>Clones</th>\n",
       "      <th>Runs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Different directional prefix formats for same ...</td>\n",
       "      <td>2024 NW 5th Ave, Miami, FL 33127</td>\n",
       "      <td>2024 Northwest 5th Avenue, Miami, Florida 33127</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abbreviated street type for same address shoul...</td>\n",
       "      <td>10200 NE 12th St, Bellevue, WA 98003</td>\n",
       "      <td>10200 NE 12th Street, Bellevue, WA 98003</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Common misspellings for same address should match</td>\n",
       "      <td>1600 Pennsylvna Ave NW, Washington, DC 20500</td>\n",
       "      <td>1600 Pennsylvania Avenue NW, Washington, DC 20500</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Different directional prefix formats for same ...</td>\n",
       "      <td>550 S Hill St, Los Angeles, CA</td>\n",
       "      <td>550 South Hill Street, Los Angeles, California</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Incomplete address vs full address may match</td>\n",
       "      <td>1020 SW 2nd Ave, Portland</td>\n",
       "      <td>1020 SW 2nd Ave, Portland, OR 97204</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Different addresses in the same country that d...</td>\n",
       "      <td>1234 Manor Plaza, Pacifica, CA 94044</td>\n",
       "      <td>1234 Bly Manor, Pacific Heights, WA 98003</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Different addresses in the same country that d...</td>\n",
       "      <td>350 5th Ave, New York, NY 10118</td>\n",
       "      <td>1350 El Prado, San Diego, CA 92101</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Completely different addresses that don't match</td>\n",
       "      <td>Rue de la Loi 175, 1040 Brussels</td>\n",
       "      <td>1 Macquarie Street, Sydney, NSW 2000</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Different street names means different address</td>\n",
       "      <td>market Square</td>\n",
       "      <td>davis Place</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Similar but different street numbers</td>\n",
       "      <td>10101 Tensor St.</td>\n",
       "      <td>11010 Tensor St.</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Description  \\\n",
       "0   Different directional prefix formats for same ...   \n",
       "1   Abbreviated street type for same address shoul...   \n",
       "2   Common misspellings for same address should match   \n",
       "3   Different directional prefix formats for same ...   \n",
       "4        Incomplete address vs full address may match   \n",
       "..                                                ...   \n",
       "71  Different addresses in the same country that d...   \n",
       "72  Different addresses in the same country that d...   \n",
       "73    Completely different addresses that don't match   \n",
       "74     Different street names means different address   \n",
       "75               Similar but different street numbers   \n",
       "\n",
       "                                        Address1  \\\n",
       "0               2024 NW 5th Ave, Miami, FL 33127   \n",
       "1           10200 NE 12th St, Bellevue, WA 98003   \n",
       "2   1600 Pennsylvna Ave NW, Washington, DC 20500   \n",
       "3                 550 S Hill St, Los Angeles, CA   \n",
       "4                      1020 SW 2nd Ave, Portland   \n",
       "..                                           ...   \n",
       "71          1234 Manor Plaza, Pacifica, CA 94044   \n",
       "72               350 5th Ave, New York, NY 10118   \n",
       "73              Rue de la Loi 175, 1040 Brussels   \n",
       "74                                 market Square   \n",
       "75                              10101 Tensor St.   \n",
       "\n",
       "                                             Address2  Label  Clones  Runs  \n",
       "0     2024 Northwest 5th Avenue, Miami, Florida 33127      1     100     1  \n",
       "1            10200 NE 12th Street, Bellevue, WA 98003      1     100     1  \n",
       "2   1600 Pennsylvania Avenue NW, Washington, DC 20500      1     100     1  \n",
       "3      550 South Hill Street, Los Angeles, California      1     100     1  \n",
       "4                 1020 SW 2nd Ave, Portland, OR 97204      1     100     1  \n",
       "..                                                ...    ...     ...   ...  \n",
       "71          1234 Bly Manor, Pacific Heights, WA 98003      0     100     1  \n",
       "72                 1350 El Prado, San Diego, CA 92101      0     100     1  \n",
       "73               1 Macquarie Street, Sydney, NSW 2000      0     100     1  \n",
       "74                                        davis Place      0     100     1  \n",
       "75                                   11010 Tensor St.      0     100     1  \n",
       "\n",
       "[76 rows x 6 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gold_df.head(len(gold_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded543cb-48b1-4055-84a1-05bab8502240",
   "metadata": {},
   "source": [
    "## Gold Label Evaluation\n",
    "\n",
    "Let's define a method to evaluate our models on the original records, rather than on a sample of the augmented records we will generate below. This will let us know in certain terms how different methods of address matching peform.\n",
    "\n",
    "### Raw Report and Grouped Report\n",
    "\n",
    "We use a utility function in [utils.py](utils.py) called `gold_label_report` that will apply a list of matching methods to our gold label data and return the raw results and a categorical summary. One DataFrame `raw_df` will contain each address pair, while another `grouped_df` will group them by their `Description` field to better understand each model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dfbcce63-1d4d-4970-bb44-36949b676ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def strict_parse_match(row: pd.Series) -> pd.Series:\n",
    "    \"\"\"strict_parse_match Strict address matching\"\"\"\n",
    "    return parse_match_address(row[\"Address1\"], row[\"Address2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9ad7ac90-8373-4d8f-aca0-03bf723560d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get raw results and accuracy by type of matching\n",
    "raw_df, grouped_df = gold_label_report(gold_df, [strict_parse_match])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d82209c-b822-4528-8d7a-edf7e732d36a",
   "metadata": {},
   "source": [
    "### Gold Label Report by `Description`\n",
    "\n",
    "Let's evaluate how well our address matchers work by category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6767841a-602b-4508-a3c9-303a2ee0f83c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strict_parse_match_acc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Description</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Missing country in one record can match</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Same address with and without country should match</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Including and excluding building names for same address should match</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Typographical errors in same address with country should match</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Typographical errors in city of same address should match</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Different unit numbers means different address</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Different units in a building means different address</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Formal and localized format of same address should match</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Including a business name or not, in same address should match</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Variant formats of same address should match</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    strict_parse_match_acc\n",
       "Description                                                               \n",
       "Missing country in one record can match                                1.0\n",
       "Same address with and without country should match                     1.0\n",
       "Including and excluding building names for same...                     1.0\n",
       "Typographical errors in same address with count...                     1.0\n",
       "Typographical errors in city of same address sh...                     1.0\n",
       "...                                                                    ...\n",
       "Different unit numbers means different address                         0.0\n",
       "Different units in a building means different a...                     0.0\n",
       "Formal and localized format of same address sho...                     0.0\n",
       "Including a business name or not, in same addre...                     0.0\n",
       "Variant formats of same address should match                           0.0\n",
       "\n",
       "[59 rows x 1 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show what it knows, followed by what it don't, in alphabetical order\n",
    "grouped_df.sort_values(by=\"strict_parse_match_acc\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ff54d6-e2be-4f4d-afb9-07c9cd2c3057",
   "metadata": {},
   "source": [
    "### Strict Matching Results\n",
    "\n",
    "You can see that strict matching only works for our gold labeled records under certain circumstances, such as when values not essential for a strict match vary. We will improve upon these results below!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a136a817-5025-4969-b810-b4c63c56b1a4",
   "metadata": {},
   "source": [
    "### Gold Label Report\n",
    "\n",
    "Here we can view each example, including what we got right and what we got wrong. This can lead to iterative improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c90be5ba-baf0-455e-a453-416327b05d14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total accurate matches for strict_parse_match: 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Address1</th>\n",
       "      <th>Address2</th>\n",
       "      <th>Label</th>\n",
       "      <th>strict_parse_match</th>\n",
       "      <th>strict_parse_match_correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Missing state but has postal code and country ...</td>\n",
       "      <td>Pariser Platz 2, 10117 Berlin, Germany</td>\n",
       "      <td>Pariser Platz 2, 10117 Berlin, Berlin, Germany</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Missing state but has postal code and country ...</td>\n",
       "      <td>Marienplatz 1, 80331 Munich, Germany</td>\n",
       "      <td>Marienplatz 1, 80331 Munich, Bavaria, Germany</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Same address with and without country should m...</td>\n",
       "      <td>1600 Amphitheatre Parkway, Mountain View, CA 9...</td>\n",
       "      <td>1600 Amphitheatre Parkway, Mountain View, CA 9...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Same address with and without country should m...</td>\n",
       "      <td>3413 Sean Way, Lawrenceville, GA 30044, U.S.A.</td>\n",
       "      <td>3413 Sean Way, Lawrenceville, Georgia, 30044</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Including and excluding building names for sam...</td>\n",
       "      <td>The Empire State Building, 350 5th Ave, New Yo...</td>\n",
       "      <td>350 5th Ave, New York, NY 10118</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Different addresses in the same country that d...</td>\n",
       "      <td>1234 Manor Plaza, Pacifica, CA 94044</td>\n",
       "      <td>1234 Bly Manor, Pacific Heights, WA 98003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Different addresses in the same country that d...</td>\n",
       "      <td>350 5th Ave, New York, NY 10118</td>\n",
       "      <td>1350 El Prado, San Diego, CA 92101</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Completely different addresses that don't match</td>\n",
       "      <td>Rue de la Loi 175, 1040 Brussels</td>\n",
       "      <td>1 Macquarie Street, Sydney, NSW 2000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Different street names means different address</td>\n",
       "      <td>market Square</td>\n",
       "      <td>davis Place</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Similar but different street numbers</td>\n",
       "      <td>10101 Tensor St.</td>\n",
       "      <td>11010 Tensor St.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Description  \\\n",
       "0   Missing state but has postal code and country ...   \n",
       "1   Missing state but has postal code and country ...   \n",
       "2   Same address with and without country should m...   \n",
       "3   Same address with and without country should m...   \n",
       "4   Including and excluding building names for sam...   \n",
       "..                                                ...   \n",
       "41  Different addresses in the same country that d...   \n",
       "42  Different addresses in the same country that d...   \n",
       "43    Completely different addresses that don't match   \n",
       "44     Different street names means different address   \n",
       "45               Similar but different street numbers   \n",
       "\n",
       "                                             Address1  \\\n",
       "0              Pariser Platz 2, 10117 Berlin, Germany   \n",
       "1                Marienplatz 1, 80331 Munich, Germany   \n",
       "2   1600 Amphitheatre Parkway, Mountain View, CA 9...   \n",
       "3      3413 Sean Way, Lawrenceville, GA 30044, U.S.A.   \n",
       "4   The Empire State Building, 350 5th Ave, New Yo...   \n",
       "..                                                ...   \n",
       "41               1234 Manor Plaza, Pacifica, CA 94044   \n",
       "42                    350 5th Ave, New York, NY 10118   \n",
       "43                   Rue de la Loi 175, 1040 Brussels   \n",
       "44                                      market Square   \n",
       "45                                   10101 Tensor St.   \n",
       "\n",
       "                                             Address2  Label  \\\n",
       "0      Pariser Platz 2, 10117 Berlin, Berlin, Germany      1   \n",
       "1       Marienplatz 1, 80331 Munich, Bavaria, Germany      1   \n",
       "2   1600 Amphitheatre Parkway, Mountain View, CA 9...      1   \n",
       "3        3413 Sean Way, Lawrenceville, Georgia, 30044      1   \n",
       "4                     350 5th Ave, New York, NY 10118      1   \n",
       "..                                                ...    ...   \n",
       "41          1234 Bly Manor, Pacific Heights, WA 98003      0   \n",
       "42                 1350 El Prado, San Diego, CA 92101      0   \n",
       "43               1 Macquarie Street, Sydney, NSW 2000      0   \n",
       "44                                        davis Place      0   \n",
       "45                                   11010 Tensor St.      0   \n",
       "\n",
       "    strict_parse_match  strict_parse_match_correct  \n",
       "0                    1                        True  \n",
       "1                    1                        True  \n",
       "2                    1                        True  \n",
       "3                    1                        True  \n",
       "4                    1                        True  \n",
       "..                 ...                         ...  \n",
       "41                   0                        True  \n",
       "42                   0                        True  \n",
       "43                   0                        True  \n",
       "44                   0                        True  \n",
       "45                   0                        True  \n",
       "\n",
       "[46 rows x 6 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_df = raw_df[raw_df[\"strict_parse_match_correct\"]].reset_index(drop=True)\n",
    "print(f\"Total accurate matches for strict_parse_match: {len(true_df):,}\")\n",
    "\n",
    "true_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "076c2e43-942e-4374-815c-1aaba48c0846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total mismatches for strict_parse_match: 30\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Address1</th>\n",
       "      <th>Address2</th>\n",
       "      <th>Label</th>\n",
       "      <th>strict_parse_match</th>\n",
       "      <th>strict_parse_match_correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Different directional prefix formats for same ...</td>\n",
       "      <td>2024 NW 5th Ave, Miami, FL 33127</td>\n",
       "      <td>2024 Northwest 5th Avenue, Miami, Florida 33127</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abbreviated street type for same address shoul...</td>\n",
       "      <td>10200 NE 12th St, Bellevue, WA 98003</td>\n",
       "      <td>10200 NE 12th Street, Bellevue, WA 98003</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Common misspellings for same address should match</td>\n",
       "      <td>1600 Pennsylvna Ave NW, Washington, DC 20500</td>\n",
       "      <td>1600 Pennsylvania Avenue NW, Washington, DC 20500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Different directional prefix formats for same ...</td>\n",
       "      <td>550 S Hill St, Los Angeles, CA</td>\n",
       "      <td>550 South Hill Street, Los Angeles, California</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Incomplete address vs full address may match</td>\n",
       "      <td>1020 SW 2nd Ave, Portland</td>\n",
       "      <td>1020 SW 2nd Ave, Portland, OR 97204</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Common typographical errors in same address sh...</td>\n",
       "      <td>北京市东城区东长安街1号, 中国</td>\n",
       "      <td>北京市东城区东长安街1号, 中囯</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Numeric or written street number for same addr...</td>\n",
       "      <td>123 4th St, Springfield, IL</td>\n",
       "      <td>123 Fourth St, Springfield, IL</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Punctuation or not in abbreviations for same a...</td>\n",
       "      <td>10350 NE 12th St, Bellevue, WA 98003</td>\n",
       "      <td>10350 N.E. 12th St., Bellevue, WA 98003</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Normal vs formal country names for same addres...</td>\n",
       "      <td>456 Coastal Lane, Benaulim, Goa, 403716, India</td>\n",
       "      <td>456 Coastal Lane, Benaulim, Goa, 403716, Repub...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Normal vs abbreviated country name for same ad...</td>\n",
       "      <td>456 Coastal Lane, Benaulim, Goa, 403716, India</td>\n",
       "      <td>456 Coastal Lane, Benaulim, Goa, 403716, IN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Description  \\\n",
       "0   Different directional prefix formats for same ...   \n",
       "1   Abbreviated street type for same address shoul...   \n",
       "2   Common misspellings for same address should match   \n",
       "3   Different directional prefix formats for same ...   \n",
       "4        Incomplete address vs full address may match   \n",
       "..                                                ...   \n",
       "25  Common typographical errors in same address sh...   \n",
       "26  Numeric or written street number for same addr...   \n",
       "27  Punctuation or not in abbreviations for same a...   \n",
       "28  Normal vs formal country names for same addres...   \n",
       "29  Normal vs abbreviated country name for same ad...   \n",
       "\n",
       "                                          Address1  \\\n",
       "0                 2024 NW 5th Ave, Miami, FL 33127   \n",
       "1             10200 NE 12th St, Bellevue, WA 98003   \n",
       "2     1600 Pennsylvna Ave NW, Washington, DC 20500   \n",
       "3                   550 S Hill St, Los Angeles, CA   \n",
       "4                        1020 SW 2nd Ave, Portland   \n",
       "..                                             ...   \n",
       "25                                北京市东城区东长安街1号, 中国   \n",
       "26                     123 4th St, Springfield, IL   \n",
       "27            10350 NE 12th St, Bellevue, WA 98003   \n",
       "28  456 Coastal Lane, Benaulim, Goa, 403716, India   \n",
       "29  456 Coastal Lane, Benaulim, Goa, 403716, India   \n",
       "\n",
       "                                             Address2  Label  \\\n",
       "0     2024 Northwest 5th Avenue, Miami, Florida 33127      1   \n",
       "1            10200 NE 12th Street, Bellevue, WA 98003      1   \n",
       "2   1600 Pennsylvania Avenue NW, Washington, DC 20500      1   \n",
       "3      550 South Hill Street, Los Angeles, California      1   \n",
       "4                 1020 SW 2nd Ave, Portland, OR 97204      1   \n",
       "..                                                ...    ...   \n",
       "25                                   北京市东城区东长安街1号, 中囯      1   \n",
       "26                     123 Fourth St, Springfield, IL      1   \n",
       "27            10350 N.E. 12th St., Bellevue, WA 98003      1   \n",
       "28  456 Coastal Lane, Benaulim, Goa, 403716, Repub...      1   \n",
       "29        456 Coastal Lane, Benaulim, Goa, 403716, IN      1   \n",
       "\n",
       "    strict_parse_match  strict_parse_match_correct  \n",
       "0                    0                       False  \n",
       "1                    0                       False  \n",
       "2                    0                       False  \n",
       "3                    0                       False  \n",
       "4                    0                       False  \n",
       "..                 ...                         ...  \n",
       "25                   0                       False  \n",
       "26                   0                       False  \n",
       "27                   0                       False  \n",
       "28                   0                       False  \n",
       "29                   0                       False  \n",
       "\n",
       "[30 rows x 6 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_df = raw_df[raw_df[\"strict_parse_match_correct\"] == False].reset_index(drop=True)\n",
    "print(f\"Total mismatches for strict_parse_match: {len(false_df):,}\")\n",
    "\n",
    "false_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ba0cc5-4665-4575-85e9-1c6973fecb24",
   "metadata": {},
   "source": [
    "### Setup LLM Caching: Sometimes\n",
    "\n",
    "Our OpenAI LLM request generates a lot of data when asking for a 100 JSON record array. This causes it to occasionally timeout. Accordingly, we setup in memory caching for its requests, so if there is an exception in the request loop for our training examples below, we can simply re-run the cell and it will rapidly return to where it failed and retry, without having to run the previous requests over again.\n",
    "\n",
    "**NOTE: If we iterate and make multiple LLM calls per record via `RUNS_PER_EXAMPLE`, we can't use LLM caching because it will give us the cached result for all iterative API calls after the first one.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5d2ddb23-41c5-4b9f-8b22-f3542065c1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set LLM caching up front\n",
    "set_llm_cache(InMemoryCache())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "775b2b17-76e3-46ab-8f28-8dfbac17e325",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5a8377e2-2bb8-4423-bff4-5b6669dc5616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: I need your help with a data science, data augmentation task. I am fine-tuning a sentence transformer paraphrase model to match pairs of addresses. I tried several embedding models and none of them perform well. They need fine-tuning for this task. I have created about 100 example pairs of addresses to serve as training data for fine-tuning a SentenceTransformer model. Each record has the fields Address1, Address2, a Description of the semantic they express (ex. 'different street number') and a Label (1 for positive match, 0 for negative).\n",
      "\n",
      "The tasks cover two categories of corner cases or difficult tasks. The first is when similar addresses in string distance aren't the same, thus have label 0. The second is the opposite: when dissimilar addresses in string distance are the same, thus have label 1. The strings you return for Address1 and Address2 should not be literally the same.\n",
      "\n",
      "Your task is to read a pair of Addresses, their Description and their Label and generate 100 different examples that express a similar semantic. Your job is to create variations of these records that satisfy the semantic expressed in the description but cover widely varying cases of the meaning covering the entire world. Do not literally copy the address components. Think methodically. Use what you know about postal addresses to accomplish this work.\n",
      "\n",
      "You should return the result in a valid JSON array of records and nothing else, using the fields Address1, Address2, Description and Label.\n",
      "Human: Please generate 100 different examples that express the same or similar semantic as the pair of addresses below based on its Descripton, Label and the Address pairs.\n",
      "\n",
      "Address 1: 2024 NW 5th Ave, Miami, FL 33127\n",
      "Address 2: 2024 Northwest 5th Avenue, Miami, Florida 33127\n",
      "Description: Different directional prefix formats for same address should match\n",
      "Label: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "messages: List[Union[SystemMessagePromptTemplate, HumanMessagePromptTemplate]] = [\n",
    "    SystemMessagePromptTemplate.from_template(\n",
    "        \"I need your help with a data science, data augmentation task. I am fine-tuning \"\n",
    "        \"a sentence transformer paraphrase model to match pairs of addresses. I tried \"\n",
    "        \"several embedding models and none of them perform well. They need fine-tuning \"\n",
    "        \"for this task. I have created about 100 example pairs of addresses to serve as training \"\n",
    "        \"data for fine-tuning a SentenceTransformer model. Each record has the fields \"\n",
    "        \"Address1, Address2, a Description of the semantic they express \"\n",
    "        \"(ex. 'different street number') and a Label (1 for positive match, 0 for negative).\"\n",
    "        \"\\n\\n\"\n",
    "        \"The tasks cover two categories of corner cases or difficult tasks. The first is when similar \"\n",
    "        \"addresses in string distance aren't the same, thus have label 0. \"\n",
    "        \"The second is the opposite: when dissimilar addresses in string distance are the same, \"\n",
    "        \"thus have label 1. The strings you return for Address1 and Address2 should not be literally \"\n",
    "        \"the same.\\n\\n\"\n",
    "        \"Your task is to read a pair of Addresses, their Description and their Label and generate {Clones} \"\n",
    "        \"different examples that express a similar semantic. Your job is to create variations \"\n",
    "        \"of these records that satisfy the semantic expressed in the description but cover \"\n",
    "        \"widely varying cases of the meaning covering the entire world. Do not literally copy the \"\n",
    "        \"address components. Think methodically. Use what you know about postal addresses to accomplish \"\n",
    "        \"this work.\"\n",
    "        \"\\n\\n\"\n",
    "        \"You should return the result in a valid JSON array of records and nothing else, using the \"\n",
    "        \"fields Address1, Address2, Description and Label.\"\n",
    "    ),\n",
    "    # MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    HumanMessagePromptTemplate.from_template(\n",
    "        \"Please generate {Clones} different examples that express the same or similar semantic as \"\n",
    "        \"the pair of addresses below based on its Descripton, Label and the Address pairs.\\n\\n\"\n",
    "        \"Address 1: {Address1}\\n\"\n",
    "        + \"Address 2: {Address2}\\n\"\n",
    "        + \"Description: {Description}\\n\"\n",
    "        + \"Label: {Label}\\n\"\n",
    "    ),\n",
    "]\n",
    "prompt = ChatPromptTemplate.from_messages(messages=messages)\n",
    "\n",
    "# Everything look alright?\n",
    "print(\n",
    "    prompt.format(\n",
    "        Clones=CLONES_PER_RUN,\n",
    "        Address1=gold_df.iloc[0][\"Address1\"],\n",
    "        Address2=gold_df.iloc[0][\"Address2\"],\n",
    "        Description=gold_df.iloc[0][\"Description\"],\n",
    "        Label=gold_df.iloc[0][\"Label\"],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3630e001-ddd2-4057-a20f-759029e21ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new label_chain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: I need your help with a data science, data augmentation task. I am fine-tuning a sentence transformer paraphrase model to match pairs of addresses. I tried several embedding models and none of them perform well. They need fine-tuning for this task. I have created about 100 example pairs of addresses to serve as training data for fine-tuning a SentenceTransformer model. Each record has the fields Address1, Address2, a Description of the semantic they express (ex. 'different street number') and a Label (1 for positive match, 0 for negative).\n",
      "\n",
      "The tasks cover two categories of corner cases or difficult tasks. The first is when similar addresses in string distance aren't the same, thus have label 0. The second is the opposite: when dissimilar addresses in string distance are the same, thus have label 1. The strings you return for Address1 and Address2 should not be literally the same.\n",
      "\n",
      "Your task is to read a pair of Addresses, their Description and their Label and generate 100 different examples that express a similar semantic. Your job is to create variations of these records that satisfy the semantic expressed in the description but cover widely varying cases of the meaning covering the entire world. Do not literally copy the address components. Think methodically. Use what you know about postal addresses to accomplish this work.\n",
      "\n",
      "You should return the result in a valid JSON array of records and nothing else, using the fields Address1, Address2, Description and Label.\n",
      "Human: Please generate 100 different examples that express the same or similar semantic as the pair of addresses below based on its Descripton, Label and the Address pairs.\n",
      "\n",
      "Address 1: 2024 NW 5th Ave, Miami, FL 33127\n",
      "Address 2: 2024 Northwest 5th Avenue, Miami, Florida 33127\n",
      "Description: Different directional prefix formats for same address should match\n",
      "Label: 1\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "[{'Address1': '1500 SE 10th St, Fort Lauderdale, FL 33316', 'Address2': '1500 Southeast 10th Street, Fort Lauderdale, Florida 33316', 'Description': 'Different directional prefix formats for same address should match', 'Label': 1}, {'Address1': '300 W 23rd St, New York, NY 10011', 'Address2': '300 West 23rd Street, New York, New York 10011', 'Description': 'Different directional prefix formats for same address should match', 'Label': 1}, {'Address1': '120 N Main St, Ann Arbor, MI 48104', 'Address2': '120 North Main Street, Ann Arbor, Michigan 48104', 'Description': 'Different directional prefix formats for same address should match', 'Label': 1}, {'Address1': '450 E 8th Ave, Denver, CO 80203', 'Address2': '450 East 8th Avenue, Denver, Colorado 80203', 'Description': 'Different directional prefix formats for same address should match', 'Label': 1}, {'Address1': '789 S 9th St, Louisville, KY 40203', 'Address2': '789 South 9th Street, Louisville, Kentucky 40203', 'Description': 'Different directional prefix formats for same address should match', 'Label': 1}, {'Address1': '3600 W 6th St, Los Angeles, CA 90020', 'Address2': '3600 West 6th Street, Los Angeles, California 90020', 'Description': 'Different directional prefix formats for same address should match', 'Label': 1}, {'Address1': '123 NE 1st Ave, Portland, OR 97232', 'Address2': '123 Northeast 1st Avenue, Portland, Oregon 97232', 'Description': 'Different directional prefix formats for same address should match', 'Label': 1}, {'Address1': '200 SW 3rd St, Oklahoma City, OK 73109', 'Address2': '200 Southwest 3rd Street, Oklahoma City, Oklahoma 73109', 'Description': 'Different directional prefix formats for same address should match', 'Label': 1}, {'Address1': '654 NW 4th Ave, Seattle, WA 98109', 'Address2': '654 Northwest 4th Avenue, Seattle, Washington 98109', 'Description': 'Different directional prefix formats for same address should match', 'Label': 1}, {'Address1': '890 E 5th St, Austin, TX 78702', 'Address2': '890 East 5th Street, Austin, Texas 78702', 'Description': 'Different directional prefix formats for same address should match', 'Label': 1}, {'Address1': '555 S 6th Ave, Tucson, AZ 85701', 'Address2': '555 South 6th Avenue, Tucson, Arizona 85701', 'Description': 'Different directional prefix formats for same address should match', 'Label': 1}, {'Address1': '101 N 7th St, Philadelphia, PA 19106', 'Address2': '101 North 7th Street, Philadelphia, Pennsylvania 19106', 'Description': 'Different directional prefix formats for same address should match', 'Label': 1}, {'Address1': '789 W 8th Ave, Vancouver, BC V5Z 1E4', 'Address2': '789 West 8th Avenue, Vancouver, British Columbia V5Z 1E4', 'Description': 'Different directional prefix formats for same address should match', 'Label': 1}, {'Address1': '234 E 9th St, Charlotte, NC 28202', 'Address2': '234 East 9th Street, Charlotte, North Carolina 28202', 'Description': 'Different directional prefix formats for same address should match', 'Label': 1}, {'Address1': '345 N 10th Ave, Phoenix, AZ 85007', 'Address2': '345 North 10th Avenue, Phoenix, Arizona 85007', 'Description': 'Different directional prefix formats for same address should match', 'Label': 1}, {'Address1': '678 S 11th St, San Diego, CA 92101', 'Address2': '678 South 11th Street, San Diego, California 92101', 'Description': 'Different directional prefix formats for same address should match', 'Label': 1}, {'Address1': '910 E 12th Ave, Houston, TX 77008', 'Address2': '910 East 12th Avenue, Houston, Texas 77008', 'Description': 'Different directional prefix formats for same address should match', 'Label': 1}, {'Address1': '112 W 13th St, Dallas, TX 75208', 'Address2': '112 West 13th Street, Dallas, Texas 75208', 'Description': 'Different directional prefix formats for same address should match', 'Label': 1}, {'Address1': '223 N 14th Ave, San Francisco, CA 94118', 'Address2': '223 North 14th Avenue, San Francisco, California 94118', 'Description': 'Different directional prefix formats for same address should match', 'Label': 1}, {'Address1': '334 S 15th St, Las Vegas, NV 89101', 'Address2': '334 South 15th Street, Las Vegas, Nevada 89101', 'Description': 'Different directional prefix formats for same address should match', 'Label': 1}, {'Address1': '445 E 16th Ave, Atlanta, GA 30308', 'Address2': '445 East 16th Avenue, Atlanta, Georgia 30308', 'Description': 'Different directional prefix formats for same address should match', 'Label': 1}, {'Address1': '556 W 17th St, Boston, MA 02118', 'Address2': '556 West 17th Street, Boston, Massachusetts 02118', 'Description': 'Different directional prefix formats for same address should match', 'Label': 1}, {'Address1': '667 N 18th Ave, Chicago, IL 60616', 'Address2': '667 North 18th Avenue, Chicago, Illinois 60616', 'Description': 'Different directional prefix formats for same address should match', 'Label': 1}, {'Address1': '778 S 19th St, Detroit, MI 48208', 'Address2': '778 South 19th Street, Detroit, Michigan 48208', 'Description': 'Different directional prefix formats for same address should match', 'Label': 1}, {'Address1': '889 E 20th Ave, Columbus, OH 43211', 'Address2': '889 East 20th Avenue, Columbus, Ohio 43211', 'Description': 'Different directional prefix formats for same address should match', 'Label': 1}, {'Address1': '990 W 21st St, Indianapolis, IN 46202', 'Address2': '990 West 21st Street, Indianapolis, Indiana 46202', 'Description': 'Different directional prefix formats for same address should match', 'Label': 1}, {'Address1': '1011 N 22nd Ave, Memphis, TN 38112', 'Address2': '1011 North 22nd Avenue, Memphis, Tennessee 38112', 'Description': 'Different directional prefix formats for same address should match', 'Label': 1}, {'Address1': '1122 S 23rd St, Kansas City, MO 64108', 'Address2': '1122 South 23rd Street, Kansas City, Missouri 64108', 'Description': 'Different directional prefix formats for same address should match', 'Label': 1}, {'Address1': '1233 E 24th Ave, Nashville, TN 37208', 'Address2': '1233 East 24th Avenue, Nashville, Tennessee 37208', 'Description': 'Different directional prefix formats for same address should match', 'Label': 1}, {'Address1': '1344 W 25th St, Louisville, KY 40211', 'Address2': '1344 West 25th Street, Louisville, Kentucky 40211', 'Description': 'Different directional prefix formats for same address should match', 'Label': 1}, {'Address1': '1455 N 26th Ave, Milwaukee, WI 53208', 'Address2': '1455 North 26th Avenue, Milwaukee, Wisconsin 53208', 'Description': 'Different directional prefix formats for same address should match', 'Label': 1}, {'Address1': '1566 S 27th St, Minneapolis, MN 55407', 'Address2': '1566 South 27th Street, Minneapolis, Minnesota 55407', 'Description': 'Different directional prefix formats for same address should match', 'Label': 1}, {'Address1': '1677 E 28th Ave, New Orleans, LA 70119', 'Address2': '1677 East 28th Avenue, New Orleans, Louisiana 70119', 'Description': 'Different directional prefix formats for same address should match', 'Label': 1}, {'Address1': '1788 W 29th St, Sacramento, CA 95816', 'Address2': '1788 West 29th Street, Sacramento, California 95816', 'Description': 'Different directional prefix formats for same address should match', 'Label': 1}, {'Address1': '1899 N 30th Ave, Portland, OR 97210', 'Address2': '1899 North 30th Avenue, Portland, Oregon 97210', 'Description': 'Different directional prefix formats for same address should match', 'Label': 1}, {'Address1': '2000 S 31st St, Omaha, NE 68105', 'Address2': '2000 South 31st Street, Omaha, Nebraska 68105', 'Description': 'Different directional prefix formats for same address should match', 'Label': 1}, {'Address1': '2111 E 32nd Ave, Tulsa, OK 74105', 'Address2': '2111 East 32nd Avenue, Tulsa, Oklahoma 74105', 'Description': 'Different directional prefix formats for same address should match', 'Label': 1}, {'Address1': '2222 W 33rd St, Wichita, KS 67217', 'Address2': '2222 West 33rd Street, Wichita, Kansas 67217', 'Description': 'Different directional prefix formats for same address should match', 'Label': 1}, {'Address1': '2333 N 34th Ave, Albuquerque, NM 87107', 'Address2': '2333 North 34th Avenue, Albuquerque, New Mexico 87107', 'Description': 'Different directional prefix formats for same address should match', 'Label': 1}, {'Address1': '2444 S 35th St, Tucson, AZ 85713', 'Address2': '2444 South 35th Street, Tucson, Arizona 85713', 'Description': 'Different directional prefix formats for same address should match', 'Label': 1}, {'Address1': '2555 E 36th Ave, Fresno, CA 93702', 'Address2': '2555 East 36th Avenue, Fresno, California 93702', 'Description': 'Different directional prefix formats for same address should match', 'Label': 1}, {'Address1': '2666 W 37th St, Mesa, AZ 85201', 'Address2': '2666 West 37th Street, Mesa, Arizona 85201', 'Description': 'Different directional prefix formats for same address should match', 'Label': 1}, {'Address1': '2777 N 38th Ave, Colorado Springs, CO 80907', 'Address2': '2777 North 38th Avenue, Colorado Springs, Colorado 80907', 'Description': 'Different directional prefix formats for same address should match', 'Label': 1}, {'Address1': '2888 S 39th St, Long Beach, CA 90806', 'Address2': '2888 South 39th Street, Long Beach, California 90806', 'Description': 'Different directional prefix formats for same address should match', 'Label': 1}, {'Address1': '2999 E 40th Ave, Virginia Beach, VA 23451', 'Address2': '2999 East 40th Avenue, Virginia Beach, Virginia 23451', 'Description': 'Different directional prefix formats for same address should match', 'Label': 1}, {'Address1': '3100 W 41st St, Miami, FL 33142', 'Address2': '3100 West 41st Street, Miami, Florida 33142', 'Description': 'Different directional prefix formats for same address should match', 'Label': 1}, {'Address1': '3211 N 42nd Ave, Raleigh, NC 27609', 'Address2': '3211 North 42nd Avenue, Raleigh, North Carolina 27609', 'Description': 'Different directional prefix formats for same address should match', 'Label': 1}, {'Address1': '3322 S 43rd St, Richmond, VA 23223', 'Address2': '3322 South 43rd Street, Richmond, Virginia 23223', 'Description': 'Different directional prefix formats for same address should match', 'Label': 1}, {'Address1': '3433 E 44th Ave, Orlando, FL 32803', 'Address2': '3433 East 44th Avenue, Orlando, Florida 32803', 'Description': 'Different directional prefix formats for same address should match', 'Label': 1}, {'Address1': '3544 W 45th St, Jacksonville, FL 32209', 'Address2': '3544 West 45th Street, Jacksonville, Florida 32209', 'Description': 'Different directional prefix formats for same address should match', 'Label': 1}, {'Address1': '3655 N 46th Ave, Tampa, FL 33610', 'Address2': '3655 North 46th Avenue, Tampa, Florida 33610', 'Description': 'Different directional prefix formats for same address should match', 'Label': 1}, {'Address1': '3766 S 47th St, St. Petersburg, FL 33711', 'Address2': '3766 South 47th Street, St. Petersburg, Florida 33711', 'Description': 'Different directional prefix formats for same address should match', 'Label': 1}, {'Address1': '3877 E 48th Ave, Hialeah, FL 33013', 'Address2': '3877 East 48th Avenue, Hialeah, Florida 33013', 'Description': 'Different directional prefix formats for same address should match', 'Label': 1}, {'Address1': '3988 W 49th St, Tallahassee, FL 32304', 'Address2': '3988 West 49th Street, Tallahassee, Florida 32304', 'Description': 'Different directional prefix formats for same address should match', 'Label': 1}, {'Address1': '4099 N 50th Ave, Fort Lauderdale, FL 33334', 'Address2': '4099 North 50th Avenue, Fort Lauderdale, Florida 33334', 'Description': 'Different directional prefix formats for same address should match', 'Label': 1}, {'Address1': '4200 S 51st St, Hollywood, FL 33021', 'Address2': '4200 South 51st Street, Hollywood, Florida 33021', 'Description': 'Different directional prefix formats for same address should match', 'Label': 1}, {'Address1': '4311 E 52nd Ave, Pembroke Pines, FL 33024', 'Address2': '4311 East 52nd Avenue, Pembroke Pines, Florida 33024', 'Description': 'Different directional prefix formats for same address should match', 'Label': 1}, {'Address1': '4422 W 53rd St, Miramar, FL 33025', 'Address2': '4422 West 53rd Street, Miramar, Florida 33025', 'Description': 'Different directional prefix formats for same address should match', 'Label': 1}, {'Address1': '4533 N 54th Ave, Coral Springs, FL 33065', 'Address2': '4533 North 54th Avenue, Coral Springs, Florida 33065', 'Description': 'Different directional prefix formats for same address should match', 'Label': 1}, {'Address1': '4644 S 55th St, Gainesville, FL 32608', 'Address2': '4644 South 55th Street, Gainesville, Florida 32608', 'Description': 'Different directional prefix formats for same address should match', 'Label': 1}, {}]\n"
     ]
    }
   ],
   "source": [
    "json_output_parser = JsonOutputParser()\n",
    "\n",
    "label_chain = LLMChain(\n",
    "    name=\"label_chain\", prompt=prompt, llm=llm, output_parser=json_output_parser, verbose=True\n",
    ")\n",
    "\n",
    "# Test it once...\n",
    "TEST_INDEX = 0\n",
    "\n",
    "result = label_chain.run(**gold_df.iloc[TEST_INDEX].to_dict())\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef53f6e-7d8f-476c-8872-88c4bf7e733d",
   "metadata": {},
   "source": [
    "### Run Examples through an LLM to Generate Records to Fine-Tune `SentenceTransformers` and other Models\n",
    "\n",
    "Now that we know our chain works, let's generate some training data! I have created a helper function called `augment_gold_labels` that iterates through our gold labeled data and submits them for augmentation as we have seen above. You can find it in [utils.py](utils.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75d8f04-fd7f-4cf5-886a-a07999c92b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "augment_results_df = augment_gold_labels(gold_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27312559-3463-487b-a8a1-3717f45d34e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "augment_results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0f6d76-3697-4977-ab4f-b2241fae0047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle our results so we can see different examples - remember we shuffle again in our train_test_split\n",
    "augment_results_df = augment_results_df.sample(frac=1.0).reset_index(drop=True)\n",
    "augment_results_df.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b9295b-e080-4273-ab88-34895de89d90",
   "metadata": {},
   "source": [
    "### Sanity Check our Descriptions\n",
    "\n",
    "At one point the model generated 50K examples of one type because my iteration on the LLM instructions went haywire. Let's make sure we have a variety of corner cases in our data. Depending on the prompt, it is possible for the jobs we submitted to return surprising data :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cfc74088-4fcc-456c-b4e8-dcad869cf867",
   "metadata": {},
   "outputs": [],
   "source": [
    "augment_results_df.groupby(\"Description\").count()[\"Label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d6382fc3-ca84-4d17-9d74-354ab798d21c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Address1</th>\n",
       "      <th>Address2</th>\n",
       "      <th>Description</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>667 Birchwood Ave, San Diego, CA</td>\n",
       "      <td>667 Birchwood Ln, San Diego, CA</td>\n",
       "      <td>Different street suffixes means different address</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12 Lagoon Lane, Suva, 00000, Fiji</td>\n",
       "      <td>12 Lagoon Lane, Suva, 00000, Republic of Fiji</td>\n",
       "      <td>Normal vs formal country names for same addres...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1010 Spruce Street, Suite 24TT, Baltimore, MD ...</td>\n",
       "      <td>1010 Spruce Street, Suite 24-UU, Baltimore, MD...</td>\n",
       "      <td>Different units in a building means different ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bagan, Mandalay Region, Myanmar</td>\n",
       "      <td>Bagan, Mandalay Region, Myanmr</td>\n",
       "      <td>Typographical errors in city of same address s...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>One Market Street, San Francisco, CA 94105, USA</td>\n",
       "      <td>One Market Street, San Francisco, CA 94105, US</td>\n",
       "      <td>Typographical errors in city of same address s...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Statue of Liberty, Liberty Island, New York, N...</td>\n",
       "      <td>Statue of Liberty, Liberty Island, New York, N...</td>\n",
       "      <td>Missing state but has postal code and country ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5353 Sequoia Street, Yerevan, 0001, Armenia</td>\n",
       "      <td>5353 Sequoia Street, Yerevan, 0001</td>\n",
       "      <td>Same address with and without country should m...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10 Downing Street, Westminster, London SW1A 2AA</td>\n",
       "      <td>10 Downing Lane, Westminster, London SW1A 2AA</td>\n",
       "      <td>Similar road names can be different addresses</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1 Infinite Loop, Cupertino, CA 95014</td>\n",
       "      <td>4 Infinite Loop, Cupertino, CA 95014</td>\n",
       "      <td>Different street numbers means different address</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Niagara Falls, NY 14303, USA</td>\n",
       "      <td>Niagara Falls, New York 14303, USA</td>\n",
       "      <td>Variant formats of same address should match</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5000 Forbes Ave, Pittsburgh, PA 15213</td>\n",
       "      <td>5001 Forbes Ave, Pittsburgh, PA 15213</td>\n",
       "      <td>Different street numbers means different address</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3232 Cedar St., Albany, NY 12207</td>\n",
       "      <td>3232 Cedar St., Albany, GA 31701</td>\n",
       "      <td>Different states means different address</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3000 Oak Street, Sacramento, CA 95814</td>\n",
       "      <td>3002 Oak Street, Sacramento, CA 95814</td>\n",
       "      <td>Adjacent or nearby building numbers means diff...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Eighty-Sixth Lane, Philadelphia, PA</td>\n",
       "      <td>86th Ln, Philadelphia, Pennsylvania</td>\n",
       "      <td>Numerical variations for same address should m...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5000 Main St, Ottawa, ON K1A 6A1, Canada</td>\n",
       "      <td>5000 Main St, Regina, SK S4P 7A2, Canada</td>\n",
       "      <td>Different states means different address</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1 Infinite Loop, Cupertino, CA 95014</td>\n",
       "      <td>123 Main St, Anytown, USA 12345</td>\n",
       "      <td>Different addresses in the same country that d...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>90 Orchard Road, Singapore, 238841, Singapore</td>\n",
       "      <td>90 Orchard Road, Singapore, 238841, SG</td>\n",
       "      <td>Normal vs abbreviated country name for same ad...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Great Smoky Mountains National Park, Tennessee...</td>\n",
       "      <td>Great Smoky Mountains National Park, Tennessee...</td>\n",
       "      <td>Common typographical errors in same address sh...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3637 Dogwood Street, Anytown, USA</td>\n",
       "      <td>3637 Dogwood Avenue, Anytown, USA</td>\n",
       "      <td>Similar road names can be different addresses</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Victoria Falls, Mosi-o-Tunya Road, Livingstone...</td>\n",
       "      <td>Chutes Victoria, Mosi-o-Tunya Road, Livingston...</td>\n",
       "      <td>Different languages for same address should match</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Address1  \\\n",
       "0                    667 Birchwood Ave, San Diego, CA   \n",
       "1                   12 Lagoon Lane, Suva, 00000, Fiji   \n",
       "2   1010 Spruce Street, Suite 24TT, Baltimore, MD ...   \n",
       "3                     Bagan, Mandalay Region, Myanmar   \n",
       "4     One Market Street, San Francisco, CA 94105, USA   \n",
       "5   Statue of Liberty, Liberty Island, New York, N...   \n",
       "6         5353 Sequoia Street, Yerevan, 0001, Armenia   \n",
       "7     10 Downing Street, Westminster, London SW1A 2AA   \n",
       "8                1 Infinite Loop, Cupertino, CA 95014   \n",
       "9                        Niagara Falls, NY 14303, USA   \n",
       "10              5000 Forbes Ave, Pittsburgh, PA 15213   \n",
       "11                   3232 Cedar St., Albany, NY 12207   \n",
       "12              3000 Oak Street, Sacramento, CA 95814   \n",
       "13                Eighty-Sixth Lane, Philadelphia, PA   \n",
       "14           5000 Main St, Ottawa, ON K1A 6A1, Canada   \n",
       "15               1 Infinite Loop, Cupertino, CA 95014   \n",
       "16      90 Orchard Road, Singapore, 238841, Singapore   \n",
       "17  Great Smoky Mountains National Park, Tennessee...   \n",
       "18                  3637 Dogwood Street, Anytown, USA   \n",
       "19  Victoria Falls, Mosi-o-Tunya Road, Livingstone...   \n",
       "\n",
       "                                             Address2  \\\n",
       "0                     667 Birchwood Ln, San Diego, CA   \n",
       "1       12 Lagoon Lane, Suva, 00000, Republic of Fiji   \n",
       "2   1010 Spruce Street, Suite 24-UU, Baltimore, MD...   \n",
       "3                      Bagan, Mandalay Region, Myanmr   \n",
       "4      One Market Street, San Francisco, CA 94105, US   \n",
       "5   Statue of Liberty, Liberty Island, New York, N...   \n",
       "6                  5353 Sequoia Street, Yerevan, 0001   \n",
       "7       10 Downing Lane, Westminster, London SW1A 2AA   \n",
       "8                4 Infinite Loop, Cupertino, CA 95014   \n",
       "9                  Niagara Falls, New York 14303, USA   \n",
       "10              5001 Forbes Ave, Pittsburgh, PA 15213   \n",
       "11                   3232 Cedar St., Albany, GA 31701   \n",
       "12              3002 Oak Street, Sacramento, CA 95814   \n",
       "13                86th Ln, Philadelphia, Pennsylvania   \n",
       "14           5000 Main St, Regina, SK S4P 7A2, Canada   \n",
       "15                    123 Main St, Anytown, USA 12345   \n",
       "16             90 Orchard Road, Singapore, 238841, SG   \n",
       "17  Great Smoky Mountains National Park, Tennessee...   \n",
       "18                  3637 Dogwood Avenue, Anytown, USA   \n",
       "19  Chutes Victoria, Mosi-o-Tunya Road, Livingston...   \n",
       "\n",
       "                                          Description  Label  \n",
       "0   Different street suffixes means different address    0.0  \n",
       "1   Normal vs formal country names for same addres...    1.0  \n",
       "2   Different units in a building means different ...    0.0  \n",
       "3   Typographical errors in city of same address s...    1.0  \n",
       "4   Typographical errors in city of same address s...    1.0  \n",
       "5   Missing state but has postal code and country ...    1.0  \n",
       "6   Same address with and without country should m...    1.0  \n",
       "7       Similar road names can be different addresses    0.0  \n",
       "8    Different street numbers means different address    0.0  \n",
       "9        Variant formats of same address should match    1.0  \n",
       "10   Different street numbers means different address    0.0  \n",
       "11           Different states means different address    0.0  \n",
       "12  Adjacent or nearby building numbers means diff...    0.0  \n",
       "13  Numerical variations for same address should m...    1.0  \n",
       "14           Different states means different address    0.0  \n",
       "15  Different addresses in the same country that d...    0.0  \n",
       "16  Normal vs abbreviated country name for same ad...    1.0  \n",
       "17  Common typographical errors in same address sh...    1.0  \n",
       "18      Similar road names can be different addresses    0.0  \n",
       "19  Different languages for same address should match    1.0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you want to start from here and not run the data augmentation pipeline again...\n",
    "augment_results_df = pd.read_parquet(\"data/training.5.parquet\")\n",
    "\n",
    "augment_results_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "778a9d3d-3576-4e16-9629-12ce3efa7b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save for posterity\n",
    "# augment_results_df.to_parquet(\"data/training.5.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2b2e4e-0c28-47ce-8b3c-7c1dac0062f5",
   "metadata": {},
   "source": [
    "### Data Augmentation Complete!\n",
    "\n",
    "Starting by hand labeling under 100 records and iterating a few times on data augmentation instructions for GPT4o, we have multiplied them by many times to get almost 10,000 synthetic records! This is enough to fine-tune a `SentenceTransformer` or semantic text similarity classifier model. GPT4o is a powerful tool for data augmentation! This can work for a variety of problems.\n",
    "\n",
    "LLM based data augmentation is a powerful tool for your data labeling toolbox."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423992c9-bd0c-4e85-b5ce-cbf14a1d5356",
   "metadata": {},
   "source": [
    "# Comparing Different Approaches to Address Matching\n",
    "\n",
    "Now we're going to compare the following methods of address matching:\n",
    "\n",
    "1) String Distance - we'll use PyPI library [fuzzywuzzy](https://pypi.org/project/fuzzywuzzy/0.6.1/) to compute the Levenshtein ratio and partial ratio of how many edits are required to match the address strings. There are times this works well, and there are times it couldn't be more wrong.\n",
    "2) Text Embeddings - we'll use transfer learning to load an existing [SentenceTransformer](https://sbert.net) model to sentence encode pairs of addresses to create fixed-length embeddings for each address and then compute a similarity score via [cosine similarity](https://en.wikipedia.org/wiki/Cosine_similarity). This won't work without fine-tuning, so we fine-tune the model to the task.\n",
    "3) Deep Matching Model - We'll train a deep semantic textual similarity classification model that will use Siamese BERT networks as in [Sentence-BERT](https://arxiv.org/abs/1908.10084) to classify address pairs as matching or not matching.\n",
    "\n",
    "## Imprecise Country Matching with `pycountry`\n",
    "\n",
    "The structured address has fields that each have their own semantics. Tools specific to a field can help match address components.\n",
    "\n",
    "If you have any valid ISO nation abbreviation or long form name, [pycountry](https://pypi.org/project/pycountry/) is a PyPi module that can retrieve the actual country for it. This enables efficient comparison. Let's use that to convert the mismatched Singapore references in these records to the same entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2a5668a3-cd66-4eb1-a9b3-b029dc045f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_country_names(country1: str, country2: str) -> Literal[0, 1]:\n",
    "    \"\"\"match_country_strings - compare and match varying country formats using pycountry\"\"\"\n",
    "\n",
    "    # Remove any punctuation from the country\n",
    "    def remove_punctuation(country: str) -> str:\n",
    "        # Use re.sub to replace all punctuation characters with an empty string\n",
    "        return re.sub(r\"[^\\w\\s]\", \"\", country)\n",
    "\n",
    "    def multi_lookup(**kwargs):\n",
    "        \"\"\"Try each key until we retrieve a result\"\"\"\n",
    "        for arg, value in kwargs.items():\n",
    "            result = pycountry.countries.get(**{arg: value})\n",
    "            if result:\n",
    "                return result\n",
    "\n",
    "    def get_args(country: str):\n",
    "        \"\"\"Compose pycountries.countries.get arguments dict based on length of country string\"\"\"\n",
    "        args = {}\n",
    "        if country and len(country) == 2:\n",
    "            args[\"alpha_2\"] = country\n",
    "        elif country and len(country) == 3:\n",
    "            args[\"alpha_3\"] = country\n",
    "        elif country:\n",
    "            args[\"name\"] = country\n",
    "            args[\"common_name\"] = country\n",
    "            args[\"official_name\"] = country\n",
    "        return args\n",
    "\n",
    "    try:\n",
    "        pycountry1 = multi_lookup(**get_args(remove_punctuation(country1)))\n",
    "        pycountry2 = multi_lookup(**get_args(remove_punctuation(country2)))\n",
    "\n",
    "        return 1 if pycountry1.name == pycountry2.name else 0\n",
    "    except AttributeError:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f275580d-a5ed-40b2-a27f-5d7134e56eb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_country_names(\"sg\", \"singapore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "49a967b3-ada6-4b8e-b526-671460f0f81a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_country_names(\"usa\", \"united states\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "60a116cb-05c4-4bcd-8c35-3e16f12621ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Didn't match until I added and called remove_punctuation(country: str) -> str\n",
    "match_country_names(\"U.S.A.\", \"United States of America\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7774066a-5e75-4420-ba88-ecb39cb7d828",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_country_names(\"USA\", \"MEX\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "089d99c3-61ec-442e-97ad-b7f826186579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_country_names(\"United States\", \"United Mexican States\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df92059-6211-4044-973f-844a04682d96",
   "metadata": {},
   "source": [
    "### Country Parsing in Structured Matching\n",
    "\n",
    "Let's use our new method `match_pycountry(country1: str, country2: str) -> Literal[0, 1]` matcher to improve our original structured matcher. This will allow it to contain varying country formats and still match. This makes the matcher more robust. \n",
    "\n",
    "In order to make this work we have to refactor our code to create matching functions for each field. Note that we are leaving out matching states, as they aren't required if the road name, number, unit and postal code match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5e9ad90b-9524-4cd4-b0da-4c0a0b1e7f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_match_address_country(address1: str, address2: str) -> Literal[0, 1]:\n",
    "    \"\"\"parse_match_address_country implements address matching like parse_match_address() but with pycountry country matching\"\"\"\n",
    "    address1 = to_dict(parse_address(address1))\n",
    "    address2 = to_dict(parse_address(address2))\n",
    "\n",
    "    def match_road(address1: str, address2: str) -> Literal[0, 1]:\n",
    "        \"\"\"match_road - literal road matching, negative if either lacks a road\"\"\"\n",
    "        if (\"road\" in address1) and (\"road\" in address2):\n",
    "            if address1[\"road\"] == address2[\"road\"]:\n",
    "                logger.debug(\"road match\")\n",
    "                return 1\n",
    "            else:\n",
    "                logger.debug(\"road mismatch\")\n",
    "                return 0\n",
    "        logger.debug(\"road mismatch\")\n",
    "        return 0\n",
    "\n",
    "    def match_house_number(address1: str, address2: str) -> Literal[0, 1]:\n",
    "        \"\"\"match_house_number - literal house number matching, negative if either lacks a house_number\"\"\"\n",
    "        if (\"house_number\" in address1) and (\"house_number\" in address2):\n",
    "            if address1[\"house_number\"] == address2[\"house_number\"]:\n",
    "                logger.debug(\"house_number match\")\n",
    "                return 1\n",
    "            else:\n",
    "                logger.debug(\"house_number mismatch\")\n",
    "                return 0\n",
    "        logger.debug(\"house_number mistmatch\")\n",
    "        return 0\n",
    "\n",
    "    def match_unit(address1: str, address2: str) -> Literal[0, 1]:\n",
    "        \"\"\"match_unit - note a missing unit in both is a match\"\"\"\n",
    "        if \"unit\" in address1:\n",
    "            if \"unit\" in address2:\n",
    "                logger.debug(\"unit match\")\n",
    "                return 1 if (address1[\"unit\"] == address2[\"unit\"]) else 0\n",
    "            else:\n",
    "                logger.debug(\"unit mismatch\")\n",
    "                return 0\n",
    "        if \"unit\" in address2:\n",
    "            if \"unit\" in address1:\n",
    "                logger.debug(\"unit match\")\n",
    "                return 1 if (address1[\"unit\"] == address2[\"unit\"]) else 0\n",
    "            else:\n",
    "                logger.debug(\"unit mismatch\")\n",
    "                return 0\n",
    "        # Neither address has a unit, which is a default match\n",
    "        return 1\n",
    "\n",
    "    def match_postcode(address1: str, address2: str) -> Literal[0, 1]:\n",
    "        \"\"\"match_postcode - literal matching, negative if either lacks a postal code\"\"\"\n",
    "        if (\"postcode\" in address1) and (\"postcode\" in address2):\n",
    "            if address1[\"postcode\"] == address2[\"postcode\"]:\n",
    "                logger.debug(\"postcode match\")\n",
    "                return 1\n",
    "            else:\n",
    "                logger.debug(\"postcode mismatch\")\n",
    "                return 0\n",
    "        logger.debug(\"postcode mismatch\")\n",
    "        return 0\n",
    "\n",
    "    def match_country(address1: str, address2: str) -> Literal[0, 1]:\n",
    "        \"\"\"match_country - semantic country matching with pycountry via match_country_names(country1, country2)\"\"\"\n",
    "        if (\"country\" in address1) and (\"country\" in address2):\n",
    "            if match_country_names(address1[\"country\"], address2[\"country\"]):\n",
    "                logger.debug(\"country match\")\n",
    "                return 1\n",
    "            else:\n",
    "                logger.debug(\"country mismatch\")\n",
    "                return 0\n",
    "        # One or none countries should match\n",
    "        logger.debug(\"country match\")\n",
    "        return 1\n",
    "\n",
    "    # Combine the above to get a complete address matcher\n",
    "    if (\n",
    "        match_road(address1, address2)\n",
    "        and match_house_number(address1, address2)\n",
    "        and match_unit(address1, address2)\n",
    "        and match_postcode(address1, address2)\n",
    "        # Our only non-exact match - default to 1, match\n",
    "        and match_country(address1, address2)\n",
    "    ):\n",
    "        logger.debug(\"overall match\")\n",
    "        return 1\n",
    "    else:\n",
    "        logger.debug(\"overall mismatch\")\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f807c16a-02db-4246-b696-ca1ff4cd9372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_match_address_country(\n",
    "    \"100 Roxas Blvd, Ermita, Manila, 1000 Metro Manila, PH\",\n",
    "    \"100 Roxas Blvd, Ermita, Manila, 1000 Metro Manila, Republic of the Philippines\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9fbc2cc2-39c6-4570-9cb5-55664e44cdc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defaults to match if no countries are provided\n",
    "parse_match_address_country(\n",
    "    \"100 King St W, Toronto, ON M5X 1A9\",\n",
    "    \"100 King St W, Toronto, ON M5X 1A9\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "27403f50-900b-44c0-bae0-58ed27ccd3ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defaults to match if only one address has country\n",
    "parse_match_address_country(\n",
    "    \"100 King St W, Toronto, ON M5X 1A9\",\n",
    "    \"100 King St W, Toronto, ON M5X 1A9, Canada\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "783b75eb-86ee-4674-928e-474e00e7e2a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify mismatch\n",
    "parse_match_address_country(\n",
    "    \"Bosque de Chapultepec I Secc, Miguel Hidalgo, 11850 Ciudad de México, CDMX, Mexico\",\n",
    "    \"Bosque de Chapultepec I Secc, Miguel Hidalgo, 11850 Ciudad de México, CDMX, USA\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86d1fc4-a574-480c-a9fe-1bc119f12f97",
   "metadata": {},
   "source": [
    "### Gold Label Validation\n",
    "\n",
    "We need to evaluate this new method against our gold labeled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "54e2ef9f-b652-43f9-9f27-4a1b58bebea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_match_country(row: pd.Series) -> pd.Series:\n",
    "    \"\"\"parse_match Strict address matching\"\"\"\n",
    "    return parse_match_address_country(row[\"Address1\"], row[\"Address2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c6ad7b4b-1f33-499e-8a84-d62f32b6635f",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df, grouped_df = gold_label_report(gold_df, [strict_parse_match, parse_match_country])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f5c5d0a1-222a-4eba-8387-206ab6e30d57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>strict_parse_match_acc</th>\n",
       "      <th>parse_match_country_acc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Description</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Abbreviated street type for same address should match</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Abbreviated vs. full street names for same address should match</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Addition of parenthetical details for same address should match</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adjacent or nearby building numbers means different address</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Close numerical variants are different addresses</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Typographical errors in city of same address should match</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Typographical errors in same address with country should match</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Typographical errors in street name of same address should match</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Variant format of same address should match</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Variant formats of same address should match</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    strict_parse_match_acc  \\\n",
       "Description                                                                  \n",
       "Abbreviated street type for same address should...                     0.0   \n",
       "Abbreviated vs. full street names for same addr...                     0.0   \n",
       "Addition of parenthetical details for same addr...                     0.0   \n",
       "Adjacent or nearby building numbers means diffe...                     0.0   \n",
       "Close numerical variants are different addresses                       0.0   \n",
       "...                                                                    ...   \n",
       "Typographical errors in city of same address sh...                     1.0   \n",
       "Typographical errors in same address with count...                     1.0   \n",
       "Typographical errors in street name of same add...                     0.0   \n",
       "Variant format of same address should match                            0.0   \n",
       "Variant formats of same address should match                           0.0   \n",
       "\n",
       "                                                    parse_match_country_acc  \n",
       "Description                                                                  \n",
       "Abbreviated street type for same address should...                      0.0  \n",
       "Abbreviated vs. full street names for same addr...                      0.0  \n",
       "Addition of parenthetical details for same addr...                      0.0  \n",
       "Adjacent or nearby building numbers means diffe...                      0.0  \n",
       "Close numerical variants are different addresses                        0.0  \n",
       "...                                                                     ...  \n",
       "Typographical errors in city of same address sh...                      0.5  \n",
       "Typographical errors in same address with count...                      0.0  \n",
       "Typographical errors in street name of same add...                      0.0  \n",
       "Variant format of same address should match                             0.0  \n",
       "Variant formats of same address should match                            0.0  \n",
       "\n",
       "[59 rows x 2 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "51b8a76c-ede2-44dd-b50c-94765ee65fc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total accurate matches for strict_parse_match: 46\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Address1</th>\n",
       "      <th>Address2</th>\n",
       "      <th>Label</th>\n",
       "      <th>strict_parse_match</th>\n",
       "      <th>strict_parse_match_correct</th>\n",
       "      <th>parse_match_country</th>\n",
       "      <th>parse_match_country_correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Adjacent or nearby building numbers means diff...</td>\n",
       "      <td>4800 Oak Street, Kansas City, MO 64112</td>\n",
       "      <td>4800 W Oak Street, Kansas City, MO 64112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Close numerical variants are different addresses</td>\n",
       "      <td>75 West 50th Street, New York, NY 10112</td>\n",
       "      <td>50 West 75th Street, New York, NY 10023</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Completely different addresses that don't match</td>\n",
       "      <td>110 Sejong-daero, Jung-gu, Seoul, South Korea</td>\n",
       "      <td>Avenue Colonel Mondjiba 372, Kinshasa, Gombe, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Completely different addresses that don't match</td>\n",
       "      <td>Rue de la Loi 175, 1040 Brussels</td>\n",
       "      <td>1 Macquarie Street, Sydney, NSW 2000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Different addresses in the same country that d...</td>\n",
       "      <td>1234 Manor Plaza, Pacifica, CA 94044</td>\n",
       "      <td>1234 Bly Manor, Pacific Heights, WA 98003</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Similar road names can be different addresses</td>\n",
       "      <td>Běijīng Shì Cháoyáng Qū Cháoyángmén Wài Dàjiē ...</td>\n",
       "      <td>Běijīng Shì Cháoyáng Qū Cháoyángmén Nèi Dàjiē ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Similar road names can be different addresses</td>\n",
       "      <td>北京市朝阳区朝阳门外大街6号</td>\n",
       "      <td>北京市朝阳区朝阳门内大街6号</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Similar street names with different directions...</td>\n",
       "      <td>200 1st Ave, Seattle, WA 98109</td>\n",
       "      <td>200 1st Ave N, Seattle, WA 98109</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Street type variations means different address</td>\n",
       "      <td>456 Elm St, Springfield, IL 62704</td>\n",
       "      <td>456 Elm Rd, Springfield, IL 62704</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Typographical errors in city of same address s...</td>\n",
       "      <td>16 Rue de la Paix, 75002 Paris, France</td>\n",
       "      <td>16 Rue de la Paix, 75002 Pariss, France</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Description  \\\n",
       "0   Adjacent or nearby building numbers means diff...   \n",
       "1    Close numerical variants are different addresses   \n",
       "2     Completely different addresses that don't match   \n",
       "3     Completely different addresses that don't match   \n",
       "4   Different addresses in the same country that d...   \n",
       "..                                                ...   \n",
       "41      Similar road names can be different addresses   \n",
       "42      Similar road names can be different addresses   \n",
       "43  Similar street names with different directions...   \n",
       "44     Street type variations means different address   \n",
       "45  Typographical errors in city of same address s...   \n",
       "\n",
       "                                             Address1  \\\n",
       "0              4800 Oak Street, Kansas City, MO 64112   \n",
       "1             75 West 50th Street, New York, NY 10112   \n",
       "2       110 Sejong-daero, Jung-gu, Seoul, South Korea   \n",
       "3                    Rue de la Loi 175, 1040 Brussels   \n",
       "4                1234 Manor Plaza, Pacifica, CA 94044   \n",
       "..                                                ...   \n",
       "41  Běijīng Shì Cháoyáng Qū Cháoyángmén Wài Dàjiē ...   \n",
       "42                                     北京市朝阳区朝阳门外大街6号   \n",
       "43                     200 1st Ave, Seattle, WA 98109   \n",
       "44                  456 Elm St, Springfield, IL 62704   \n",
       "45             16 Rue de la Paix, 75002 Paris, France   \n",
       "\n",
       "                                             Address2  Label  \\\n",
       "0            4800 W Oak Street, Kansas City, MO 64112      0   \n",
       "1             50 West 75th Street, New York, NY 10023      0   \n",
       "2   Avenue Colonel Mondjiba 372, Kinshasa, Gombe, ...      0   \n",
       "3                1 Macquarie Street, Sydney, NSW 2000      0   \n",
       "4           1234 Bly Manor, Pacific Heights, WA 98003      0   \n",
       "..                                                ...    ...   \n",
       "41  Běijīng Shì Cháoyáng Qū Cháoyángmén Nèi Dàjiē ...      0   \n",
       "42                                     北京市朝阳区朝阳门内大街6号      0   \n",
       "43                   200 1st Ave N, Seattle, WA 98109      0   \n",
       "44                  456 Elm Rd, Springfield, IL 62704      0   \n",
       "45            16 Rue de la Paix, 75002 Pariss, France      1   \n",
       "\n",
       "    strict_parse_match  strict_parse_match_correct  parse_match_country  \\\n",
       "0                    0                        True                    0   \n",
       "1                    0                        True                    0   \n",
       "2                    0                        True                    0   \n",
       "3                    0                        True                    0   \n",
       "4                    0                        True                    0   \n",
       "..                 ...                         ...                  ...   \n",
       "41                   0                        True                    0   \n",
       "42                   0                        True                    0   \n",
       "43                   0                        True                    0   \n",
       "44                   0                        True                    0   \n",
       "45                   1                        True                    1   \n",
       "\n",
       "    parse_match_country_correct  \n",
       "0                          True  \n",
       "1                          True  \n",
       "2                          True  \n",
       "3                          True  \n",
       "4                          True  \n",
       "..                          ...  \n",
       "41                         True  \n",
       "42                         True  \n",
       "43                         True  \n",
       "44                         True  \n",
       "45                         True  \n",
       "\n",
       "[46 rows x 8 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_df = raw_df[raw_df[\"parse_match_country_correct\"]]\n",
    "print(f\"Total accurate matches for strict_parse_match: {len(true_df):,}\")\n",
    "\n",
    "true_df.sort_values(by=\"Description\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d2f1119a-c9a8-40d1-8253-856b5495d712",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total mismatches for strict_parse_match: 30\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Description</th>\n",
       "      <th>Address1</th>\n",
       "      <th>Address2</th>\n",
       "      <th>Label</th>\n",
       "      <th>strict_parse_match</th>\n",
       "      <th>strict_parse_match_correct</th>\n",
       "      <th>parse_match_country</th>\n",
       "      <th>parse_match_country_correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abbreviated street type for same address shoul...</td>\n",
       "      <td>10200 NE 12th St, Bellevue, WA 98003</td>\n",
       "      <td>10200 NE 12th Street, Bellevue, WA 98003</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abbreviated vs. full street names for same add...</td>\n",
       "      <td>123 Main St, Springfield, IL</td>\n",
       "      <td>123 Main Street, Springfield, IL</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Addition of parenthetical details for same add...</td>\n",
       "      <td>Building 4 (East Wing), 123 Tech Park, Silicon...</td>\n",
       "      <td>Building 4, 123 Tech Park, Silicon Valley, CA ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Common misspellings for same address should match</td>\n",
       "      <td>1600 Pennsylvna Ave NW, Washington, DC 20500</td>\n",
       "      <td>1600 Pennsylvania Avenue NW, Washington, DC 20500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Common typographical errors in same address sh...</td>\n",
       "      <td>北京市东城区东长安街1号, 中国</td>\n",
       "      <td>北京市东城区东长安街1号, 中囯</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Typographical errors in street name of same ad...</td>\n",
       "      <td>1600 Amphitheatre Parkway, Mountain View, CA</td>\n",
       "      <td>1600 Amptheatre Parkway, Mountain View, CA</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Variant format of same address should match</td>\n",
       "      <td>350 Fifth Avenue, New York, NY 10118</td>\n",
       "      <td>Empire State Bldg, 350 5th Ave, NY, NY 10118</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Variant format of same address should match</td>\n",
       "      <td>Çırağan Caddesi No: 32, 34349 Beşiktaş, Istanb...</td>\n",
       "      <td>Ciragan Palace Hotel, Ciragan Street 32, Besik...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Variant formats of same address should match</td>\n",
       "      <td>上海市黄浦区南京东路318号</td>\n",
       "      <td>上海黄浦南京东路318号</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Variant formats of same address should match</td>\n",
       "      <td>Shànghǎi Shì Huángpǔ Qū Nánjīng Dōng Lù 318 Hào</td>\n",
       "      <td>Shànghǎi Huángpǔ Nánjīng Dōng Lù 318 Hào</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Description  \\\n",
       "0   Abbreviated street type for same address shoul...   \n",
       "1   Abbreviated vs. full street names for same add...   \n",
       "2   Addition of parenthetical details for same add...   \n",
       "3   Common misspellings for same address should match   \n",
       "4   Common typographical errors in same address sh...   \n",
       "..                                                ...   \n",
       "25  Typographical errors in street name of same ad...   \n",
       "26        Variant format of same address should match   \n",
       "27        Variant format of same address should match   \n",
       "28       Variant formats of same address should match   \n",
       "29       Variant formats of same address should match   \n",
       "\n",
       "                                             Address1  \\\n",
       "0                10200 NE 12th St, Bellevue, WA 98003   \n",
       "1                        123 Main St, Springfield, IL   \n",
       "2   Building 4 (East Wing), 123 Tech Park, Silicon...   \n",
       "3        1600 Pennsylvna Ave NW, Washington, DC 20500   \n",
       "4                                    北京市东城区东长安街1号, 中国   \n",
       "..                                                ...   \n",
       "25       1600 Amphitheatre Parkway, Mountain View, CA   \n",
       "26               350 Fifth Avenue, New York, NY 10118   \n",
       "27  Çırağan Caddesi No: 32, 34349 Beşiktaş, Istanb...   \n",
       "28                                     上海市黄浦区南京东路318号   \n",
       "29    Shànghǎi Shì Huángpǔ Qū Nánjīng Dōng Lù 318 Hào   \n",
       "\n",
       "                                             Address2  Label  \\\n",
       "0            10200 NE 12th Street, Bellevue, WA 98003      1   \n",
       "1                    123 Main Street, Springfield, IL      1   \n",
       "2   Building 4, 123 Tech Park, Silicon Valley, CA ...      1   \n",
       "3   1600 Pennsylvania Avenue NW, Washington, DC 20500      1   \n",
       "4                                    北京市东城区东长安街1号, 中囯      1   \n",
       "..                                                ...    ...   \n",
       "25         1600 Amptheatre Parkway, Mountain View, CA      1   \n",
       "26       Empire State Bldg, 350 5th Ave, NY, NY 10118      1   \n",
       "27  Ciragan Palace Hotel, Ciragan Street 32, Besik...      1   \n",
       "28                                       上海黄浦南京东路318号      1   \n",
       "29           Shànghǎi Huángpǔ Nánjīng Dōng Lù 318 Hào      1   \n",
       "\n",
       "    strict_parse_match  strict_parse_match_correct  parse_match_country  \\\n",
       "0                    0                       False                    0   \n",
       "1                    0                       False                    0   \n",
       "2                    0                       False                    0   \n",
       "3                    0                       False                    0   \n",
       "4                    0                       False                    0   \n",
       "..                 ...                         ...                  ...   \n",
       "25                   0                       False                    0   \n",
       "26                   0                       False                    0   \n",
       "27                   0                       False                    0   \n",
       "28                   0                       False                    0   \n",
       "29                   0                       False                    0   \n",
       "\n",
       "    parse_match_country_correct  \n",
       "0                         False  \n",
       "1                         False  \n",
       "2                         False  \n",
       "3                         False  \n",
       "4                         False  \n",
       "..                          ...  \n",
       "25                        False  \n",
       "26                        False  \n",
       "27                        False  \n",
       "28                        False  \n",
       "29                        False  \n",
       "\n",
       "[30 rows x 8 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "false_df = raw_df[raw_df[\"parse_match_country_correct\"] == False]\n",
    "print(f\"Total mismatches for strict_parse_match: {len(false_df):,}\")\n",
    "\n",
    "false_df.sort_values(by=\"Description\").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7aa526-33e4-4705-a453-585ab7f3869a",
   "metadata": {},
   "source": [
    "# Machine Learning Approaches to Address Matching\n",
    "\n",
    "In this section we pursue two machine learning approaches to address matching, in order of sophistication. First we fine-tune a pre-trained embedding model to our task, try it on our data and search for a threshold similarity that results in good performance for our address matching problem. Second we build a Siamese BERT network model based on [Sentence-BERT](https://arxiv.org/abs/1908.10084) to classify pairs of addresses as match or mismatch. We will train it using the same dataset we use to fine-tune a sentence transformer, and if we have enough training data this will likely be a more powerful approach.\n",
    "\n",
    "## Text Embeddings, Sentence Encoding, `SentenceTransformers`, Vector Distance and Cosine Similarity\n",
    "\n",
    "Text embeddings are trained on large volumes of text that include addresses. As a result they have some understanding of address strings and can do a form of semantic comparison that is less explicit than logical comparisons with address parsing. They're an important benchmark to explore. Huggingface has an excellent [introduction to sentence similarity](https://huggingface.co/tasks/sentence-similarity).\n",
    "\n",
    "In our first machine learning approach, we are going to use transfer learning to load a pre-trained [sentence transformer](https://sbert.net) models from huggingface. We will use the training data we've prepared to fine-tune this model to our task, before rigorously evaluating it along with our other approaches.\n",
    "\n",
    "Sentence transformers sentence encode strings of different distances into fixed-length vectors, a technique called sentence encoding. Once two address strings are embedded into a pair of equal length vectors, they can be compared with cosine similarity to get a distance, the inverse of which is a similarity score.\n",
    "\n",
    "### Convert our `pd.DataFrame` to a `List[sentence_transformers.InputExample]`\n",
    "\n",
    "First we need to convert our Pandas `DataFrame` to a list of sentence transformer input examples. `InputExamples` require two fields `texts=List[str, str]` and `label`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7b105924-4872-4abf-a10c-4d77150f1b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data:   3,928\n",
      "Validation data: 491\n",
      "Test data        491\n"
     ]
    }
   ],
   "source": [
    "train_df, tmp_df = train_test_split(augment_results_df, test_size=0.2, shuffle=True)\n",
    "eval_df, test_df = train_test_split(tmp_df, test_size=0.5, random_state=42, shuffle=True)\n",
    "\n",
    "train_dataset = Dataset.from_dict({\n",
    "    \"sentence1\": train_df[\"Address1\"].tolist(),\n",
    "    \"sentence2\": train_df[\"Address2\"].tolist(),\n",
    "    \"label\": train_df[\"Label\"].tolist(),\n",
    "})\n",
    "\n",
    "eval_dataset = Dataset.from_dict({\n",
    "    \"sentence1\": eval_df[\"Address1\"].tolist(),\n",
    "    \"sentence2\": eval_df[\"Address2\"].tolist(),\n",
    "    \"label\": eval_df[\"Label\"].tolist(),\n",
    "})\n",
    "\n",
    "test_dataset = Dataset.from_dict({\n",
    "    \"sentence1\": test_df[\"Address1\"].tolist(),\n",
    "    \"sentence2\": test_df[\"Address2\"].tolist(),\n",
    "    \"label\": test_df[\"Label\"].tolist(),\n",
    "})\n",
    "\n",
    "print(f\"Training data:   {len(train_df):,}\")\n",
    "print(f\"Validation data: {len(eval_df):,}\")\n",
    "print(f\"Test data        {len(eval_df):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680e51e3-84d0-40e5-97d1-ebce61cd9514",
   "metadata": {},
   "source": [
    "### Configure Fine-Tuning, Initialize a `SentenceTransformer`\n",
    "\n",
    "To use the training data we prepared to fine-tune a `SentenceTransformer`, we need to select and load a pre-trained model from Huggingface Hub. Here are some models you can try:\n",
    "\n",
    "* [sentence-transformers/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2](https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2) - multilingual paraphrase models are designed to compare sentences in terms of their semantics.\n",
    "* [BAAI/bge-m3](https://huggingface.co/BAAI/bge-m3) - a robust, multilingual model optimized for a variety of tasks\n",
    "* [sentence-transformers/paraphrase-multilingual-mpnet-base-v2](https://huggingface.co/sentence-transformers/paraphrase-multilingual-mpnet-base-v2) - MPNet is another paraphrase model architecture we can fine-tune for address comparison\n",
    "* [sentence-transformers/all-mpnet-base-v2](https://huggingface.co/sentence-transformers/all-mpnet-base-v2) - a top performing MPNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "15a2a181-a9cd-469f-9b1b-32b9d3163dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "SBERT_MODEL = \"paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "VARIANT = \"original\"\n",
    "MODEL_SAVE_NAME = (SBERT_MODEL + \"-\" + VARIANT).replace(\"/\", \"-\")\n",
    "\n",
    "EPOCHS = 12\n",
    "BATCH_SIZE = 32\n",
    "PATIENCE = 2\n",
    "LEARNING_RATE = .00005\n",
    "DATASET_MULTIPLE = CLONES_PER_RUN * RUNS_PER_EXAMPLE\n",
    "SBERT_OUTPUT_FOLDER = f\"data/fine-tuned-sbert-{MODEL_SAVE_NAME}\"\n",
    "SAVE_EVAL_STEPS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e174e134-4761-4732-a2f7-98a5a785155c",
   "metadata": {},
   "source": [
    "### Initialize Weights & Biases\n",
    "\n",
    "Weights and biases `wandb` package makes it simple to monitor the performance of your training runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d68f7a53-d09a-4e8b-b5e9-f62857c12e4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.17.2 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/rjurney/Software/libpostal-reborn/wandb/run-20240620_223202-2nnj51ft</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rjurney/libpostal-reborn/runs/2nnj51ft' target=\"_blank\">silver-butterfly-47</a></strong> to <a href='https://wandb.ai/rjurney/libpostal-reborn' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rjurney/libpostal-reborn' target=\"_blank\">https://wandb.ai/rjurney/libpostal-reborn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rjurney/libpostal-reborn/runs/2nnj51ft' target=\"_blank\">https://wandb.ai/rjurney/libpostal-reborn/runs/2nnj51ft</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/rjurney/libpostal-reborn/runs/2nnj51ft?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x4383cb990>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize Weights & Biases\n",
    "wandb.init(\n",
    "    entity=\"rjurney\",\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"libpostal-reborn\",\n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "        \"variant\": VARIANT,\n",
    "        \"dataset_multiple\": DATASET_MULTIPLE,\n",
    "        \"epochs\": EPOCHS,\n",
    "        \"batch_size\": BATCH_SIZE,\n",
    "        \"patience\": PATIENCE,\n",
    "        \"learning_rate\": LEARNING_RATE,\n",
    "        \"sbert_model\": SBERT_MODEL,\n",
    "        \"sbert_output_folder\": SBERT_OUTPUT_FOLDER,\n",
    "        \"save_eval_steps\": SAVE_EVAL_STEPS,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0f82a6-1fb7-45fe-b468-9df611413f1e",
   "metadata": {},
   "source": [
    "### Setup our `SentenceTransformer` Model\n",
    "\n",
    "Choose the model to fine-tune above in `SBERT_MODEL` and instantiate it below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2e40fb24-77a6-4291-b0c5-076f8a9997d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbert_model = SentenceTransformer(\n",
    "    SBERT_MODEL,\n",
    "    device=device,\n",
    "    model_card_data=SentenceTransformerModelCardData(\n",
    "        language=\"en\",\n",
    "        license=\"apache-2.0\",\n",
    "        model_name=f\"{SBERT_MODEL}-address-matcher-{VARIANT}\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7285812b-dde6-4af0-b0d0-f3ed7c777a51",
   "metadata": {},
   "source": [
    "### Evaluate our Model Before Fine-Tuning\n",
    "\n",
    "Let's see what it can do without fine-tuning, then we'll compare our subjective results afterwards. This won't work very well, fine-tuning is required!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2bd45043-cac4-47d1-af34-c80fbac09e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sbert_compare(address1: str, address2: str) -> float:\n",
    "    \"\"\"sbert_compare - sentence encode each address into a fixed-length text embedding.\n",
    "    Fixed-length means they can be compared with cosine similarity.\"\"\"\n",
    "    embedding1 = sbert_model.encode(address1)\n",
    "    embedding2 = sbert_model.encode(address2)\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    return 1 - distance.cosine(embedding1, embedding2)\n",
    "\n",
    "\n",
    "def sbert_match(row: pd.Series) -> pd.Series:\n",
    "    \"\"\"sbert_match - SentenceTransformer address matching, float iytoyt\"\"\"\n",
    "    return sbert_compare(row[\"Address1\"], row[\"Address2\"])\n",
    "\n",
    "\n",
    "def sbert_compare_binary(address1: str, address2: str, threshold: float = 0.5) -> Literal[0, 1]:\n",
    "    \"\"\"sbert_match - compare and return a binary match\"\"\"\n",
    "    similarity = sbert_compare(address1, address2)\n",
    "    return 1 if similarity >= threshold else 0\n",
    "\n",
    "\n",
    "def sbert_match_binary(row: pd.Series, threshold: float = 0.5) -> pd.Series:\n",
    "    \"\"\"sbert_match_binary - SentenceTransformer address matching, binary output\"\"\"\n",
    "    return sbert_compare_binary(row[\"Address1\"], row[\"Address2\"], threshold=threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b083ad79-6b50-414f-83de-a3ae68f44c77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9887310599046897"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Still too similar - very hard to train them away from this behavior!\n",
    "sbert_compare(\n",
    "    \"101 Oak Lane, Atlanta, GA 30308\",\n",
    "    \"102 Oak Lane, Atlanta, GA 30308\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a65dad9f-3f08-439d-8ee8-2b14b740a55f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9080112054372381"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A little bit further away ...\n",
    "sbert_compare(\n",
    "    \"101 Oak Lane, Atlanta, GA 30308\",\n",
    "    \"101 Oak Ln., Atlanta, GA 30308\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f869c21a-8b41-4520-87bd-7dbc8d37d1b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7771668960380212"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Properly distant ...\n",
    "sbert_compare(\n",
    "    \"3413 Sean Way, Lawrenceville, GA 30044\",\n",
    "    \"1202 Oak Rd., Lawrenceville, GA 30304\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b7aba7fb-a560-4869-b05d-414a03a34542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9754176576820044"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Properly similar ...\n",
    "sbert_compare(\n",
    "    \"3413 Sean Way, Lawrenceville, GA 30044\",\n",
    "    \"3413 Sean Way, Lawrenceville, GA 30044, USA\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a0a9d8-8c06-45dd-9ff4-7b056e078e5a",
   "metadata": {},
   "source": [
    "### Evaluate the Test Set with the Untrained Model\n",
    "\n",
    "Let's see how well the [paraphrase-multilingual-MiniLM-L12-v2](https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2) model does on its own. This is our baseline score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "04e9a873-9044-443b-9741-3ab3fed0a154",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'paraphrase-multilingual-MiniLM-L12-v2_cosine_accuracy': 0.5723014256619144,\n",
       " 'paraphrase-multilingual-MiniLM-L12-v2_cosine_accuracy_threshold': 0.919810950756073,\n",
       " 'paraphrase-multilingual-MiniLM-L12-v2_cosine_f1': 0.6905444126074499,\n",
       " 'paraphrase-multilingual-MiniLM-L12-v2_cosine_f1_threshold': 0.588857889175415,\n",
       " 'paraphrase-multilingual-MiniLM-L12-v2_cosine_precision': 0.5320088300220751,\n",
       " 'paraphrase-multilingual-MiniLM-L12-v2_cosine_recall': 0.9836734693877551,\n",
       " 'paraphrase-multilingual-MiniLM-L12-v2_cosine_ap': 0.5530223235852731,\n",
       " 'paraphrase-multilingual-MiniLM-L12-v2_dot_accuracy': 0.6415478615071283,\n",
       " 'paraphrase-multilingual-MiniLM-L12-v2_dot_accuracy_threshold': 20.265094757080078,\n",
       " 'paraphrase-multilingual-MiniLM-L12-v2_dot_f1': 0.6801152737752162,\n",
       " 'paraphrase-multilingual-MiniLM-L12-v2_dot_f1_threshold': 13.856237411499023,\n",
       " 'paraphrase-multilingual-MiniLM-L12-v2_dot_precision': 0.5256124721603563,\n",
       " 'paraphrase-multilingual-MiniLM-L12-v2_dot_recall': 0.963265306122449,\n",
       " 'paraphrase-multilingual-MiniLM-L12-v2_dot_ap': 0.7064934753406598,\n",
       " 'paraphrase-multilingual-MiniLM-L12-v2_manhattan_accuracy': 0.5743380855397149,\n",
       " 'paraphrase-multilingual-MiniLM-L12-v2_manhattan_accuracy_threshold': 60.32664489746094,\n",
       " 'paraphrase-multilingual-MiniLM-L12-v2_manhattan_f1': 0.6984126984126984,\n",
       " 'paraphrase-multilingual-MiniLM-L12-v2_manhattan_f1_threshold': 61.2036018371582,\n",
       " 'paraphrase-multilingual-MiniLM-L12-v2_manhattan_precision': 0.5401785714285714,\n",
       " 'paraphrase-multilingual-MiniLM-L12-v2_manhattan_recall': 0.9877551020408163,\n",
       " 'paraphrase-multilingual-MiniLM-L12-v2_manhattan_ap': 0.5377863898568034,\n",
       " 'paraphrase-multilingual-MiniLM-L12-v2_euclidean_accuracy': 0.5763747454175153,\n",
       " 'paraphrase-multilingual-MiniLM-L12-v2_euclidean_accuracy_threshold': 3.8208060264587402,\n",
       " 'paraphrase-multilingual-MiniLM-L12-v2_euclidean_f1': 0.7002881844380404,\n",
       " 'paraphrase-multilingual-MiniLM-L12-v2_euclidean_f1_threshold': 3.953191041946411,\n",
       " 'paraphrase-multilingual-MiniLM-L12-v2_euclidean_precision': 0.5412026726057907,\n",
       " 'paraphrase-multilingual-MiniLM-L12-v2_euclidean_recall': 0.9918367346938776,\n",
       " 'paraphrase-multilingual-MiniLM-L12-v2_euclidean_ap': 0.5383699611315687,\n",
       " 'paraphrase-multilingual-MiniLM-L12-v2_max_accuracy': 0.6415478615071283,\n",
       " 'paraphrase-multilingual-MiniLM-L12-v2_max_accuracy_threshold': 60.32664489746094,\n",
       " 'paraphrase-multilingual-MiniLM-L12-v2_max_f1': 0.7002881844380404,\n",
       " 'paraphrase-multilingual-MiniLM-L12-v2_max_f1_threshold': 61.2036018371582,\n",
       " 'paraphrase-multilingual-MiniLM-L12-v2_max_precision': 0.5412026726057907,\n",
       " 'paraphrase-multilingual-MiniLM-L12-v2_max_recall': 0.9918367346938776,\n",
       " 'paraphrase-multilingual-MiniLM-L12-v2_max_ap': 0.7064934753406598}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the evaluator\n",
    "binary_acc_evaluator = BinaryClassificationEvaluator(\n",
    "    sentences1=eval_dataset[\"sentence1\"],\n",
    "    sentences2=eval_dataset[\"sentence2\"],\n",
    "    labels=eval_dataset[\"label\"],\n",
    "    name=SBERT_MODEL,\n",
    ")\n",
    "binary_acc_evaluator(sbert_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d22615-249a-4ee7-b7c5-43fb1cada980",
   "metadata": {},
   "source": [
    "### Computing Metrics with `sklearn.metrics`\n",
    "\n",
    "We use [scikit-learn metrics](https://scikit-learn.org/stable/modules/model_evaluation.html) instead to compute our evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "31111f8e-0167-4a6b-abff-dc3ecf391687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will rapidly train the embedding model. MultipleNegativesRankingLoss did not work.\n",
    "loss = losses.ContrastiveLoss(model=sbert_model)\n",
    "\n",
    "sbert_args = SentenceTransformerTrainingArguments(\n",
    "    output_dir=SBERT_OUTPUT_FOLDER,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    warmup_ratio=0.1,\n",
    "    run_name=SBERT_MODEL,\n",
    "    load_best_model_at_end=True,\n",
    "    save_steps=SAVE_EVAL_STEPS,\n",
    "    eval_steps=SAVE_EVAL_STEPS,\n",
    "    save_strategy=\"steps\",\n",
    "    eval_strategy=\"steps\",\n",
    "    greater_is_better=False,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    learning_rate=LEARNING_RATE,\n",
    ")\n",
    "\n",
    "trainer = SentenceTransformerTrainer(\n",
    "    model=sbert_model,\n",
    "    args=sbert_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    loss=loss,\n",
    "    evaluator=binary_acc_evaluator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=PATIENCE)],\n",
    ")\n",
    "\n",
    "trainer.evaluate()\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0340162d-e84f-496b-bc8c-f730d327205f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f52923-5fc9-4e0c-8e5d-d2cb21d68246",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ad1454-2902-483b-9500-63456cfa5e8d",
   "metadata": {},
   "source": [
    "### Try the Model from Our Best Epoch\n",
    "\n",
    "We fine-tuned the model for `EPOCHS` nubmer of epochs, but the last epoch isn't always best. The `TrainingArgument` `load_best_model_at_end=True` loads the model at the end.\n",
    "\n",
    "Another way to load the best model is to load our output folder and evaluate that `SentenceTransformer` on some examples to get a gestalt sense for its performance.\n",
    "\n",
    "```python\n",
    "sbert_model = SentenceTransformer(OUTPUT_FOLDER, device=device)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f2c9c5-5f70-4f13-8b3a-8e24d8509872",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbert_compare(\n",
    "    \"101 Oak Lane, Atlanta, GA 30308\",\n",
    "    \"102 Oak Lane, Atlanta, GA 30308\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246f35ba-5e5f-4801-a5dd-e0b54bc34d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbert_compare(\n",
    "    \"101 Oak Lane, Macon, GA 30308\",\n",
    "    \"101 Oak Lane, Atlanta, GA 30408\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96ef967-0c99-4301-9c2c-6909360566e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbert_compare(\n",
    "    \"101 Oak Lane, Atlanta, GA 30308\",\n",
    "    \"101 Oak Ln., Atlanta, GA 30308\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76eb3771-17c6-4d85-9bad-8615c1eb8db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbert_compare(\n",
    "    \"3413 Sean Way, Lawrenceville, GA 30044\",\n",
    "    \"1202 Oak Rd., Lawrenceville, GA 30304\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c78fd25-be01-4052-b717-6471730d92ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbert_compare(\n",
    "    \"3413 Sean Way, Lawrenceville, GA 30044\",\n",
    "    \"3413 Sean Way, Lawrenceville, GA 30044, USA\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441a2b8b-2525-4c7c-98c0-6a65f69661b0",
   "metadata": {},
   "source": [
    "### Evaluate ROC Curve to Determine Optimum Similarity Threshold\n",
    "\n",
    "0.5 is an arbitrary line on which to divide positive (match, 1) and negative (mismatch, 0). Let's evaluate the ROC Curve of the F1 score to see what it should be set to. Recall that the `sbert_match` function has a `threshold: float = 0.5` argument.\n",
    "\n",
    "#### Evaluate on our Augmented Test Dataset\n",
    "\n",
    "First we'll evaluate the ROC curve on our augmented test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53242e2-7ce0-4c00-853f-277ba98b6317",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = test_df[\"Label\"]\n",
    "y_scores = test_df.apply(sbert_match, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecb6dc8-528b-4680-9794-5da506b02502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute precision-recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_true, y_scores)\n",
    "\n",
    "# Compute F1 score for each threshold\n",
    "f1_scores = [f1_score(y_true, y_scores >= t) for t in thresholds]\n",
    "\n",
    "# Find the threshold that maximizes the F1 score\n",
    "best_threshold_index = np.argmax(f1_scores)\n",
    "best_threshold = thresholds[best_threshold_index]\n",
    "best_f1_score = f1_scores[best_threshold_index]\n",
    "\n",
    "print(f'Best Threshold: {best_threshold}')\n",
    "print(f'Best F1 Score: {best_f1_score}')\n",
    "\n",
    "roc_auc = roc_auc_score(y_true, y_scores)\n",
    "print(f'AUC-ROC: {roc_auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737566a7-4902-468f-b87e-585650d484fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame for Seaborn\n",
    "pr_data = pd.DataFrame({\n",
    "    'Precision': precision[:-1],\n",
    "    'Recall': recall[:-1],\n",
    "    'F1 Score': f1_scores\n",
    "})\n",
    "\n",
    "# Plot Precision-Recall curve using Seaborn\n",
    "sns.lineplot(data=pr_data, x='Recall', y='Precision', marker='o')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Augmented Test Set Precision-Recall Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f50818-d35c-43b9-b022-9746ce96cdc2",
   "metadata": {},
   "source": [
    "### Plot a ROC Curve for our Gold Labeled Data\n",
    "\n",
    "We need to see the ROC Curve for our gold labeled data as well. We care more about performance on this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3eae08-beef-419a-bb8a-ffe74fae4cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = gold_df[\"Label\"]\n",
    "y_scores = gold_df.apply(sbert_match, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bfde9f-9610-4b47-88d6-4432d5081f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute precision-recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_true, y_scores)\n",
    "\n",
    "# Compute F1 score for each threshold\n",
    "f1_scores = [f1_score(y_true, y_scores >= t) for t in thresholds]\n",
    "\n",
    "# Find the threshold that maximizes the F1 score\n",
    "best_threshold_index = np.argmax(f1_scores)\n",
    "best_threshold = thresholds[best_threshold_index]\n",
    "best_f1_score = f1_scores[best_threshold_index]\n",
    "\n",
    "print(f'Best Threshold: {best_threshold}')\n",
    "print(f'Best F1 Score: {best_f1_score}')\n",
    "\n",
    "roc_auc = roc_auc_score(y_true, y_scores)\n",
    "print(f'AUC-ROC: {roc_auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe142c8-8b4b-4384-be50-4e77413fd40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame for Seaborn\n",
    "pr_data = pd.DataFrame({\n",
    "    'Precision': precision[:-1],\n",
    "    'Recall': recall[:-1],\n",
    "    'F1 Score': f1_scores\n",
    "})\n",
    "\n",
    "# Plot Precision-Recall curve using Seaborn\n",
    "sns.lineplot(data=pr_data, x='Recall', y='Precision', marker='o')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Gold Label Precision-Recall Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768d6185-8345-4460-82fc-654fd63cec04",
   "metadata": {},
   "source": [
    "### Debugging Errors on our Gold Labels\n",
    "\n",
    "Let's evaluate the data using our `gold_label_report` function with the best F1 score. Then we can view the errors and figure out where our model is failing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b16f14-ee29-4e2b-acec-61df4bfe8add",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df, grouped_df = gold_label_report(\n",
    "    gold_df,\n",
    "    [\n",
    "        strict_parse_match,\n",
    "        parse_match_country,\n",
    "        sbert_match_binary,\n",
    "    ],\n",
    "    threshold=best_threshold\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd151a3-f774-45ce-857f-e3d072fc803d",
   "metadata": {},
   "source": [
    "#### Label Description Group Analysis\n",
    "\n",
    "You can see the types of address pairs we are failing on. This can guide our data augmentation / programmatic labeling work at a high level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c954ca92-334d-4d73-98a2-313bbec12c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edae3d6-4085-41d9-bacb-3efde3d48e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df[\"sbert_match_binary_acc\"].sort_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4340fd-af40-4450-bfc1-834bac0851cb",
   "metadata": {},
   "source": [
    "#### What it Got Right ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090a985a-a152-4976-8f57-890e88ef99ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Truthiness analysis\n",
    "correct_df = raw_df[raw_df[\"sbert_match_binary_correct\"]].reset_index()\n",
    "print(f\"Number correct: {len(correct_df):,}\")\n",
    "\n",
    "correct_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d228d188-ed22-42ca-985b-ddd9088ac94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error analysis\n",
    "wrong_df = raw_df[raw_df[\"sbert_match_binary_correct\"] == False].reset_index()\n",
    "print(f\"Number wrong: {len(wrong_df):,}\")\n",
    "\n",
    "wrong_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c299637d-619f-4683-b277-6c8081c4c23c",
   "metadata": {},
   "source": [
    "# Fuzzy, Structured Address Matching with Libpostal and Vector Distance\n",
    "\n",
    "There seems to be merit to both structured and embedding approaches to address matching. Let's see how an approximate approach to matching parsed address components might help."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cebf8f6-2acc-49f7-8500-993b0a405b79",
   "metadata": {},
   "source": [
    "## Combining an Address Parsing and Embedding Approach\n",
    "\n",
    "Libpostal is a powerful parsing model, and it seems like parsing is a logical first step in matching addresses. Some logical combinations of fields should result in a match, while some should not. This logic can be programmed by a human, provided fuzzy matching is available at the field level. `101 Oak Lane` should match `101 Oak Ln` but not `102 Oak Lane`. `street_name` and `street_number` are separate fields in an address parsed by Libpostal. What is we got some machine learning help with field-level matching?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c4d097-22de-4477-b9ed-2e4700888bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbert_compare(\"Oak Lane\", \"Oak Ln.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efde24e4-9963-42eb-a436-2e0964b269f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbert_compare(\"Cheer Lane\", \"Cheer Road\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b6f3a3-5ba2-43e2-81ef-145b9f66a4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbert_compare(\"101\", \"110\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d79ab110-cc3c-4ea7-a5a3-b72dd383e723",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbert_compare(\"5th\", \"Fifth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf32bb3-b165-40d8-ab19-38829a2b1c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbert_compare(\"USA\", \"United States\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f4a121-44b1-4441-8742-a6688c2a96b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbert_compare(\"30044\", \"30308\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0715a288-d141-474a-a5f8-f5cbb7e0bd9a",
   "metadata": {},
   "source": [
    "## Fine-Tuning a Lowercase `SentenceTransformer`\n",
    "\n",
    "My first pass at this method did not work whatsoever - the performance of the matcher was abysmal. This was because Libpostal *lowercases* addresses when it parses them, and I did NOT do that to the training data on a first pass :) Once I did that and retrained below - things worked much better!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aeb24d9-ef8c-4f39-a709-8630c749a809",
   "metadata": {},
   "source": [
    "### Lowercase our Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ef2c3ad6-8418-4fdc-98aa-e4187b648020",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_augment_results_df = augment_results_df.copy(deep=True)\n",
    "\n",
    "lower_augment_results_df[\"Address1\"] = lower_augment_results_df[\"Address1\"].str.lower()\n",
    "lower_augment_results_df[\"Address2\"] = lower_augment_results_df[\"Address2\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5c4cb876-ea2c-4133-a2ee-f4dbb635b132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data:   3,928\n",
      "Validation data: 491\n",
      "Test data        491\n"
     ]
    }
   ],
   "source": [
    "train_df, tmp_df = train_test_split(lower_augment_results_df, test_size=0.2, shuffle=True)\n",
    "eval_df, test_df = train_test_split(tmp_df, test_size=0.5, random_state=42, shuffle=True)\n",
    "\n",
    "train_dataset = Dataset.from_dict({\n",
    "    \"sentence1\": train_df[\"Address1\"].tolist(),\n",
    "    \"sentence2\": train_df[\"Address2\"].tolist(),\n",
    "    \"label\": train_df[\"Label\"].tolist(),\n",
    "})\n",
    "\n",
    "eval_dataset = Dataset.from_dict({\n",
    "    \"sentence1\": eval_df[\"Address1\"].tolist(),\n",
    "    \"sentence2\": eval_df[\"Address2\"].tolist(),\n",
    "    \"label\": eval_df[\"Label\"].tolist(),\n",
    "})\n",
    "\n",
    "test_dataset = Dataset.from_dict({\n",
    "    \"sentence1\": test_df[\"Address1\"].tolist(),\n",
    "    \"sentence2\": test_df[\"Address2\"].tolist(),\n",
    "    \"label\": test_df[\"Label\"].tolist(),\n",
    "})\n",
    "\n",
    "print(f\"Training data:   {len(train_df):,}\")\n",
    "print(f\"Validation data: {len(eval_df):,}\")\n",
    "print(f\"Test data        {len(eval_df):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0af638c-048c-47a1-98bd-bdc670d9f377",
   "metadata": {},
   "outputs": [],
   "source": [
    "SBERT_MODEL = \"paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "VARIANT = \"lowercase\"\n",
    "MODEL_SAVE_NAME = (SBERT_MODEL + \"-\" + VARIANT).replace(\"/\", \"-\")\n",
    "\n",
    "EPOCHS = 12\n",
    "BATCH_SIZE = 32\n",
    "PATIENCE = 2\n",
    "LEARNING_RATE = .00005\n",
    "DATASET_MULTIPLE = CLONES_PER_RUN * RUNS_PER_EXAMPLE\n",
    "SBERT_OUTPUT_FOLDER = f\"data/fine-tuned-sbert-{MODEL_SAVE_NAME}\"\n",
    "SAVE_EVAL_STEPS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450ff10b-99ce-4853-bcd2-37c17e4eb2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Weights & Biases\n",
    "wandb.init(\n",
    "    entity=\"rjurney\",\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"libpostal-reborn\",\n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "        \"variant\": VARIANT,\n",
    "        \"dataset_multiple\": DATASET_MULTIPLE,\n",
    "        \"epochs\": EPOCHS,\n",
    "        \"batch_size\": BATCH_SIZE,\n",
    "        \"patience\": PATIENCE,\n",
    "        \"learning_rate\": LEARNING_RATE,\n",
    "        \"sbert_model\": SBERT_MODEL,\n",
    "        \"sbert_output_folder\": SBERT_OUTPUT_FOLDER,\n",
    "        \"save_eval_steps\": SAVE_EVAL_STEPS,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc7965c-5619-44a2-a07f-9646078db1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbert_model_lower = SentenceTransformer(\n",
    "    SBERT_MODEL,\n",
    "    device=device,\n",
    "    model_card_data=SentenceTransformerModelCardData(\n",
    "        language=\"en\",\n",
    "        license=\"apache-2.0\",\n",
    "        model_name=f\"{SBERT_MODEL}-address-matcher-{VARIANT}\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05ff3a5-111d-4f1b-bdaa-2fc4c5859346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the evaluator\n",
    "binary_acc_evaluator = BinaryClassificationEvaluator(\n",
    "    sentences1=eval_dataset[\"sentence1\"],\n",
    "    sentences2=eval_dataset[\"sentence2\"],\n",
    "    labels=eval_dataset[\"label\"],\n",
    "    name=SBERT_MODEL,\n",
    ")\n",
    "binary_acc_evaluator(sbert_model_lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16800ca1-1f40-40de-9299-f8e88b0ee2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will rapidly train the embedding model. MultipleNegativesRankingLoss did not work.\n",
    "loss = losses.ContrastiveLoss(model=sbert_model_lower)\n",
    "\n",
    "sbert_args = SentenceTransformerTrainingArguments(\n",
    "    output_dir=SBERT_OUTPUT_FOLDER,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    warmup_ratio=0.1,\n",
    "    run_name=SBERT_MODEL,\n",
    "    load_best_model_at_end=True,\n",
    "    save_steps=SAVE_EVAL_STEPS,\n",
    "    eval_steps=SAVE_EVAL_STEPS,\n",
    "    save_strategy=\"steps\",\n",
    "    eval_strategy=\"steps\",\n",
    "    greater_is_better=False,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    learning_rate=LEARNING_RATE,\n",
    ")\n",
    "\n",
    "trainer = SentenceTransformerTrainer(\n",
    "    model=sbert_model_lower,\n",
    "    args=sbert_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    loss=loss,\n",
    "    evaluator=binary_acc_evaluator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=PATIENCE)],\n",
    ")\n",
    "\n",
    "trainer.evaluate()\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0092c331-3ab7-436b-ac7e-0cf0bfd0406c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6739716e-4567-47e7-a49a-87228bc33f3f",
   "metadata": {},
   "source": [
    "### Rewrite our Matchers for Lowercase Duty\n",
    "\n",
    "Need two versions of these to compare the original with their new lowercase cousins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b1761b-001e-4fd8-b61a-7d31686bc9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sbert_compare_lower(address1: str, address2: str) -> float:\n",
    "    \"\"\"sbert_compare - sentence encode each address into a fixed-length text embedding.\n",
    "    Fixed-length means they can be compared with cosine similarity.\"\"\"\n",
    "    embedding1 = sbert_model_lower.encode(address1.lower())\n",
    "    embedding2 = sbert_model_lower.encode(address2.lower())\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    return 1 - distance.cosine(embedding1, embedding2)\n",
    "\n",
    "\n",
    "def sbert_match_lower(row: pd.Series) -> pd.Series:\n",
    "    \"\"\"sbert_match - SentenceTransformer address matching, float iytoyt\"\"\"\n",
    "    return sbert_compare_lower(row[\"Address1\"], row[\"Address2\"])\n",
    "\n",
    "\n",
    "def sbert_compare_binary_lower(address1: str, address2: str, threshold: float = 0.5) -> Literal[0, 1]:\n",
    "    \"\"\"sbert_match - compare and return a binary match\"\"\"\n",
    "    similarity = sbert_compare_lower(address1, address2)\n",
    "    return 1 if similarity >= threshold else 0\n",
    "\n",
    "\n",
    "def sbert_match_binary_lower(row: pd.Series, threshold: float = 0.5) -> pd.Series:\n",
    "    \"\"\"sbert_match_binary - SentenceTransformer address matching, binary output\"\"\"\n",
    "    return sbert_compare_binary_lower(row[\"Address1\"], row[\"Address2\"], threshold=threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94e3805-efb3-4677-97a6-03f469484ac0",
   "metadata": {},
   "source": [
    "### Evaluate ROC Curve to Determine Optimum Similarity Threshold\n",
    "\n",
    "We need to evaluate the ROC Curve of the F1 score to see what it should be set to for our lowercase model too. Recall that the `sbert_match_lower` function has a `threshold: float = 0.5` argument.\n",
    "\n",
    "#### Evaluate on our Augmented Test Dataset\n",
    "\n",
    "First we'll evaluate the ROC curve on our augmented test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245e39c8-4434-4e20-993e-b6dcf4b8bd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = test_df[\"Label\"]\n",
    "y_scores = test_df.apply(sbert_match_lower, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044d9937-5c3e-4e9a-aff2-e30aec095d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute precision-recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_true, y_scores)\n",
    "\n",
    "# Compute F1 score for each threshold\n",
    "f1_scores = [f1_score(y_true, y_scores >= t) for t in thresholds]\n",
    "\n",
    "# Find the threshold that maximizes the F1 score\n",
    "best_threshold_index = np.argmax(f1_scores)\n",
    "best_threshold = thresholds[best_threshold_index]\n",
    "best_f1_score = f1_scores[best_threshold_index]\n",
    "\n",
    "print(f'Best Threshold: {best_threshold}')\n",
    "print(f'Best F1 Score: {best_f1_score}')\n",
    "\n",
    "roc_auc = roc_auc_score(y_true, y_scores)\n",
    "print(f'AUC-ROC: {roc_auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3d1d6e-8ca0-4964-aa69-91e2e7ddffc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame for Seaborn\n",
    "pr_data = pd.DataFrame({\n",
    "    'Precision': precision[:-1],\n",
    "    'Recall': recall[:-1],\n",
    "    'F1 Score': f1_scores\n",
    "})\n",
    "\n",
    "# Plot Precision-Recall curve using Seaborn\n",
    "sns.lineplot(data=pr_data, x='Recall', y='Precision', marker='o')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Augmented Test Set Precision-Recall Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3a978d-6193-4968-99b3-65cfbd584c4e",
   "metadata": {},
   "source": [
    "### Plot a ROC Curve for our Gold Labeled Data\n",
    "\n",
    "We need to see the ROC Curve for our gold labeled data as well. We care more about performance on this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb225e7-ad73-4236-b4ea-49fbb1da3bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = gold_df[\"Label\"]\n",
    "y_scores = gold_df.apply(sbert_match_lower, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d2c166-d6c2-481c-b573-f1c5ca6fd41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute precision-recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_true, y_scores)\n",
    "\n",
    "# Compute F1 score for each threshold\n",
    "f1_scores = [f1_score(y_true, y_scores >= t) for t in thresholds]\n",
    "\n",
    "# Find the threshold that maximizes the F1 score\n",
    "best_threshold_index = np.argmax(f1_scores)\n",
    "best_threshold = thresholds[best_threshold_index]\n",
    "best_f1_score = f1_scores[best_threshold_index]\n",
    "\n",
    "print(f'Best Threshold: {best_threshold}')\n",
    "print(f'Best F1 Score: {best_f1_score}')\n",
    "\n",
    "roc_auc = roc_auc_score(y_true, y_scores)\n",
    "print(f'AUC-ROC: {roc_auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50070e2-5c1e-4367-b5be-d1145d87e97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame for Seaborn\n",
    "pr_data = pd.DataFrame({\n",
    "    'Precision': precision[:-1],\n",
    "    'Recall': recall[:-1],\n",
    "    'F1 Score': f1_scores\n",
    "})\n",
    "\n",
    "# Plot Precision-Recall curve using Seaborn\n",
    "sns.lineplot(data=pr_data, x='Recall', y='Precision', marker='o')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Gold Label Precision-Recall Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e133fb1b-6fcd-406a-82a0-8d9e9fac579e",
   "metadata": {},
   "source": [
    "### Rewriting our Structured Matcher\n",
    "\n",
    "Let's rewrite our original parser to use `sbert_compare_binary(address1: str, address2: str, threshold=best_threshold)` for the road name, city (which we skipped before) and country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31be0a9-8281-4ed4-92e3-753a8f040ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_fuzzy_match_address(address1: str, address2: str, threshold=0.5) -> Literal[0, 1]:\n",
    "    \"\"\"parse_fuzzy_match_address uses parsed addresses with fuzzy matching for street, city and country.\"\"\"\n",
    "    address1 = to_dict(parse_address(address1))\n",
    "    address2 = to_dict(parse_address(address2))\n",
    "\n",
    "    def match_road(address1: Dict, address2: Dict) -> Literal[0, 1]:\n",
    "        \"\"\"match_road - literal road matching, negative if either lacks a road\"\"\"\n",
    "        if (\"road\" in address1) and (\"road\" in address2):\n",
    "\n",
    "            # to_dict produces a list if two tuples have the same key\n",
    "            if isinstance(address1[\"road\"], list):\n",
    "                address1[\"road\"] = \" \".join(address1[\"road\"])\n",
    "            if isinstance(address2[\"road\"], list):\n",
    "                address2[\"road\"] = \" \".join(address2[\"road\"])\n",
    "            \n",
    "            if sbert_compare_binary_lower(\n",
    "                address1[\"road\"],\n",
    "                address2[\"road\"], \n",
    "                threshold=threshold\n",
    "            ):\n",
    "                logger.debug(\"road match\")\n",
    "                return 1\n",
    "            else:\n",
    "                logger.debug(\"road mismatch\")\n",
    "                return 0\n",
    "        logger.debug(\"road mismatch\")\n",
    "        return 0\n",
    "\n",
    "    def match_house_number(address1: Dict, address2: Dict) -> Literal[0, 1]:\n",
    "        \"\"\"match_house_number - literal house number matching, negative if either lacks a house_number\"\"\"\n",
    "        if (\"house_number\" in address1) and (\"house_number\" in address2):\n",
    "            if address1[\"house_number\"] == address2[\"house_number\"]:\n",
    "                logger.debug(\"house_number match\")\n",
    "                return 1\n",
    "            else:\n",
    "                logger.debug(\"house_number mismatch\")\n",
    "                return 0\n",
    "        logger.debug(\"house_number mistmatch\")\n",
    "        return 0\n",
    "\n",
    "    def match_unit(address1: Dict, address2: Dict) -> Literal[0, 1]:\n",
    "        \"\"\"match_unit - note a missing unit in both is a match\"\"\"\n",
    "        if \"unit\" in address1:\n",
    "            if \"unit\" in address2:\n",
    "                logger.debug(\"unit match\")\n",
    "                return 1 if (address1[\"unit\"] == address2[\"unit\"]) else 0\n",
    "            else:\n",
    "                logger.debug(\"unit mismatch\")\n",
    "                return 0\n",
    "        if \"unit\" in address2:\n",
    "            if \"unit\" in address1:\n",
    "                logger.debug(\"unit match\")\n",
    "                return 1 if (address1[\"unit\"] == address2[\"unit\"]) else 0\n",
    "            else:\n",
    "                logger.debug(\"unit mismatch\")\n",
    "                return 0\n",
    "        # Neither address has a unit, which is a default match\n",
    "        return 1\n",
    "\n",
    "    def match_postcode(address1: Dict, address2: Dict) -> Literal[0, 1]:\n",
    "        \"\"\"match_postcode - literal matching, negative if either lacks a postal code\"\"\"\n",
    "        if (\"postcode\" in address1) and (\"postcode\" in address2):\n",
    "            if address1[\"postcode\"] == address2[\"postcode\"]:\n",
    "                logger.debug(\"postcode match\")\n",
    "                return 1\n",
    "            else:\n",
    "                logger.debug(\"postcode mismatch\")\n",
    "                return 0\n",
    "        logger.debug(\"postcode mismatch\")\n",
    "        return 0\n",
    "\n",
    "    def match_country(address1: Dict, address2: Dict) -> Literal[0, 1]:\n",
    "        \"\"\"match_country - literal country matching - pass if both don't have one\"\"\"\n",
    "        if (\"country\" in address1) and (\"country\" in address2):\n",
    "\n",
    "            # to_dict produces a list if two tuples have the same key\n",
    "            if isinstance(address1[\"country\"], list):\n",
    "                address1[\"country\"] = \" \".join(address1[\"country\"])\n",
    "            if isinstance(address2[\"country\"], list):\n",
    "                address2[\"country\"] = \" \".join(address2[\"country\"])\n",
    "\n",
    "            if sbert_compare_binary_lower(\n",
    "                address1[\"country\"],\n",
    "                address2[\"country\"],\n",
    "                threshold=best_threshold,\n",
    "            ):\n",
    "                logger.debug(\"country match\")\n",
    "                return 1\n",
    "            else:\n",
    "                logger.debug(\"country mismatch\")\n",
    "                return 0\n",
    "\n",
    "        # One or none countries should match\n",
    "        logger.debug(\"country match\")\n",
    "        return 1\n",
    "\n",
    "    # Combine the above to get a complete address matcher\n",
    "    if (\n",
    "        match_road(address1, address2)\n",
    "        and match_house_number(address1, address2)\n",
    "        and match_unit(address1, address2)\n",
    "        and match_postcode(address1, address2)\n",
    "        and match_country(address1, address2)\n",
    "    ):\n",
    "        logger.debug(\"overall match\")\n",
    "        return 1\n",
    "    else:\n",
    "        logger.debug(\"overall mismatch\")\n",
    "        return 0\n",
    "\n",
    "\n",
    "def sbert_parse_match(row: pd.Series, threshold: float = 0.5) -> pd.Series:\n",
    "    \"\"\"fuzzy_parse_match Fuzzy, structured address matching. Threshold is passed through via gold_label_report.\"\"\"\n",
    "    return parse_fuzzy_match_address(row[\"Address1\"], row[\"Address2\"], threshold=threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394be39d-eb55-4ca5-9d56-f14d06c220ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df, grouped_df = gold_label_report(\n",
    "    gold_df,\n",
    "    [\n",
    "        strict_parse_match,\n",
    "        parse_match_country,\n",
    "        sbert_match_binary,\n",
    "        sbert_parse_match,\n",
    "    ],\n",
    "    threshold=best_threshold\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4554ba8-9280-4b86-a5e9-7610aca02a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df[\"sbert_parse_match_acc\"].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf346df-68a4-47e0-8e6d-ff1c237a0a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Truthiness analysis\n",
    "correct_df = raw_df[raw_df[\"sbert_parse_match_correct\"]].reset_index(drop=True)\n",
    "print(f\"Number correct: {len(correct_df):,}\")\n",
    "\n",
    "correct_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a67103-0ac3-4254-872b-0c245ca4ddf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error analysis\n",
    "wrong_df = raw_df[raw_df[\"sbert_parse_match_correct\"] == False].reset_index()\n",
    "print(f\"Number wrong: {len(wrong_df):,}\")\n",
    "\n",
    "wrong_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39042e3c-7a97-4589-97d2-af269c7d11c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbert_compare_lower(\"nw 5th ave\", \"northwest 5th avenue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb15a9f-1863-4bc3-822f-5057f8baab75",
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_fuzzy_match_address(\"2024 NW 5th Ave, Miami, FL 33127\", \"2024 Northwest 5th Avenue, Miami, Florida 33127\", threshold=best_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d839232a-9e11-4954-8968-fb7f83597ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_fuzzy_match_address(\"Third Ave, New York, NY\", \"3rd Avenue, New York, New York\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730af59f-37d8-408b-b1ea-fba55ca6f5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbert_compare_lower(\"101 market square, seattle, wa 98039\", \"101 davis place, seattle, wa 98039\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6ea0fe-c542-4ff1-8010-16fa5e20084d",
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_fuzzy_match_address(\"221B Baker Street, London, NW1 6XE, UK\", \"221B Baker St, Marylebone, London NW1 6XE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ce4d63-059e-4830-a0b6-4b0b9ab515f7",
   "metadata": {},
   "source": [
    "## Fuzzy Parsed Conclusion\n",
    "\n",
    "If you look at the items missed by this model, they are largely due to stricter matching requirements. These could be addressed logically, as with the help of fuzzy matching with `SentenceTransformers` they fall within the scope of task a human can accomplish. This means the structured, fuzzy model can be trusted more than the pure `SentenceTransformer` model. A little more work could bring it into a state that meets or beats the pure `SentenceTransformer` model while providing explainability that entity resolution often requires."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0388ebba-f964-41ce-ab37-c9c295a45806",
   "metadata": {},
   "source": [
    "## Structured Prediction with a `Sentence-BERT` Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6f9841-6248-4e06-81b7-c5761fde354e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SBERT_MODEL = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "VARIANT = \"untrained-embeddings\"\n",
    "MODEL_SAVE_NAME = (\"Sentence-BERT\" + \"-\" + VARIANT).replace(\"/\", \"-\")\n",
    "\n",
    "EPOCHS = 3\n",
    "BATCH_SIZE = 32\n",
    "PATIENCE = 2\n",
    "LEARNING_RATE = .00005\n",
    "MODEL_OUTPUT_FOLDER = f\"data/{MODEL_SAVE_NAME}\"\n",
    "SAVE_EVAL_STEPS = 100\n",
    "\n",
    "COLUMN_SPECIAL_CHAR = \"[COL]\"\n",
    "VALUE_SPECIAL_CHAR = \"[VAL]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "3aaed279-2818-4a22-84bd-26a48fba64e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceBERT(torch.nn.Module):\n",
    "    def __init__(self, model_name=SBERT_MODEL, dim=384):\n",
    "        super().__init__()\n",
    "        self.model_name = model_name\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModel.from_pretrained(model_name)\n",
    "        self.ffnn = torch.nn.Linear(dim*3, 1)\n",
    "\n",
    "    @staticmethod\n",
    "    def mean_pool(token_embeds, attention_mask):\n",
    "        in_mask = attention_mask.unsqueeze(-1).expand(token_embeds.size()).float()\n",
    "        pool = torch.sum(token_embeds * in_mask, 1) / torch.clamp(in_mask.sum(1), min=1e-9)\n",
    "        return pool\n",
    "\n",
    "    def _check_similarity(self, a, b, mask_a, mask_b):\n",
    "        u = self.model(a, attention_mask=mask_a)[0]\n",
    "        v = self.model(b, attention_mask=mask_b)[0]\n",
    "        u = SentenceBERT.mean_pool(u, mask_a)\n",
    "        v = SentenceBERT.mean_pool(v, mask_b)\n",
    "        uv = torch.abs(u - v)\n",
    "        x = torch.cat([u, v, uv], dim=-1)\n",
    "        x = torch.sigmoid(self.ffnn(x).float())\n",
    "        return x\n",
    "\n",
    "    def check_similarity(self, a, b):\n",
    "        encoded_a = self.tokenizer(a, padding=True, truncation=True, return_tensors='pt')\n",
    "        encoded_b = self.tokenizer(b, padding=True, truncation=True, return_tensors='pt')\n",
    "        a = encoded_a['input_ids']\n",
    "        b = encoded_b['input_ids']\n",
    "        mask_a = encoded_a['attention_mask']\n",
    "        mask_b = encoded_b['attention_mask']\n",
    "        with torch.no_grad():\n",
    "            return self._check_similarity(a, b, mask_a, mask_b)\n",
    "\n",
    "    def forward(self, input_ids_a, input_ids_b, attention_mask_a=None, attention_mask_b=None, labels=None):\n",
    "        logits = self._check_similarity(input_ids_a, input_ids_b, attention_mask_a, attention_mask_b)\n",
    "        if labels is not None:\n",
    "            loss_fct = torch.nn.BCEWithLogitsLoss()\n",
    "            labels = labels.float().unsqueeze(1)\n",
    "            loss = loss_fct(logits, labels)\n",
    "            return loss, logits\n",
    "\n",
    "    def predict(self, a: str, b: str):\n",
    "        with torch.no_grad():\n",
    "            logits = self.check_similarity(a, b)\n",
    "            probabilities = torch.sigmoid(logits)\n",
    "            predicted_class = (probabilities > 0.5).long().item()\n",
    "            return predicted_class, probabilities.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "15494649-c8bc-495c-9a10-7516c315b6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceBERT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916eb7c6-fa55-4207-8e50-724dfae27189",
   "metadata": {},
   "outputs": [],
   "source": [
    "def structured_encode_address(address: List[Tuple[str, str]]) -> str:\n",
    "    \"\"\"structured_parse_address - encode a parsed address\"\"\"\n",
    "    sorted_address: List[Tuple[str, str]] = sorted(address, key=lambda x: x[0])\n",
    "    encoded_address: str = str()\n",
    "    for col, val in sorted_address:\n",
    "        encoded_address += COLUMN_SPECIAL_CHAR + col + VALUE_SPECIAL_CHAR + val\n",
    "    return encoded_address\n",
    "\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    encoded_a = model.tokenizer(examples[\"sentence1\"], padding=\"max_length\", truncation=True)\n",
    "    encoded_b = model.tokenizer(examples[\"sentence2\"], padding=\"max_length\", truncation=True)\n",
    "    return {\n",
    "        \"input_ids_a\": encoded_a[\"input_ids\"],\n",
    "        \"attention_mask_a\": encoded_a[\"attention_mask\"],\n",
    "        \"input_ids_b\": encoded_b[\"input_ids\"],\n",
    "        \"attention_mask_b\": encoded_b[\"attention_mask\"],\n",
    "        \"labels\": examples[\"label\"]\n",
    "    }\n",
    "\n",
    "\n",
    "def format_dataset(dataset):\n",
    "    dataset.set_format(type=\"torch\", columns=[\"input_ids_a\", \"attention_mask_a\", \"input_ids_b\", \"attention_mask_b\", \"labels\"])\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac83aeb-e907-4724-9da7-c95f4cac124b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, tmp_df = train_test_split(augment_results_df, test_size=0.2, shuffle=True)\n",
    "eval_df, test_df = train_test_split(tmp_df, test_size=0.5, random_state=42, shuffle=True)\n",
    "\n",
    "train_dataset = Dataset.from_dict({\n",
    "    \"sentence1\": train_df[\"Address1\"].tolist(),\n",
    "    \"sentence2\": train_df[\"Address2\"].tolist(),\n",
    "    \"label\": train_df[\"Label\"].tolist(),\n",
    "})\n",
    "\n",
    "eval_dataset = Dataset.from_dict({\n",
    "    \"sentence1\": eval_df[\"Address1\"].tolist(),\n",
    "    \"sentence2\": eval_df[\"Address2\"].tolist(),\n",
    "    \"label\": eval_df[\"Label\"].tolist(),\n",
    "})\n",
    "\n",
    "test_dataset = Dataset.from_dict({\n",
    "    \"sentence1\": test_df[\"Address1\"].tolist(),\n",
    "    \"sentence2\": test_df[\"Address2\"].tolist(),\n",
    "    \"label\": test_df[\"Label\"].tolist(),\n",
    "})\n",
    "\n",
    "print(f\"Training data:   {len(train_df):,}\")\n",
    "print(f\"Validation data: {len(eval_df):,}\")\n",
    "print(f\"Test data        {len(eval_df):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4ee830c6-cea1-4113-b398-827e5f101643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36d10088317f497cb696120bdae4046a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3928 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3abdfc32db245acbf2c4b40d820eb47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/491 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53254ea308d54da3b3e486b86ff152e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/491 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_eval_dataset = eval_dataset.map(tokenize_function, batched=True)\n",
    "tokenized_test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "tokenized_train_dataset = format_dataset(tokenized_train_dataset)\n",
    "tokenized_eval_dataset = format_dataset(tokenized_eval_dataset)\n",
    "tokenized_test_dataset = format_dataset(tokenized_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e650246e-27b7-4135-bbf6-8320a8858b88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13' max='1473' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  13/1473 00:06 < 13:16, 1.83 it/s, Epoch 0.02/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[97], line 35\u001b[0m\n\u001b[1;32m     25\u001b[0m trainer \u001b[38;5;241m=\u001b[39m CustomTrainer(\n\u001b[1;32m     26\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     27\u001b[0m     args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics,\n\u001b[1;32m     31\u001b[0m )\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[1;32m     39\u001b[0m results \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mevaluate()\n",
      "File \u001b[0;32m~/anaconda3/envs/libpostal/lib/python3.11/site-packages/transformers/trainer.py:1885\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1883\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1884\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1885\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/libpostal/lib/python3.11/site-packages/transformers/trainer.py:2221\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2215\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[1;32m   2216\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m   2218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2219\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2220\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m-> 2221\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misinf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss_step\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2222\u001b[0m ):\n\u001b[1;32m   2223\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2224\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n\u001b[1;32m   2225\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define the Trainer\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "\n",
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        input_ids_a = inputs.pop(\"input_ids_a\")\n",
    "        input_ids_b = inputs.pop(\"input_ids_b\")\n",
    "        attention_mask_a = inputs.pop(\"attention_mask_a\")\n",
    "        attention_mask_b = inputs.pop(\"attention_mask_b\")\n",
    "        outputs = model(input_ids_a, input_ids_b, attention_mask_a, attention_mask_b, labels)\n",
    "        loss = outputs[0]\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "\n",
    "# Evaluate the model\n",
    "results = trainer.evaluate()\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6af6c2-408a-47a0-bc73-fa832385f797",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
