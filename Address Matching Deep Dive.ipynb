{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d0f6845-e53f-4e9b-be24-0e376269f522",
   "metadata": {},
   "source": [
    "# Address Matching Deep Dive\n",
    "\n",
    "This notebook experiments with different ways of comparing addresses in order to demonstrate the power of parsed address comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8feab8c8-a116-40f9-a882-5a932140af26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "from numbers import Number\n",
    "from typing import Callable, Dict, List, Literal, Sequence, Tuple, Union\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import pyarrow.dataset as ds\n",
    "import pytest\n",
    "import random\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import wandb\n",
    "from datasets import Dataset\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "from postal.parser import parse_address\n",
    "from scipy.spatial import distance\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_recall_curve,\n",
    "    precision_recall_fscore_support,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    roc_curve,\n",
    "    auc\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sentence_transformers import InputExample, SentenceTransformer, SentencesDataset, SentenceTransformerTrainer, losses\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator, SimilarityFunction, BinaryClassificationEvaluator\n",
    "from sentence_transformers.model_card import SentenceTransformerModelCardData\n",
    "from sentence_transformers.training_args import BatchSamplers, SentenceTransformerTrainingArguments\n",
    "from tenacity import retry\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import RAdam\n",
    "from tqdm.autonotebook import tqdm\n",
    "from transformers import AutoTokenizer, AutoModel, EarlyStoppingCallback, TrainingArguments, Trainer\n",
    "from transformers.integrations import WandbCallback\n",
    "\n",
    "from utils import (\n",
    "    augment_gold_labels,\n",
    "    compute_sbert_metrics,\n",
    "    compute_classifier_metrics,\n",
    "    format_dataset,\n",
    "    gold_label_report,\n",
    "    preprocess_logits_for_metrics,\n",
    "    structured_encode_address,\n",
    "    tokenize_function,\n",
    "    to_dict,\n",
    "    save_custom_model,\n",
    "    load_custom_model,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0578d26d-790c-4fe6-aed7-2529f155f7f6",
   "metadata": {},
   "source": [
    "#### Pin Random Seeds for Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b495c03-2aba-4d6b-889b-3b21b56f4d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 31337\n",
    "\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.mps.manual_seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e998da-0660-4274-b000-619b28c3c533",
   "metadata": {},
   "source": [
    "#### Setup Basic Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e508b00c-0011-4845-a4d6-cd131ec5b6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(stream=sys.stderr, level=logging.ERROR)\n",
    "\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2912a2be-9e56-4bf9-94fc-3dbcfd02ef17",
   "metadata": {},
   "source": [
    "#### Ignore Warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18cd4a2c-f1f5-4c82-8c15-a52dc87db947",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter('ignore', FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ba8945-a02c-4661-a865-c03ee6eecebe",
   "metadata": {},
   "source": [
    "#### Configure Weights & Biases\n",
    "\n",
    "`wandb` needs some environment variables to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9491984a-c9fb-40d5-8fb0-743b77d15c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_LOG_MODEL\"] = \"end\"\n",
    "os.environ[\"WANDB_WATCH\"] = \"gradients\"\n",
    "os.environ[\"WANDB_PROJECT\"] = \"libpostal-reborn\"\n",
    "os.environ[\"WANDB_DISABLED\"] = \"false\"\n",
    "os.environ[\"WANDB_IGNORE_GLOBS\"] = \".env\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9006aa62-5aac-4bd2-900e-09b8107903e3",
   "metadata": {},
   "source": [
    "#### Optionally Disable `wandb` Uploads\n",
    "\n",
    "Weights and Biases can be slow..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17afaccb-e7db-48a5-aaff-561804821337",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_MODE\"] = \"online\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e1d411-e2a5-4824-9309-ff50861a0e19",
   "metadata": {},
   "source": [
    "#### Configure Huggingface APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62d0d44b-c38a-48ca-a3b1-895b5b8c320b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HF_ENDPOINT\"] = \"https://huggingface.co/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7462e0-b3d1-4d76-bd7a-803cbd2f3446",
   "metadata": {},
   "source": [
    "#### Configure Huggingface APIs\n",
    "\n",
    "Squash any warnings..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fcde550-79a6-4333-967e-c80d555de5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42913e46-e5db-4eff-9410-5a8449d4cbf6",
   "metadata": {},
   "source": [
    "#### Configure Pandas to Show More Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2d4cb15-b201-4f34-8917-d292dd2a1876",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", 40)\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad42226-1abc-4c29-b68d-659d330ba1f9",
   "metadata": {},
   "source": [
    "### Use CUDA or MPS if Avaialable\n",
    "\n",
    "CPU training and even inference with sentence transformers and deep learning models is quite slow. Since all machine learning in this library is based on [PyTorch](https://pytorch.org/get-started/locally/), we can assign all ML operations to a GPU in this one block of code. Otherwise we default to CPU without acceleration. The notebook is still workable in this mode, you just may need to grab a cup of tea or coffee while you wait for it to train the Sentence-BERT model below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1051aa37-26b7-496a-8182-f10cfa1f5f6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for CUDA or MPS availability and set the device\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "    logger.debug(\"Using Apple GPU acceleration\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    logger.debug(\"Using NVIDIA CUDA GPU acceleration\")\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    logger.debug(\"Using CPU for ML\")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921a41eb-4e6b-4d64-a3b4-46013524e37c",
   "metadata": {},
   "source": [
    "### Use Weights & Biases for Logging Metrics\n",
    "\n",
    "Weights & Biases has a free account for individuals with public projects. Using it will produce charts during our training runs that anyone can view. You can create your own project for this notebook and login with that key to log your own training runs.\n",
    "\n",
    "You may need to run the following command from your shell before the next cell, otherwise you will have to paste your project key into the \n",
    "\n",
    "```bash\n",
    "wandb login\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d98cdf2f-fcb9-495e-9201-80f9e07d9070",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrjurney\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Login to wandb. Comment out if you already haven't via `wandb login` from a CLI\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85701b19-a5e1-42c4-9ace-8d88d96f893f",
   "metadata": {},
   "source": [
    "## Implementing a Structured Address Matcher\n",
    "\n",
    "Let's start our exercise by using the structured address data provided by [Libpostal](https://github.com/openvenues/libpostal) to parse them for matching. We write a function for each address part to deal with missing fields without duplicating a lot of logic.\n",
    "\n",
    "We start with something quite literal and basic. We'll improve it as we go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44031098-15b5-45ef-b1d0-8a51a9838bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_match_address(address1: str, address2: str) -> Literal[0, 1]:\n",
    "    \"\"\"parse_match_address implements address matching using the precise, parsed structure of addresses.\"\"\"\n",
    "    address1 = to_dict(parse_address(address1))\n",
    "    address2 = to_dict(parse_address(address2))\n",
    "\n",
    "    def match_road(address1: Dict, address2: Dict) -> Literal[0, 1]:\n",
    "        \"\"\"match_road - literal road matching, negative if either lacks a road\"\"\"\n",
    "        if (\"road\" in address1) and (\"road\" in address2):\n",
    "            if address1[\"road\"] == address2[\"road\"]:\n",
    "                logger.debug(\"road match\")\n",
    "                return 1\n",
    "            else:\n",
    "                logger.debug(\"road mismatch\")\n",
    "                return 0\n",
    "        logger.debug(\"road mismatch\")\n",
    "        return 0\n",
    "\n",
    "    def match_house_number(address1: Dict, address2: Dict) -> Literal[0, 1]:\n",
    "        \"\"\"match_house_number - literal house number matching, negative if either lacks a house_number\"\"\"\n",
    "        if (\"house_number\" in address1) and (\"house_number\" in address2):\n",
    "            if address1[\"house_number\"] == address2[\"house_number\"]:\n",
    "                logger.debug(\"house_number match\")\n",
    "                return 1\n",
    "            else:\n",
    "                logger.debug(\"house_number mismatch\")\n",
    "                return 0\n",
    "        logger.debug(\"house_number mistmatch\")\n",
    "        return 0\n",
    "\n",
    "    def match_unit(address1: Dict, address2: Dict) -> Literal[0, 1]:\n",
    "        \"\"\"match_unit - note a missing unit in both is a match\"\"\"\n",
    "        if \"unit\" in address1:\n",
    "            if \"unit\" in address2:\n",
    "                logger.debug(\"unit match\")\n",
    "                return 1 if (address1[\"unit\"] == address2[\"unit\"]) else 0\n",
    "            else:\n",
    "                logger.debug(\"unit mismatch\")\n",
    "                return 0\n",
    "        if \"unit\" in address2:\n",
    "            if \"unit\" in address1:\n",
    "                logger.debug(\"unit match\")\n",
    "                return 1 if (address1[\"unit\"] == address2[\"unit\"]) else 0\n",
    "            else:\n",
    "                logger.debug(\"unit mismatch\")\n",
    "                return 0\n",
    "        # Neither address has a unit, which is a default match\n",
    "        return 1\n",
    "\n",
    "    def match_postcode(address1: Dict, address2: Dict) -> Literal[0, 1]:\n",
    "        \"\"\"match_postcode - literal matching, negative if either lacks a postal code\"\"\"\n",
    "        if (\"postcode\" in address1) and (\"postcode\" in address2):\n",
    "            if address1[\"postcode\"] == address2[\"postcode\"]:\n",
    "                logger.debug(\"postcode match\")\n",
    "                return 1\n",
    "            else:\n",
    "                logger.debug(\"postcode mismatch\")\n",
    "                return 0\n",
    "        logger.debug(\"postcode mismatch\")\n",
    "        return 0\n",
    "\n",
    "    def match_country(address1: Dict, address2: Dict) -> Literal[0, 1]:\n",
    "        \"\"\"match_country - literal country matching - pass if both don't have one\"\"\"\n",
    "        if (\"country\" in address1) and (\"country\" in address2):\n",
    "            if address1[\"country\"] == address2[\"country\"]:\n",
    "                logger.debug(\"country match\")\n",
    "                return 1\n",
    "            else:\n",
    "                logger.debug(\"country mismatch\")\n",
    "                return 0\n",
    "        # One or none countries should match\n",
    "        logger.debug(\"country match\")\n",
    "        return 1\n",
    "\n",
    "    # Combine the above to get a complete address matcher\n",
    "    if (\n",
    "        match_road(address1, address2)\n",
    "        and match_house_number(address1, address2)\n",
    "        and match_unit(address1, address2)\n",
    "        and match_postcode(address1, address2)\n",
    "        and match_country(address1, address2)\n",
    "    ):\n",
    "        logger.debug(\"overall match\")\n",
    "        return 1\n",
    "    else:\n",
    "        logger.debug(\"overall mismatch\")\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f67113-6f5f-45cb-9f4c-4ee0a4362de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yup down to house_number ...\n",
    "parse_match_address(\n",
    "    \"3413 Sean Way, Lawrenceville, GA 30044\",\n",
    "    \"3413 Sean Way Lawrenceville, GA, 30044\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea361bd-56df-4980-a060-1d7e743af38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fuzz.ratio(\n",
    "    \"3413 Sean Way, Lawrenceville, GA 30044\",\n",
    "    \"3413 Sean Way Lawrenceville, GA, 30044\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797ace98-a912-4c45-b178-6c6201f58bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yup down to unit ...\n",
    "parse_match_address(\n",
    "    \"120 Ralph McGill Blvd, Apt 101, Atlanta, GA 30308, USA\",\n",
    "    \"120 Ralph McGill Blvd, Apt 101, Atlanta GA 30308\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5caf28fb-64e1-447f-a996-6d0d9e67bb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fuzz.ratio(\n",
    "    \"120 Ralph McGill Blvd, Apt 101, Atlanta, GA 30308, USA\",\n",
    "    \"120 Ralph McGill Blvd, Apt 101, Atlanta GA 30308\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b949ebe-8889-498c-a601-904c2c5c1433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nope if only one uses an abbreviation ...\n",
    "parse_match_address(\n",
    "    \"120 Ralph McGill Blvd, Apt 333, Atlanta, GA 30308\",\n",
    "    \"120 Ralph McGill Boulevard, Apt 333, Atlanta, GA 30308\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108b88c9-9aca-4a13-80f9-2c88dbe77afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "fuzz.ratio(\n",
    "    \"120 Ralph McGill Blvd, Apt 333, Atlanta, GA 30308\",\n",
    "    \"120 Ralph McGill Boulevard, Apt 333, Atlanta, GA 30308\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498ab13c-1457-4c4c-95ff-2f691f697738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nope if one character in the streetname is off ...\n",
    "parse_match_address(\n",
    "    \"120 Ralp McGill Blvd, Apt 333, Atlanta, GA 30308\",\n",
    "    \"120 Ralph McGill Blvd, Apt 333, Atlanta, GA 30308\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6681fa67-bdf4-43b0-984d-8c91e5cbf902",
   "metadata": {},
   "outputs": [],
   "source": [
    "fuzz.ratio(\n",
    "    \"120 Ralp McGill Blvd, Apt 333, Atlanta, GA 30308\",\n",
    "    \"120 Ralph McGill Blvd, Apt 333, Atlanta, GA 30308\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f1a4c5-0bcd-4c52-b5d7-7be7ad1932ea",
   "metadata": {},
   "source": [
    "### Literal is Too Precise!\n",
    "\n",
    "While it is useful to parse addresses and implement literal matching logic as we did above, as the third example indicates, an abbreviation or a single typo results in a mistmatch. We're going to write a more complex, approximate logical matcher below using string distance and text embeddings.\n",
    "\n",
    "Depending on your application you might relax this criteria to include corner cases such as missing postcodes. Before we get into that, let's create some training and evaluation data using hand-labeled data with an LLM data augmentation strategy to generate a lot of labeled records."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15895b85-1d0f-441c-9d20-0849b3db3b22",
   "metadata": {},
   "source": [
    "## Data Augmentation with the OpenAI GPT4o API\n",
    "\n",
    "We need training data for our supervised learning approaches to addres matching. Open the sister notebook [Address Data Augmentation.ipynb](Address%20Matching%20Deep%20Dive.ipynb) before procceeding to further cells in order to create some training data via minimal manual labeling and programmatic data labeling for data augmentation. This will teach you programmatic data labeling, a critical skill that LLMs make MUCH EASIER because they understand things like the semantics of global addresses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "833e8045-5cd3-4b5a-9cd3-afc65965062a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_df = pd.read_csv(\"data/gold.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6382fc3-ca84-4d17-9d74-354ab798d21c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Address1</th>\n",
       "      <th>Address2</th>\n",
       "      <th>Description</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>123 E Main St, Springfield, IL 62701</td>\n",
       "      <td>123 East Main Street, Springfield, Illinois 62701</td>\n",
       "      <td>Different directional prefix formats for same ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>456 W Elm St, Boston, MA 02118</td>\n",
       "      <td>456 West Elm Street, Boston, Massachusetts 02118</td>\n",
       "      <td>Different directional prefix formats for same ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>789 S Oak St, Denver, CO 80203</td>\n",
       "      <td>789 South Oak Street, Denver, Colorado 80203</td>\n",
       "      <td>Different directional prefix formats for same ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>321 N Pine St, Seattle, WA 98101</td>\n",
       "      <td>321 North Pine Street, Seattle, Washington 98101</td>\n",
       "      <td>Different directional prefix formats for same ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>654 E Maple St, Austin, TX 73301</td>\n",
       "      <td>654 East Maple Street, Austin, Texas 73301</td>\n",
       "      <td>Different directional prefix formats for same ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>987 W Cedar St, San Francisco, CA 94102</td>\n",
       "      <td>987 West Cedar Street, San Francisco, Californ...</td>\n",
       "      <td>Different directional prefix formats for same ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>246 S Birch St, New York, NY 10001</td>\n",
       "      <td>246 South Birch Street, New York, New York 10001</td>\n",
       "      <td>Different directional prefix formats for same ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>135 N Cedar Ave, Chicago, IL 60601</td>\n",
       "      <td>135 North Cedar Avenue, Chicago, Illinois 60601</td>\n",
       "      <td>Different directional prefix formats for same ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>864 E Pine Ave, Los Angeles, CA 90001</td>\n",
       "      <td>864 East Pine Avenue, Los Angeles, California ...</td>\n",
       "      <td>Different directional prefix formats for same ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>753 W Spruce St, Houston, TX 77001</td>\n",
       "      <td>753 West Spruce Street, Houston, Texas 77001</td>\n",
       "      <td>Different directional prefix formats for same ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>159 S Maple Ave, Phoenix, AZ 85001</td>\n",
       "      <td>159 South Maple Avenue, Phoenix, Arizona 85001</td>\n",
       "      <td>Different directional prefix formats for same ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>357 N Oak St, Philadelphia, PA 19102</td>\n",
       "      <td>357 North Oak Street, Philadelphia, Pennsylvan...</td>\n",
       "      <td>Different directional prefix formats for same ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>468 E Birch Ave, San Antonio, TX 78201</td>\n",
       "      <td>468 East Birch Avenue, San Antonio, Texas 78201</td>\n",
       "      <td>Different directional prefix formats for same ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>579 W Cedar St, Dallas, TX 75201</td>\n",
       "      <td>579 West Cedar Street, Dallas, Texas 75201</td>\n",
       "      <td>Different directional prefix formats for same ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>681 S Pine Ave, San Jose, CA 95101</td>\n",
       "      <td>681 South Pine Avenue, San Jose, California 95101</td>\n",
       "      <td>Different directional prefix formats for same ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>792 N Maple St, Jacksonville, FL 32201</td>\n",
       "      <td>792 North Maple Street, Jacksonville, Florida ...</td>\n",
       "      <td>Different directional prefix formats for same ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>903 E Oak St, Columbus, OH 43201</td>\n",
       "      <td>903 East Oak Street, Columbus, Ohio 43201</td>\n",
       "      <td>Different directional prefix formats for same ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>104 W Elm Ave, Charlotte, NC 28201</td>\n",
       "      <td>104 West Elm Avenue, Charlotte, North Carolina...</td>\n",
       "      <td>Different directional prefix formats for same ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>215 S Cedar St, Indianapolis, IN 46201</td>\n",
       "      <td>215 South Cedar Street, Indianapolis, Indiana ...</td>\n",
       "      <td>Different directional prefix formats for same ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>326 N Pine Ave, Fort Worth, TX 76101</td>\n",
       "      <td>326 North Pine Avenue, Fort Worth, Texas 76101</td>\n",
       "      <td>Different directional prefix formats for same ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Address1  \\\n",
       "0      123 E Main St, Springfield, IL 62701   \n",
       "1            456 W Elm St, Boston, MA 02118   \n",
       "2            789 S Oak St, Denver, CO 80203   \n",
       "3          321 N Pine St, Seattle, WA 98101   \n",
       "4          654 E Maple St, Austin, TX 73301   \n",
       "5   987 W Cedar St, San Francisco, CA 94102   \n",
       "6        246 S Birch St, New York, NY 10001   \n",
       "7        135 N Cedar Ave, Chicago, IL 60601   \n",
       "8     864 E Pine Ave, Los Angeles, CA 90001   \n",
       "9        753 W Spruce St, Houston, TX 77001   \n",
       "10       159 S Maple Ave, Phoenix, AZ 85001   \n",
       "11     357 N Oak St, Philadelphia, PA 19102   \n",
       "12   468 E Birch Ave, San Antonio, TX 78201   \n",
       "13         579 W Cedar St, Dallas, TX 75201   \n",
       "14       681 S Pine Ave, San Jose, CA 95101   \n",
       "15   792 N Maple St, Jacksonville, FL 32201   \n",
       "16         903 E Oak St, Columbus, OH 43201   \n",
       "17       104 W Elm Ave, Charlotte, NC 28201   \n",
       "18   215 S Cedar St, Indianapolis, IN 46201   \n",
       "19     326 N Pine Ave, Fort Worth, TX 76101   \n",
       "\n",
       "                                             Address2  \\\n",
       "0   123 East Main Street, Springfield, Illinois 62701   \n",
       "1    456 West Elm Street, Boston, Massachusetts 02118   \n",
       "2        789 South Oak Street, Denver, Colorado 80203   \n",
       "3    321 North Pine Street, Seattle, Washington 98101   \n",
       "4          654 East Maple Street, Austin, Texas 73301   \n",
       "5   987 West Cedar Street, San Francisco, Californ...   \n",
       "6    246 South Birch Street, New York, New York 10001   \n",
       "7     135 North Cedar Avenue, Chicago, Illinois 60601   \n",
       "8   864 East Pine Avenue, Los Angeles, California ...   \n",
       "9        753 West Spruce Street, Houston, Texas 77001   \n",
       "10     159 South Maple Avenue, Phoenix, Arizona 85001   \n",
       "11  357 North Oak Street, Philadelphia, Pennsylvan...   \n",
       "12    468 East Birch Avenue, San Antonio, Texas 78201   \n",
       "13         579 West Cedar Street, Dallas, Texas 75201   \n",
       "14  681 South Pine Avenue, San Jose, California 95101   \n",
       "15  792 North Maple Street, Jacksonville, Florida ...   \n",
       "16          903 East Oak Street, Columbus, Ohio 43201   \n",
       "17  104 West Elm Avenue, Charlotte, North Carolina...   \n",
       "18  215 South Cedar Street, Indianapolis, Indiana ...   \n",
       "19     326 North Pine Avenue, Fort Worth, Texas 76101   \n",
       "\n",
       "                                          Description  Label  \n",
       "0   Different directional prefix formats for same ...    1.0  \n",
       "1   Different directional prefix formats for same ...    1.0  \n",
       "2   Different directional prefix formats for same ...    1.0  \n",
       "3   Different directional prefix formats for same ...    1.0  \n",
       "4   Different directional prefix formats for same ...    1.0  \n",
       "5   Different directional prefix formats for same ...    1.0  \n",
       "6   Different directional prefix formats for same ...    1.0  \n",
       "7   Different directional prefix formats for same ...    1.0  \n",
       "8   Different directional prefix formats for same ...    1.0  \n",
       "9   Different directional prefix formats for same ...    1.0  \n",
       "10  Different directional prefix formats for same ...    1.0  \n",
       "11  Different directional prefix formats for same ...    1.0  \n",
       "12  Different directional prefix formats for same ...    1.0  \n",
       "13  Different directional prefix formats for same ...    1.0  \n",
       "14  Different directional prefix formats for same ...    1.0  \n",
       "15  Different directional prefix formats for same ...    1.0  \n",
       "16  Different directional prefix formats for same ...    1.0  \n",
       "17  Different directional prefix formats for same ...    1.0  \n",
       "18  Different directional prefix formats for same ...    1.0  \n",
       "19  Different directional prefix formats for same ...    1.0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you want to start from here and not run the data augmentation pipeline again...\n",
    "augment_results_df = pd.read_parquet(\"data/training.6.parquet\")\n",
    "\n",
    "augment_results_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2b2e4e-0c28-47ce-8b3c-7c1dac0062f5",
   "metadata": {},
   "source": [
    "### Data Augmentation Complete!\n",
    "\n",
    "Starting by hand labeling under 100 records and iterating a few times on data augmentation instructions for GPT4o, we have multiplied them by many times to get almost 10,000 synthetic records! This is enough to fine-tune a `SentenceTransformer` or semantic text similarity classifier model. GPT4o is a powerful tool for data augmentation! This can work for a variety of problems.\n",
    "\n",
    "LLM based data augmentation is a powerful tool for your data labeling toolbox."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "423992c9-bd0c-4e85-b5ce-cbf14a1d5356",
   "metadata": {},
   "source": [
    "# Comparing Different Approaches to Address Matching\n",
    "\n",
    "Now we're going to compare the following methods of address matching:\n",
    "\n",
    "1) Database Lookups - we'l use [pycountry](https://pypi.org/project/pycountry/) ([github](https://github.com/pycountry/pycountry)) to improve international address matching (see [PyCountry Nation Matching](PyCountry%20Nation%20Matching.ipynb)).\n",
    "2) Text Embeddings - we'll use transfer learning to load an existing [SentenceTransformer](https://sbert.net) model to sentence encode pairs of addresses to create fixed-length embeddings for each address and then compute a similarity score via [cosine similarity](https://en.wikipedia.org/wiki/Cosine_similarity). This won't work without fine-tuning, so we fine-tune the model to the task.\n",
    "3) Deep Matching Model - We'll train a deep semantic textual similarity classification model based on a Siamese BERT network as defined in [Sentence-BERT](https://arxiv.org/abs/1908.10084) to classify address pairs as matching or not matching."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7aa526-33e4-4705-a453-585ab7f3869a",
   "metadata": {},
   "source": [
    "# Machine Learning Approaches to Address Matching\n",
    "\n",
    "In this section we pursue two machine learning approaches to address matching, in order of sophistication. First we fine-tune a pre-trained embedding model to our task, try it on our data and search for a threshold similarity that results in good performance for our address matching problem. Second we build a Siamese BERT network model based on [Sentence-BERT](https://arxiv.org/abs/1908.10084) to classify pairs of addresses as match or mismatch. We will train it using the same dataset we use to fine-tune a sentence transformer, and if we have enough training data this will likely be a more powerful approach.\n",
    "\n",
    "## Text Embeddings, Sentence Encoding, `SentenceTransformers`, Vector Distance and Cosine Similarity\n",
    "\n",
    "Text embeddings are trained on large volumes of text that include addresses. As a result they have some understanding of address strings and can do a form of semantic comparison that is less explicit than logical comparisons with address parsing. They're an important benchmark to explore. Huggingface has an excellent [introduction to sentence similarity](https://huggingface.co/tasks/sentence-similarity).\n",
    "\n",
    "In our first machine learning approach, we are going to use transfer learning to load a pre-trained [sentence transformer](https://sbert.net) models from huggingface. We will use the training data we've prepared to fine-tune this model to our task, before rigorously evaluating it along with our other approaches.\n",
    "\n",
    "Sentence transformers sentence encode strings of different distances into fixed-length vectors, a technique called sentence encoding. Once two address strings are embedded into a pair of equal length vectors, they can be compared with cosine similarity to get a distance, the inverse of which is a similarity score.\n",
    "\n",
    "### Convert our `pd.DataFrame` to a `List[sentence_transformers.InputExample]`\n",
    "\n",
    "First we need to convert our Pandas `DataFrame` to a list of sentence transformer input examples. `InputExamples` require two fields `texts=List[str, str]` and `label`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b105924-4872-4abf-a10c-4d77150f1b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, tmp_df = train_test_split(augment_results_df, test_size=0.2, shuffle=True)\n",
    "eval_df, test_df = train_test_split(tmp_df, test_size=0.5, random_state=42, shuffle=True)\n",
    "\n",
    "train_dataset = Dataset.from_dict({\n",
    "    \"sentence1\": train_df[\"Address1\"].tolist(),\n",
    "    \"sentence2\": train_df[\"Address2\"].tolist(),\n",
    "    \"label\": train_df[\"Label\"].tolist(),\n",
    "})\n",
    "\n",
    "eval_dataset = Dataset.from_dict({\n",
    "    \"sentence1\": eval_df[\"Address1\"].tolist(),\n",
    "    \"sentence2\": eval_df[\"Address2\"].tolist(),\n",
    "    \"label\": eval_df[\"Label\"].tolist(),\n",
    "})\n",
    "\n",
    "test_dataset = Dataset.from_dict({\n",
    "    \"sentence1\": test_df[\"Address1\"].tolist(),\n",
    "    \"sentence2\": test_df[\"Address2\"].tolist(),\n",
    "    \"label\": test_df[\"Label\"].tolist(),\n",
    "})\n",
    "\n",
    "print(f\"Training data:   {len(train_df):,}\")\n",
    "print(f\"idation data: {len(eval_df):,}\")\n",
    "print(f\"Test data        {len(eval_df):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680e51e3-84d0-40e5-97d1-ebce61cd9514",
   "metadata": {},
   "source": [
    "### Configure Fine-Tuning, Initialize a `SentenceTransformer`\n",
    "\n",
    "To use the training data we prepared to fine-tune a `SentenceTransformer`, we need to select and load a pre-trained model from Huggingface Hub. Here are some models you can try:\n",
    "\n",
    "* [sentence-transformers/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2](https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2) - multilingual paraphrase models are designed to compare sentences in terms of their semantics.\n",
    "* [BAAI/bge-m3](https://huggingface.co/BAAI/bge-m3) - a robust, multilingual model optimized for a variety of tasks\n",
    "* [sentence-transformers/paraphrase-multilingual-mpnet-base-v2](https://huggingface.co/sentence-transformers/paraphrase-multilingual-mpnet-base-v2) - MPNet is another paraphrase model architecture we can fine-tune for address comparison\n",
    "* [sentence-transformers/all-mpnet-base-v2](https://huggingface.co/sentence-transformers/all-mpnet-base-v2) - a top performing MPNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a2a181-a9cd-469f-9b1b-32b9d3163dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "SBERT_MODEL = \"paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "VARIANT = \"original\"\n",
    "MODEL_SAVE_NAME = (SBERT_MODEL + \"-\" + VARIANT).replace(\"/\", \"-\")\n",
    "\n",
    "# Make sure these match the values in the data augmentation notebook for accurate loggging and reporting\n",
    "CLONES_PER_RUN = 100\n",
    "RUNS_PER_EXAMPLE = 2\n",
    "\n",
    "EPOCHS = 6\n",
    "BATCH_SIZE = 32\n",
    "PATIENCE = 2\n",
    "LEARNING_RATE = .00005\n",
    "DATASET_MULTIPLE = CLONES_PER_RUN * RUNS_PER_EXAMPLE\n",
    "SBERT_OUTPUT_FOLDER = f\"data/fine-tuned-sbert-{MODEL_SAVE_NAME}\"\n",
    "SAVE_EVAL_STEPS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e174e134-4761-4732-a2f7-98a5a785155c",
   "metadata": {},
   "source": [
    "### Initialize Weights & Biases\n",
    "\n",
    "Weights and biases `wandb` package makes it simple to monitor the performance of your training runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68f7a53-d09a-4e8b-b5e9-f62857c12e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Weights & Biases\n",
    "wandb.init(\n",
    "    entity=\"rjurney\",\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"libpostal-reborn\",\n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "        \"variant\": VARIANT,\n",
    "        \"dataset_multiple\": DATASET_MULTIPLE,\n",
    "        \"epochs\": EPOCHS,\n",
    "        \"batch_size\": BATCH_SIZE,\n",
    "        \"patience\": PATIENCE,\n",
    "        \"learning_rate\": LEARNING_RATE,\n",
    "        \"sbert_model\": SBERT_MODEL,\n",
    "        \"model_save_name\": MODEL_SAVE_NAME,\n",
    "        \"sbert_output_folder\": SBERT_OUTPUT_FOLDER,\n",
    "        \"save_eval_steps\": SAVE_EVAL_STEPS,\n",
    "    },\n",
    "    save_code=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0f82a6-1fb7-45fe-b468-9df611413f1e",
   "metadata": {},
   "source": [
    "### Setup our `SentenceTransformer` Model\n",
    "\n",
    "Choose the model to fine-tune above in `SBERT_MODEL` and instantiate it below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e40fb24-77a6-4291-b0c5-076f8a9997d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbert_model = SentenceTransformer(\n",
    "    SBERT_MODEL,\n",
    "    device=device,\n",
    "    model_card_data=SentenceTransformerModelCardData(\n",
    "        language=\"en\",\n",
    "        license=\"apache-2.0\",\n",
    "        model_name=f\"{SBERT_MODEL}-address-matcher-{VARIANT}\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7285812b-dde6-4af0-b0d0-f3ed7c777a51",
   "metadata": {},
   "source": [
    "### Evaluate our Model Before Fine-Tuning\n",
    "\n",
    "Let's see what it can do without fine-tuning, then we'll compare our subjective results afterwards. This won't work very well, fine-tuning is required!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd45043-cac4-47d1-af34-c80fbac09e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sbert_compare(address1: str, address2: str) -> float:\n",
    "    \"\"\"sbert_compare - sentence encode each address into a fixed-length text embedding.\n",
    "    Fixed-length means they can be compared with cosine similarity.\"\"\"\n",
    "    embedding1 = sbert_model.encode(address1)\n",
    "    embedding2 = sbert_model.encode(address2)\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    return 1 - distance.cosine(embedding1, embedding2)\n",
    "\n",
    "\n",
    "def sbert_match(row: pd.Series) -> pd.Series:\n",
    "    \"\"\"sbert_match - SentenceTransformer address matching, float iytoyt\"\"\"\n",
    "    return sbert_compare(row[\"Address1\"], row[\"Address2\"])\n",
    "\n",
    "\n",
    "def sbert_compare_binary(address1: str, address2: str, threshold: float = 0.5) -> Literal[0, 1]:\n",
    "    \"\"\"sbert_match - compare and return a binary match\"\"\"\n",
    "    similarity = sbert_compare(address1, address2)\n",
    "    return 1 if similarity >= threshold else 0\n",
    "\n",
    "\n",
    "def sbert_match_binary(row: pd.Series, threshold: float = 0.5) -> pd.Series:\n",
    "    \"\"\"sbert_match_binary - SentenceTransformer address matching, binary output\"\"\"\n",
    "    return sbert_compare_binary(row[\"Address1\"], row[\"Address2\"], threshold=threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b083ad79-6b50-414f-83de-a3ae68f44c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Still too similar - very hard to train them away from this behavior!\n",
    "sbert_compare(\n",
    "    \"101 Oak Lane, Atlanta, GA 30308\",\n",
    "    \"102 Oak Lane, Atlanta, GA 30308\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65dad9f-3f08-439d-8ee8-2b14b740a55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A little bit further away ...\n",
    "sbert_compare(\n",
    "    \"101 Oak Lane, Atlanta, GA 30308\",\n",
    "    \"101 Oak Ln., Atlanta, GA 30308\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f869c21a-8b41-4520-87bd-7dbc8d37d1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Properly distant ...\n",
    "sbert_compare(\n",
    "    \"3413 Sean Way, Lawrenceville, GA 30044\",\n",
    "    \"1202 Oak Rd., Lawrenceville, GA 30304\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7aba7fb-a560-4869-b05d-414a03a34542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Properly similar ...\n",
    "sbert_compare(\n",
    "    \"3413 Sean Way, Lawrenceville, GA 30044\",\n",
    "    \"3413 Sean Way, Lawrenceville, GA 30044, USA\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a0a9d8-8c06-45dd-9ff4-7b056e078e5a",
   "metadata": {},
   "source": [
    "### Evaluate the Test Set with the Untrained Model\n",
    "\n",
    "Let's see how well the [paraphrase-multilingual-MiniLM-L12-v2](https://huggingface.co/sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2) model does on its own. This is our baseline score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e9a873-9044-443b-9741-3ab3fed0a154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the evaluator\n",
    "binary_acc_evaluator = BinaryClassificationEvaluator(\n",
    "    sentences1=eval_dataset[\"sentence1\"],\n",
    "    sentences2=eval_dataset[\"sentence2\"],\n",
    "    labels=eval_dataset[\"label\"],\n",
    "    name=SBERT_MODEL,\n",
    ")\n",
    "pd.DataFrame([binary_acc_evaluator(sbert_model)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d22615-249a-4ee7-b7c5-43fb1cada980",
   "metadata": {},
   "source": [
    "### Computing Metrics with `sklearn.metrics`\n",
    "\n",
    "We use [scikit-learn metrics](https://scikit-learn.org/stable/modules/model_evaluation.html) instead to compute our evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31111f8e-0167-4a6b-abff-dc3ecf391687",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will rapidly train the embedding model. MultipleNegativesRankingLoss did not work.\n",
    "loss = losses.ContrastiveLoss(model=sbert_model)\n",
    "\n",
    "sbert_args = SentenceTransformerTrainingArguments(\n",
    "    output_dir=SBERT_OUTPUT_FOLDER,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    warmup_ratio=0.1,\n",
    "    run_name=SBERT_MODEL,\n",
    "    load_best_model_at_end=True,\n",
    "    save_total_limit=5,\n",
    "    save_steps=SAVE_EVAL_STEPS,\n",
    "    eval_steps=SAVE_EVAL_STEPS,\n",
    "    save_strategy=\"steps\",\n",
    "    eval_strategy=\"steps\",\n",
    "    greater_is_better=False,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    logging_dir=\"./logs\",\n",
    ")\n",
    "\n",
    "trainer = SentenceTransformerTrainer(\n",
    "    model=sbert_model,\n",
    "    args=sbert_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    loss=loss,\n",
    "    evaluator=binary_acc_evaluator,\n",
    "    compute_metrics=compute_sbert_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=PATIENCE)],\n",
    ")\n",
    "\n",
    "trainer.evaluate()\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fd31d5-005d-4338-973e-663eb7589443",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best model checkpoint path: {trainer.state.best_model_checkpoint}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0340162d-e84f-496b-bc8c-f730d327205f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([trainer.evaluate()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e575f148-b116-4dd3-b9fb-4c99d3027778",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(SBERT_OUTPUT_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f52923-5fc9-4e0c-8e5d-d2cb21d68246",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ad1454-2902-483b-9500-63456cfa5e8d",
   "metadata": {},
   "source": [
    "### Try the Model from Our Best Epoch\n",
    "\n",
    "We fine-tuned the model for `EPOCHS` nubmer of epochs, but the last epoch isn't always best. The `TrainingArgument` `load_best_model_at_end=True` loads the model at the end.\n",
    "\n",
    "Another way to load the best model is to load our output folder and evaluate that `SentenceTransformer` on some examples to get a gestalt sense for its performance.\n",
    "\n",
    "```python\n",
    "sbert_model = SentenceTransformer(OUTPUT_FOLDER, device=device)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f2c9c5-5f70-4f13-8b3a-8e24d8509872",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbert_compare(\n",
    "    \"101 Oak Lane, Atlanta, GA 30308\",\n",
    "    \"102 Oak Lane, Atlanta, GA 30308\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246f35ba-5e5f-4801-a5dd-e0b54bc34d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbert_compare(\n",
    "    \"101 Oak Lane, Macon, GA 30308\",\n",
    "    \"101 Oak Lane, Atlanta, GA 30408\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96ef967-0c99-4301-9c2c-6909360566e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbert_compare(\n",
    "    \"101 Oak Lane, Atlanta, GA 30308\",\n",
    "    \"101 Oak Ln., Atlanta, GA 30308\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76eb3771-17c6-4d85-9bad-8615c1eb8db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sbert_compare(\n",
    "    \"3413 Sean Way, Lawrenceville, GA 30044\",\n",
    "    \"1202 Oak Rd., Lawrenceville, GA 30304\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c78fd25-be01-4052-b717-6471730d92ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbert_compare(\n",
    "    \"3413 Sean Way, Lawrenceville, GA 30044\",\n",
    "    \"3413 Sean Way, Lawrenceville, GA 30044, USA\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441a2b8b-2525-4c7c-98c0-6a65f69661b0",
   "metadata": {},
   "source": [
    "### Evaluate ROC Curve to Determine Optimum Similarity Threshold\n",
    "\n",
    "0.5 is an arbitrary line on which to divide positive (match, 1) and negative (mismatch, 0). Let's evaluate the ROC Curve of the F1 score to see what it should be set to. Recall that the `sbert_match` function has a `threshold: float = 0.5` argument.\n",
    "\n",
    "#### Evaluate on our Augmented Test Dataset\n",
    "\n",
    "First we'll evaluate the ROC curve on our augmented test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53242e2-7ce0-4c00-853f-277ba98b6317",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = test_df[\"Label\"]\n",
    "y_scores = test_df.apply(sbert_match, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fecb6dc8-528b-4680-9794-5da506b02502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute precision-recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_true, y_scores)\n",
    "\n",
    "# Compute F1 score for each threshold\n",
    "f1_scores = [f1_score(y_true, y_scores >= t) for t in thresholds]\n",
    "\n",
    "# Find the threshold that maximizes the F1 score\n",
    "best_threshold_index = np.argmax(f1_scores)\n",
    "best_threshold = thresholds[best_threshold_index]\n",
    "best_f1_score = f1_scores[best_threshold_index]\n",
    "\n",
    "print(f'Best Threshold: {best_threshold}')\n",
    "print(f'Best F1 Score: {best_f1_score}')\n",
    "\n",
    "roc_auc = roc_auc_score(y_true, y_scores)\n",
    "print(f'AUC-ROC: {roc_auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737566a7-4902-468f-b87e-585650d484fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame for Seaborn\n",
    "pr_data = pd.DataFrame({\n",
    "    'Precision': precision[:-1],\n",
    "    'Recall': recall[:-1],\n",
    "    'F1 Score': f1_scores\n",
    "})\n",
    "\n",
    "# Plot Precision-Recall curve using Seaborn\n",
    "sns.lineplot(data=pr_data, x='Recall', y='Precision', marker='o')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Augmented Test Set Precision-Recall Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f50818-d35c-43b9-b022-9746ce96cdc2",
   "metadata": {},
   "source": [
    "### Plot a ROC Curve for our Gold Labeled Data\n",
    "\n",
    "We need to see the ROC Curve for our gold labeled data as well. We care more about performance on this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3eae08-beef-419a-bb8a-ffe74fae4cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = gold_df[\"Label\"]\n",
    "y_scores = gold_df.apply(sbert_match, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bfde9f-9610-4b47-88d6-4432d5081f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute precision-recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_true, y_scores)\n",
    "\n",
    "# Compute F1 score for each threshold\n",
    "f1_scores = [f1_score(y_true, y_scores >= t) for t in thresholds]\n",
    "\n",
    "# Find the threshold that maximizes the F1 score\n",
    "best_threshold_index = np.argmax(f1_scores)\n",
    "best_threshold = thresholds[best_threshold_index]\n",
    "best_f1_score = f1_scores[best_threshold_index]\n",
    "\n",
    "print(f'Best Threshold: {best_threshold}')\n",
    "print(f'Best F1 Score: {best_f1_score}')\n",
    "\n",
    "roc_auc = roc_auc_score(y_true, y_scores)\n",
    "print(f'AUC-ROC: {roc_auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe142c8-8b4b-4384-be50-4e77413fd40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame for Seaborn\n",
    "pr_data = pd.DataFrame({\n",
    "    'Precision': precision[:-1],\n",
    "    'Recall': recall[:-1],\n",
    "    'F1 Score': f1_scores\n",
    "})\n",
    "\n",
    "# Plot Precision-Recall curve using Seaborn\n",
    "sns.lineplot(data=pr_data, x='Recall', y='Precision', marker='o')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Gold Label Precision-Recall Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768d6185-8345-4460-82fc-654fd63cec04",
   "metadata": {},
   "source": [
    "### Debugging Errors on our Gold Labels\n",
    "\n",
    "Let's evaluate the data using our `gold_label_report` function with the best F1 score. Then we can view the errors and figure out where our model is failing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b16f14-ee29-4e2b-acec-61df4bfe8add",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df, grouped_df = gold_label_report(\n",
    "    gold_df,\n",
    "    [\n",
    "        strict_parse_match,\n",
    "        # parse_match_country,\n",
    "        sbert_match_binary,\n",
    "    ],\n",
    "    threshold=best_threshold\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd151a3-f774-45ce-857f-e3d072fc803d",
   "metadata": {},
   "source": [
    "#### Label Description Group Analysis\n",
    "\n",
    "You can see the types of address pairs we are failing on. This can guide our data augmentation / programmatic labeling work at a high level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c954ca92-334d-4d73-98a2-313bbec12c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df.head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edae3d6-4085-41d9-bacb-3efde3d48e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df[\"sbert_match_binary_acc\"].sort_values().head(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4340fd-af40-4450-bfc1-834bac0851cb",
   "metadata": {},
   "source": [
    "#### What it Got Right ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090a985a-a152-4976-8f57-890e88ef99ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Truthiness analysis\n",
    "correct_df = raw_df[raw_df[\"sbert_match_binary_correct\"]].reset_index()\n",
    "print(f\"Number correct: {len(correct_df):,}\")\n",
    "\n",
    "correct_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d228d188-ed22-42ca-985b-ddd9088ac94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error analysis\n",
    "wrong_df = raw_df[raw_df[\"sbert_match_binary_correct\"] == False].reset_index()\n",
    "print(f\"Number wrong: {len(wrong_df):,}\")\n",
    "\n",
    "wrong_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67998e4-9729-4831-993d-aca757f9aa8c",
   "metadata": {},
   "source": [
    "## Structured Address Matching with Libpostal, PyTorch and `Sentence-BERT`\n",
    "\n",
    "Our next strategy will be to parse the addresses using Libpostal and then to encode them in a way that perserves the parsed staructure. Libposstal lowercases the address parts it produces, so we need to train a lowercase `SentenceTransformer` model. We will then load the weights of this pre-trained model as the embedding layers of a deep network architecture called `SentenceBERT` to build a classifier for pairs of addresses that can achieve better performance than fine-tuned sentence transformers and cosine similarity alone."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0715a288-d141-474a-a5f8-f5cbb7e0bd9a",
   "metadata": {},
   "source": [
    "### Fine-Tuning a Lowercase `SentenceTransformer`\n",
    "\n",
    "My first pass at this method did not work whatsoever - the performance of the matcher was abysmal. This was because Libpostal *lowercases* addresses when it parses them, and I did NOT do that to the training data on a first pass :) Once I did that and retrained below - things worked much better!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aeb24d9-ef8c-4f39-a709-8630c749a809",
   "metadata": {},
   "source": [
    "#### Lowercase our Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef2c3ad6-8418-4fdc-98aa-e4187b648020",
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_augment_results_df = augment_results_df.copy(deep=True)\n",
    "\n",
    "lower_augment_results_df[\"Address1\"] = lower_augment_results_df[\"Address1\"].str.lower()\n",
    "lower_augment_results_df[\"Address2\"] = lower_augment_results_df[\"Address2\"].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c4cb876-ea2c-4133-a2ee-f4dbb635b132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data:   8,024\n",
      "Validation data: 1,003\n",
      "Test data        1,003\n"
     ]
    }
   ],
   "source": [
    "train_df, tmp_df = train_test_split(lower_augment_results_df, test_size=0.2, shuffle=True)\n",
    "eval_df, test_df = train_test_split(tmp_df, test_size=0.5, random_state=42, shuffle=True)\n",
    "\n",
    "train_dataset = Dataset.from_dict({\n",
    "    \"sentence1\": train_df[\"Address1\"].tolist(),\n",
    "    \"sentence2\": train_df[\"Address2\"].tolist(),\n",
    "    \"label\": train_df[\"Label\"].tolist(),\n",
    "})\n",
    "\n",
    "eval_dataset = Dataset.from_dict({\n",
    "    \"sentence1\": eval_df[\"Address1\"].tolist(),\n",
    "    \"sentence2\": eval_df[\"Address2\"].tolist(),\n",
    "    \"label\": eval_df[\"Label\"].tolist(),\n",
    "})\n",
    "\n",
    "test_dataset = Dataset.from_dict({\n",
    "    \"sentence1\": test_df[\"Address1\"].tolist(),\n",
    "    \"sentence2\": test_df[\"Address2\"].tolist(),\n",
    "    \"label\": test_df[\"Label\"].tolist(),\n",
    "})\n",
    "\n",
    "print(f\"Training data:   {len(train_df):,}\")\n",
    "print(f\"Validation data: {len(eval_df):,}\")\n",
    "print(f\"Test data        {len(eval_df):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b0af638c-048c-47a1-98bd-bdc670d9f377",
   "metadata": {},
   "outputs": [],
   "source": [
    "SBERT_MODEL_LOWER = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "VARIANT = \"lowercase\"\n",
    "LOWER_MODEL_SAVE_NAME = (SBERT_MODEL_LOWER + \"-\" + VARIANT).replace(\"/\", \"-\")\n",
    "\n",
    "# Make sure these match the values in the data augmentation notebook for accurate loggging and reporting\n",
    "CLONES_PER_RUN = 100\n",
    "RUNS_PER_EXAMPLE = 2\n",
    "\n",
    "EPOCHS = 6\n",
    "BATCH_SIZE = 32\n",
    "PATIENCE = 2\n",
    "LEARNING_RATE = .00005\n",
    "DATASET_MULTIPLE = CLONES_PER_RUN * RUNS_PER_EXAMPLE\n",
    "SBERT_LOWER_OUTPUT_FOLDER = f\"data/fine-tuned-sbert-{LOWER_MODEL_SAVE_NAME}\"\n",
    "SAVE_EVAL_STEPS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "450ff10b-99ce-4853-bcd2-37c17e4eb2f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/rjurney/Software/libpostal-reborn/wandb/run-20240629_224417-qjbx8mrq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rjurney/libpostal-reborn/runs/qjbx8mrq' target=\"_blank\">chocolate-smoke-105</a></strong> to <a href='https://wandb.ai/rjurney/libpostal-reborn' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rjurney/libpostal-reborn' target=\"_blank\">https://wandb.ai/rjurney/libpostal-reborn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rjurney/libpostal-reborn/runs/qjbx8mrq' target=\"_blank\">https://wandb.ai/rjurney/libpostal-reborn/runs/qjbx8mrq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/rjurney/libpostal-reborn/runs/qjbx8mrq?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x11ecfb650>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize Weights & Biases\n",
    "wandb.init(\n",
    "    entity=\"rjurney\",\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"libpostal-reborn\",\n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "        \"variant\": VARIANT,\n",
    "        \"dataset_multiple\": DATASET_MULTIPLE,\n",
    "        \"epochs\": EPOCHS,\n",
    "        \"batch_size\": BATCH_SIZE,\n",
    "        \"patience\": PATIENCE,\n",
    "        \"learning_rate\": LEARNING_RATE,\n",
    "        \"sbert_model\": SBERT_MODEL_LOWER,\n",
    "        \"model_save_name\": LOWER_MODEL_SAVE_NAME,\n",
    "        \"sbert_output_folder\": SBERT_LOWER_OUTPUT_FOLDER,\n",
    "        \"save_eval_steps\": SAVE_EVAL_STEPS,\n",
    "    },\n",
    "    save_code=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "adc7965c-5619-44a2-a07f-9646078db1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbert_model_lower = SentenceTransformer(\n",
    "    SBERT_MODEL_LOWER,\n",
    "    device=device,\n",
    "    model_card_data=SentenceTransformerModelCardData(\n",
    "        language=\"en\",\n",
    "        license=\"apache-2.0\",\n",
    "        model_name=f\"{SBERT_MODEL_LOWER}-address-matcher-{VARIANT}\",\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e05ff3a5-111d-4f1b-bdaa-2fc4c5859346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2_cosine_accuracy</th>\n",
       "      <th>sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2_cosine_accuracy_threshold</th>\n",
       "      <th>sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2_cosine_f1</th>\n",
       "      <th>sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2_cosine_f1_threshold</th>\n",
       "      <th>sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2_cosine_precision</th>\n",
       "      <th>sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2_cosine_recall</th>\n",
       "      <th>sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2_cosine_ap</th>\n",
       "      <th>sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2_dot_accuracy</th>\n",
       "      <th>sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2_dot_accuracy_threshold</th>\n",
       "      <th>sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2_dot_f1</th>\n",
       "      <th>sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2_dot_f1_threshold</th>\n",
       "      <th>sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2_dot_precision</th>\n",
       "      <th>sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2_dot_recall</th>\n",
       "      <th>sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2_dot_ap</th>\n",
       "      <th>sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2_manhattan_accuracy</th>\n",
       "      <th>sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2_manhattan_accuracy_threshold</th>\n",
       "      <th>sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2_manhattan_f1</th>\n",
       "      <th>sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2_manhattan_f1_threshold</th>\n",
       "      <th>sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2_manhattan_precision</th>\n",
       "      <th>sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2_manhattan_recall</th>\n",
       "      <th>sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2_manhattan_ap</th>\n",
       "      <th>sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2_euclidean_accuracy</th>\n",
       "      <th>sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2_euclidean_accuracy_threshold</th>\n",
       "      <th>sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2_euclidean_f1</th>\n",
       "      <th>sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2_euclidean_f1_threshold</th>\n",
       "      <th>sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2_euclidean_precision</th>\n",
       "      <th>sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2_euclidean_recall</th>\n",
       "      <th>sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2_euclidean_ap</th>\n",
       "      <th>sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2_max_accuracy</th>\n",
       "      <th>sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2_max_accuracy_threshold</th>\n",
       "      <th>sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2_max_f1</th>\n",
       "      <th>sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2_max_f1_threshold</th>\n",
       "      <th>sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2_max_precision</th>\n",
       "      <th>sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2_max_recall</th>\n",
       "      <th>sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2_max_ap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.585244</td>\n",
       "      <td>0.686361</td>\n",
       "      <td>0.721595</td>\n",
       "      <td>0.517619</td>\n",
       "      <td>0.566215</td>\n",
       "      <td>0.994505</td>\n",
       "      <td>0.497195</td>\n",
       "      <td>0.568295</td>\n",
       "      <td>7.80843</td>\n",
       "      <td>0.715693</td>\n",
       "      <td>7.517566</td>\n",
       "      <td>0.55783</td>\n",
       "      <td>0.998168</td>\n",
       "      <td>0.609015</td>\n",
       "      <td>0.591226</td>\n",
       "      <td>64.763374</td>\n",
       "      <td>0.726547</td>\n",
       "      <td>70.368423</td>\n",
       "      <td>0.570533</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.488945</td>\n",
       "      <td>0.592223</td>\n",
       "      <td>4.352671</td>\n",
       "      <td>0.726787</td>\n",
       "      <td>4.352671</td>\n",
       "      <td>0.572029</td>\n",
       "      <td>0.996337</td>\n",
       "      <td>0.489592</td>\n",
       "      <td>0.592223</td>\n",
       "      <td>64.763374</td>\n",
       "      <td>0.726787</td>\n",
       "      <td>70.368423</td>\n",
       "      <td>0.572029</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.609015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2_cosine_accuracy  \\\n",
       "0                                           0.585244                             \n",
       "\n",
       "   sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2_cosine_accuracy_threshold  \\\n",
       "0                                           0.686361                                       \n",
       "\n",
       "   sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2_cosine_f1  \\\n",
       "0                                           0.721595                       \n",
       "\n",
       "   sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2_cosine_f1_threshold  \\\n",
       "0                                           0.517619                                 \n",
       "\n",
       "   sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2_cosine_precision  \\\n",
       "0                                           0.566215                              \n",
       "\n",
       "   sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2_cosine_recall  \\\n",
       "0                                           0.994505                           \n",
       "\n",
       "   sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2_cosine_ap  \\\n",
       "0                                           0.497195                       \n",
       "\n",
       "   sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2_dot_accuracy  \\\n",
       "0                                           0.568295                          \n",
       "\n",
       "   sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2_dot_accuracy_threshold  \\\n",
       "0                                            7.80843                                    \n",
       "\n",
       "   sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2_dot_f1  \\\n",
       "0                                           0.715693                    \n",
       "\n",
       "   sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2_dot_f1_threshold  \\\n",
       "0                                           7.517566                              \n",
       "\n",
       "   sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2_dot_precision  \\\n",
       "0                                            0.55783                           \n",
       "\n",
       "   sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2_dot_recall  \\\n",
       "0                                           0.998168                        \n",
       "\n",
       "   sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2_dot_ap  \\\n",
       "0                                           0.609015                    \n",
       "\n",
       "   sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2_manhattan_accuracy  \\\n",
       "0                                           0.591226                                \n",
       "\n",
       "   sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2_manhattan_accuracy_threshold  \\\n",
       "0                                          64.763374                                          \n",
       "\n",
       "   sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2_manhattan_f1  \\\n",
       "0                                           0.726547                          \n",
       "\n",
       "   sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2_manhattan_f1_threshold  \\\n",
       "0                                          70.368423                                    \n",
       "\n",
       "   sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2_manhattan_precision  \\\n",
       "0                                           0.570533                                 \n",
       "\n",
       "   sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2_manhattan_recall  \\\n",
       "0                                                1.0                              \n",
       "\n",
       "   sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2_manhattan_ap  \\\n",
       "0                                           0.488945                          \n",
       "\n",
       "   sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2_euclidean_accuracy  \\\n",
       "0                                           0.592223                                \n",
       "\n",
       "   sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2_euclidean_accuracy_threshold  \\\n",
       "0                                           4.352671                                          \n",
       "\n",
       "   sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2_euclidean_f1  \\\n",
       "0                                           0.726787                          \n",
       "\n",
       "   sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2_euclidean_f1_threshold  \\\n",
       "0                                           4.352671                                    \n",
       "\n",
       "   sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2_euclidean_precision  \\\n",
       "0                                           0.572029                                 \n",
       "\n",
       "   sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2_euclidean_recall  \\\n",
       "0                                           0.996337                              \n",
       "\n",
       "   sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2_euclidean_ap  \\\n",
       "0                                           0.489592                          \n",
       "\n",
       "   sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2_max_accuracy  \\\n",
       "0                                           0.592223                          \n",
       "\n",
       "   sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2_max_accuracy_threshold  \\\n",
       "0                                          64.763374                                    \n",
       "\n",
       "   sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2_max_f1  \\\n",
       "0                                           0.726787                    \n",
       "\n",
       "   sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2_max_f1_threshold  \\\n",
       "0                                          70.368423                              \n",
       "\n",
       "   sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2_max_precision  \\\n",
       "0                                           0.572029                           \n",
       "\n",
       "   sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2_max_recall  \\\n",
       "0                                                1.0                        \n",
       "\n",
       "   sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2_max_ap  \n",
       "0                                           0.609015                   "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the evaluator\n",
    "binary_acc_evaluator = BinaryClassificationEvaluator(\n",
    "    sentences1=eval_dataset[\"sentence1\"],\n",
    "    sentences2=eval_dataset[\"sentence2\"],\n",
    "    labels=eval_dataset[\"label\"],\n",
    "    name=SBERT_MODEL_LOWER,\n",
    ")\n",
    "pd.DataFrame([binary_acc_evaluator(sbert_model_lower)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16800ca1-1f40-40de-9299-f8e88b0ee2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will rapidly train the embedding model. MultipleNegativesRankingLoss did not work.\n",
    "loss = losses.ContrastiveLoss(model=sbert_model_lower)\n",
    "\n",
    "sbert_args = SentenceTransformerTrainingArguments(\n",
    "    output_dir=SBERT_LOWER_OUTPUT_FOLDER,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    warmup_ratio=0.1,\n",
    "    run_name=SBERT_MODEL_LOWER,\n",
    "    load_best_model_at_end=True,\n",
    "    save_steps=SAVE_EVAL_STEPS,\n",
    "    eval_steps=SAVE_EVAL_STEPS,\n",
    "    save_strategy=\"steps\",\n",
    "    eval_strategy=\"steps\",\n",
    "    greater_is_better=False,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    logging_dir=\"./logs\",\n",
    ")\n",
    "\n",
    "trainer = SentenceTransformerTrainer(\n",
    "    model=sbert_model_lower,\n",
    "    args=sbert_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    loss=loss,\n",
    "    evaluator=binary_acc_evaluator,\n",
    "    compute_metrics=compute_sbert_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=PATIENCE)],\n",
    ")\n",
    "\n",
    "trainer.evaluate()\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ce3743-1389-4736-8659-e50e15c5a90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best model checkpoint path: {trainer.state.best_model_checkpoint}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0092c331-3ab7-436b-ac7e-0cf0bfd0406c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([trainer.evaluate()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe81a1d-2171-4915-9e2c-e9a3a88d485f",
   "metadata": {},
   "source": [
    "### Save the Best Model\n",
    "\n",
    "Because we used `load_best_model_at_end=True`, our model is now the best one we fine-tuned. Save it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16310db3-a9f5-48fd-a009-eb743e641bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(SBERT_LOWER_OUTPUT_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d671f99c-eee8-44df-a264-b943ca5e068a",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6739716e-4567-47e7-a49a-87228bc33f3f",
   "metadata": {},
   "source": [
    "### Rewrite our Matchers for Lowercase Duty\n",
    "\n",
    "Need two versions of these to compare the original with their new lowercase cousins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b1761b-001e-4fd8-b61a-7d31686bc9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sbert_compare_lower(address1: str, address2: str) -> float:\n",
    "    \"\"\"sbert_compare - sentence encode each address into a fixed-length text embedding.\n",
    "    Fixed-length means they can be compared with cosine similarity.\"\"\"\n",
    "    embedding1 = sbert_model_lower.encode(address1.lower())\n",
    "    embedding2 = sbert_model_lower.encode(address2.lower())\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    return 1 - distance.cosine(embedding1, embedding2)\n",
    "\n",
    "\n",
    "def sbert_match_lower(row: pd.Series) -> pd.Series:\n",
    "    \"\"\"sbert_match - SentenceTransformer address matching, float iytoyt\"\"\"\n",
    "    return sbert_compare_lower(row[\"Address1\"], row[\"Address2\"])\n",
    "\n",
    "\n",
    "def sbert_compare_binary_lower(address1: str, address2: str, threshold: float = 0.5) -> Literal[0, 1]:\n",
    "    \"\"\"sbert_match - compare and return a binary match\"\"\"\n",
    "    similarity = sbert_compare_lower(address1, address2)\n",
    "    return 1 if similarity >= threshold else 0\n",
    "\n",
    "\n",
    "def sbert_match_binary_lower(row: pd.Series, threshold: float = 0.5) -> pd.Series:\n",
    "    \"\"\"sbert_match_binary - SentenceTransformer address matching, binary output\"\"\"\n",
    "    return sbert_compare_binary_lower(row[\"Address1\"], row[\"Address2\"], threshold=threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94e3805-efb3-4677-97a6-03f469484ac0",
   "metadata": {},
   "source": [
    "### Evaluate ROC Curve to Determine Optimum Similarity Threshold\n",
    "\n",
    "We need to evaluate the ROC Curve of the F1 score to see what it should be set to for our lowercase model too. Recall that the `sbert_match_lower` function has a `threshold: float = 0.5` argument.\n",
    "\n",
    "#### Evaluate on our Augmented Test Dataset\n",
    "\n",
    "First we'll evaluate the ROC curve on our augmented test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245e39c8-4434-4e20-993e-b6dcf4b8bd53",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = test_df[\"Label\"]\n",
    "y_scores = test_df.apply(sbert_match_lower, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044d9937-5c3e-4e9a-aff2-e30aec095d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute precision-recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_true, y_scores)\n",
    "\n",
    "# Compute F1 score for each threshold\n",
    "f1_scores = [f1_score(y_true, y_scores >= t) for t in thresholds]\n",
    "\n",
    "# Find the threshold that maximizes the F1 score\n",
    "best_threshold_index = np.argmax(f1_scores)\n",
    "best_threshold = thresholds[best_threshold_index]\n",
    "best_f1_score = f1_scores[best_threshold_index]\n",
    "\n",
    "print(f'Best Threshold: {best_threshold}')\n",
    "print(f'Best F1 Score: {best_f1_score}')\n",
    "\n",
    "roc_auc = roc_auc_score(y_true, y_scores)\n",
    "print(f'AUC-ROC: {roc_auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3d1d6e-8ca0-4964-aa69-91e2e7ddffc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame for Seaborn\n",
    "pr_data = pd.DataFrame({\n",
    "    'Precision': precision[:-1],\n",
    "    'Recall': recall[:-1],\n",
    "    'F1 Score': f1_scores\n",
    "})\n",
    "\n",
    "# Plot Precision-Recall curve using Seaborn\n",
    "sns.lineplot(data=pr_data, x='Recall', y='Precision', marker='o')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Augmented Test Set Precision-Recall Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3a978d-6193-4968-99b3-65cfbd584c4e",
   "metadata": {},
   "source": [
    "### Plot a ROC Curve for our Gold Labeled Data\n",
    "\n",
    "We need to see the ROC Curve for our gold labeled data as well. We care more about performance on this data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb225e7-ad73-4236-b4ea-49fbb1da3bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = gold_df[\"Label\"]\n",
    "y_scores = gold_df.apply(sbert_match_lower, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d2c166-d6c2-481c-b573-f1c5ca6fd41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute precision-recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_true, y_scores)\n",
    "\n",
    "# Compute F1 score for each threshold\n",
    "f1_scores = [f1_score(y_true, y_scores >= t) for t in thresholds]\n",
    "\n",
    "# Find the threshold that maximizes the F1 score\n",
    "best_threshold_index = np.argmax(f1_scores)\n",
    "best_threshold = thresholds[best_threshold_index]\n",
    "best_f1_score = f1_scores[best_threshold_index]\n",
    "\n",
    "print(f'Best Threshold: {best_threshold}')\n",
    "print(f'Best F1 Score: {best_f1_score}')\n",
    "\n",
    "roc_auc = roc_auc_score(y_true, y_scores)\n",
    "print(f'AUC-ROC: {roc_auc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50070e2-5c1e-4367-b5be-d1145d87e97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame for Seaborn\n",
    "pr_data = pd.DataFrame({\n",
    "    'Precision': precision[:-1],\n",
    "    'Recall': recall[:-1],\n",
    "    'F1 Score': f1_scores\n",
    "})\n",
    "\n",
    "# Plot Precision-Recall curve using Seaborn\n",
    "sns.lineplot(data=pr_data, x='Recall', y='Precision', marker='o')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Gold Label Precision-Recall Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4958d260-90a9-417d-b200-df73e1869760",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbert_compare_lower(\n",
    "    \"nw 5th ave\",\n",
    "    \"northwest 5th avenue\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31be0a9-8281-4ed4-92e3-753a8f040ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbert_compare_lower(\n",
    "    \"101 market square, seattle, wa 98039\",\n",
    "    \"101 davis ct., seattle, wa 98039\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0388ebba-f964-41ce-ab37-c9c295a45806",
   "metadata": {},
   "source": [
    "## Structured Prediction with a `Sentence-BERT` Classifier\n",
    "\n",
    "Embeddings as a solution to this problem have a side-effect of optimizing an embedding for information retrieval... but they ignore the structure of parsed addresses. A deep network that is aware of it can perform better. Let's try out an implementation of the Sentence-BERT model, which was outlined by Nils Reimers and Iryna Gurevych in the original paper that created sentence tranformers, [Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks\n",
    "](https://arxiv.org/abs/1908.10084)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "02a8f5bc-c48d-4fe0-8bb6-91dac3db3609",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "from collections import defaultdict\n",
    "\n",
    "def create_standardized_address(address: str) -> str:\n",
    "\n",
    "    # Libpostal parse the address\n",
    "    parsed_address: List[Tuple[str, str]] = parse_address(address)\n",
    "    \n",
    "    FIELD_ORDER = [\n",
    "        \"house_number\",\n",
    "        \"house\",\n",
    "        \"road\",\n",
    "        \"unit\",\n",
    "        \"level\",\n",
    "        \"staircase\",\n",
    "        \"entrance\",\n",
    "        \"category\",\n",
    "        \"near\",\n",
    "        \"suburb\",\n",
    "        \"city_district\",\n",
    "        \"city\",\n",
    "        \"island\",\n",
    "        \"state_district\",\n",
    "        \"state\",\n",
    "        \"postcode\",\n",
    "        \"po_box\",\n",
    "        \"country_region\",\n",
    "        \"country\",\n",
    "        \"world_region\"\n",
    "    ]\n",
    "    \n",
    "    # Fields that typically precede a comma in addresses\n",
    "    COMMA_AFTER = {\"road\", \"city\", \"state\", \"country_region\"}\n",
    "    \n",
    "    # Create a defaultdict to group values by field\n",
    "    address_dict = defaultdict(list)\n",
    "    for value, field in parsed_address:\n",
    "        if value.strip():\n",
    "            address_dict[field].append(value.strip())\n",
    "    \n",
    "    # Create a list of non-empty address components in the specified order\n",
    "    address_components = []\n",
    "    for field in FIELD_ORDER:\n",
    "        if field in address_dict:\n",
    "            component = ' '.join(address_dict[field])\n",
    "            if field in COMMA_AFTER and field != FIELD_ORDER[-1]:\n",
    "                component += ','\n",
    "            address_components.append(component)\n",
    "    \n",
    "    # Join the components with a space\n",
    "    return ' '.join(address_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "75976b16-ca9d-4005-9a51-e76a975f876e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data:   8,024\n",
      "Validation data: 1,003\n",
      "Test data        1,003\n"
     ]
    }
   ],
   "source": [
    "train_df, tmp_df = train_test_split(augment_results_df, test_size=0.2, shuffle=True)\n",
    "eval_df, test_df = train_test_split(tmp_df, test_size=0.5, random_state=42, shuffle=True)\n",
    "\n",
    "# Encode the addresses using [COL] / [VAL] special characters\n",
    "train_dataset = Dataset.from_dict({\n",
    "    \"sentence1\": [create_standardized_address(x) for x in train_df[\"Address1\"].tolist()],\n",
    "    \"sentence2\": [create_standardized_address(x) for x in train_df[\"Address2\"].tolist()],\n",
    "    \"label\": train_df[\"Label\"].tolist(),\n",
    "})\n",
    "\n",
    "# Encode the addresses using [COL] / [VAL] special characters\n",
    "# train_dataset = Dataset.from_dict({\n",
    "#     \"sentence1\": train_df[\"Address1\"].tolist(),\n",
    "#     \"sentence2\": train_df[\"Address2\"].tolist(),\n",
    "#     \"label\": train_df[\"Label\"].tolist(),\n",
    "# })\n",
    "\n",
    "# Encode the addresses using [COL] / [VAL] special characters\n",
    "eval_dataset = Dataset.from_dict({\n",
    "    \"sentence1\": [create_standardized_address(x) for x in eval_df[\"Address1\"].tolist()],\n",
    "    \"sentence2\": [create_standardized_address(x) for x in eval_df[\"Address2\"].tolist()],\n",
    "    \"label\": eval_df[\"Label\"].tolist(),\n",
    "})\n",
    "# eval_dataset = Dataset.from_dict({\n",
    "#     \"sentence1\": eval_df[\"Address1\"].tolist(),\n",
    "#     \"sentence2\": eval_df[\"Address2\"].tolist(),\n",
    "#     \"label\": eval_df[\"Label\"].tolist(),\n",
    "# })\n",
    "\n",
    "# Encode the addresses using [COL] / [VAL] special characters\n",
    "test_dataset = Dataset.from_dict({\n",
    "    \"sentence1\": [create_standardized_address(x) for x in test_df[\"Address1\"].tolist()],\n",
    "    \"sentence2\": [create_standardized_address(x) for x in test_df[\"Address2\"].tolist()],\n",
    "    \"label\": test_df[\"Label\"].tolist(),\n",
    "})\n",
    "# test_dataset = Dataset.from_dict({\n",
    "#     \"sentence1\": test_df[\"Address1\"].tolist(),\n",
    "#     \"sentence2\": test_df[\"Address2\"].tolist(),\n",
    "#     \"label\": test_df[\"Label\"].tolist(),\n",
    "# })\n",
    "\n",
    "print(f\"Training data:   {len(train_df):,}\")\n",
    "print(f\"Validation data: {len(eval_df):,}\")\n",
    "print(f\"Test data        {len(eval_df):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "cc6f9841-6248-4e06-81b7-c5761fde354e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SBERT_INPUT_MODEL = SBERT_LOWER_OUTPUT_FOLDER\n",
    "VARIANT = \"raw-embeddings\"\n",
    "MODEL_SAVE_NAME = (\"Cosine-Sentence-BERT\" + \"-\" + VARIANT).replace(\"/\", \"-\")\n",
    "\n",
    "EPOCHS = 15\n",
    "BATCH_SIZE = 32\n",
    "PATIENCE = 2\n",
    "LEARNING_RATE = 8e-5\n",
    "MODEL_OUTPUT_FOLDER = f\"data/{MODEL_SAVE_NAME}\"\n",
    "SAVE_EVAL_STEPS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1dfb214a-2cbb-48d2-9e42-307aab992516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/rjurney/Software/libpostal-reborn/wandb/run-20240630_114347-q05f6mrn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rjurney/libpostal-reborn/runs/q05f6mrn' target=\"_blank\">colorful-eon-111</a></strong> to <a href='https://wandb.ai/rjurney/libpostal-reborn' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rjurney/libpostal-reborn' target=\"_blank\">https://wandb.ai/rjurney/libpostal-reborn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rjurney/libpostal-reborn/runs/q05f6mrn' target=\"_blank\">https://wandb.ai/rjurney/libpostal-reborn/runs/q05f6mrn</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/rjurney/libpostal-reborn/runs/q05f6mrn?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0xf8a0fc210>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize Weights & Biases\n",
    "wandb.init(\n",
    "    entity=\"rjurney\",\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"libpostal-reborn\",\n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "        \"model\": \"Cosine-Sentence-BERT\",\n",
    "        \"variant\": VARIANT,\n",
    "        \"epochs\": EPOCHS,\n",
    "        \"batch_size\": BATCH_SIZE,\n",
    "        \"patience\": PATIENCE,\n",
    "        \"learning_rate\": LEARNING_RATE,\n",
    "        \"sbert_input_model\": SBERT_INPUT_MODEL,\n",
    "        \"model_output_folder\": MODEL_OUTPUT_FOLDER,\n",
    "        \"save_eval_steps\": SAVE_EVAL_STEPS,\n",
    "        \"model_save_name\": MODEL_SAVE_NAME,\n",
    "    },\n",
    "    save_code=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2b7740e6-4a1b-4d5e-99bc-4eeb9d3f21c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "class CosineSentenceBERT(nn.Module):\n",
    "    def __init__(self, model_name=SBERT_MODEL_LOWER, dim=384):\n",
    "        super().__init__()\n",
    "        self.model_name = model_name\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "        # Update the FFNN to output embedding dimension\n",
    "        self.ffnn = nn.Sequential(\n",
    "            nn.Linear(dim, dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(0.1),\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def mean_pool(token_embeds, attention_mask):\n",
    "        in_mask = attention_mask.unsqueeze(-1).expand(token_embeds.size()).float()\n",
    "        pool = torch.sum(token_embeds * in_mask, 1) / torch.clamp(in_mask.sum(1), min=1e-9)\n",
    "        return pool\n",
    "\n",
    "    def encode(self, input_ids, attention_mask):\n",
    "        outputs = self.model(input_ids, attention_mask=attention_mask)[0]\n",
    "        embeddings = self.mean_pool(outputs, attention_mask)\n",
    "        return self.ffnn(embeddings)\n",
    "\n",
    "    def forward(self, input_ids_a, input_ids_b, attention_mask_a=None, attention_mask_b=None, labels=None):\n",
    "        # Encode both sentences\n",
    "        embed_a = self.encode(input_ids_a, attention_mask_a)\n",
    "        embed_b = self.encode(input_ids_b, attention_mask_b)\n",
    "\n",
    "        # Compute cosine similarity\n",
    "        cosine_sim = F.cosine_similarity(embed_a, embed_b)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.CosineEmbeddingLoss()\n",
    "            # CosineEmbeddingLoss expects 1 for similar pairs and -1 for dissimilar pairs\n",
    "            loss = loss_fct(embed_a, embed_b, (labels * 2) - 1)\n",
    "\n",
    "        return {\"loss\": loss, \"similarity\": cosine_sim}\n",
    "\n",
    "    def predict(self, a: str, b: str):\n",
    "        encoded_a = self.tokenizer(a, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "        encoded_b = self.tokenizer(b, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            embed_a = self.encode(encoded_a[\"input_ids\"].to(self.model.device), \n",
    "                                  encoded_a[\"attention_mask\"].to(self.model.device))\n",
    "            embed_b = self.encode(encoded_b[\"input_ids\"].to(self.model.device), \n",
    "                                  encoded_b[\"attention_mask\"].to(self.model.device))\n",
    "            \n",
    "            similarity = F.cosine_similarity(embed_a, embed_b).item()\n",
    "            \n",
    "            return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4d77c9e7-cee9-4821-8e2c-f7b30a3f0c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_model = CosineSentenceBERT()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "238b0455-144a-4924-bffa-d4a01f6fe99d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37871e1ed40d4b17898a3021f9a4e64d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8024 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d5908bab20d41fca6ac48f16837b79f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1003 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4512b2c36ce247beb9a8f42bb352ca82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1003 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_train_dataset = train_dataset.map(lambda x: tokenize_function(x, classifier_model), batched=True)\n",
    "tokenized_eval_dataset = eval_dataset.map(lambda x: tokenize_function(x, classifier_model), batched=True)\n",
    "tokenized_test_dataset = test_dataset.map(lambda x: tokenize_function(x, classifier_model), batched=True)\n",
    "\n",
    "tokenized_train_dataset = format_dataset(tokenized_train_dataset)\n",
    "tokenized_eval_dataset = format_dataset(tokenized_eval_dataset)\n",
    "tokenized_test_dataset = format_dataset(tokenized_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171c0469-a059-4932-8b03-52cd94d8cd93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rjurney/anaconda3/envs/libpostal/lib/python3.11/site-packages/transformers/training_args.py:2101: UserWarning: `use_mps_device` is deprecated and will be removed in version 5.0 of  Transformers. `mps` device will be used by default if available similar to the way `cuda` device is used.Therefore, no action from user is required. \n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='929' max='3765' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 929/3765 37:17 < 1:54:06, 0.41 it/s, Epoch 3.70/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.408661</td>\n",
       "      <td>0.610169</td>\n",
       "      <td>0.721708</td>\n",
       "      <td>0.565848</td>\n",
       "      <td>0.996071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.359284</td>\n",
       "      <td>0.649053</td>\n",
       "      <td>0.738484</td>\n",
       "      <td>0.593787</td>\n",
       "      <td>0.976424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.309300</td>\n",
       "      <td>0.701894</td>\n",
       "      <td>0.770881</td>\n",
       "      <td>0.631910</td>\n",
       "      <td>0.988212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.271002</td>\n",
       "      <td>0.746760</td>\n",
       "      <td>0.798732</td>\n",
       "      <td>0.669323</td>\n",
       "      <td>0.990177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.346500</td>\n",
       "      <td>0.250848</td>\n",
       "      <td>0.765703</td>\n",
       "      <td>0.807219</td>\n",
       "      <td>0.692958</td>\n",
       "      <td>0.966601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.346500</td>\n",
       "      <td>0.235971</td>\n",
       "      <td>0.785643</td>\n",
       "      <td>0.822754</td>\n",
       "      <td>0.708807</td>\n",
       "      <td>0.980354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.346500</td>\n",
       "      <td>0.214602</td>\n",
       "      <td>0.807577</td>\n",
       "      <td>0.837405</td>\n",
       "      <td>0.733038</td>\n",
       "      <td>0.976424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.346500</td>\n",
       "      <td>0.215412</td>\n",
       "      <td>0.804586</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.734633</td>\n",
       "      <td>0.962672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.346500</td>\n",
       "      <td>0.183409</td>\n",
       "      <td>0.824526</td>\n",
       "      <td>0.849829</td>\n",
       "      <td>0.751131</td>\n",
       "      <td>0.978389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "\n",
    "class CosineSimilarityTrainer(Trainer):\n",
    "    \"\"\"Trainer for Cosine-Sentence-BERT\"\"\"\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        outputs = model(**inputs)\n",
    "        loss = outputs[\"loss\"]\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=MODEL_OUTPUT_FOLDER,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    num_train_epochs=EPOCHS,\n",
    "    per_device_train_batch_size=BATCH_SIZE,\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    # warmup_ratio=0.1,\n",
    "    run_name=MODEL_SAVE_NAME,\n",
    "    load_best_model_at_end=True,\n",
    "    save_steps=SAVE_EVAL_STEPS,\n",
    "    eval_steps=SAVE_EVAL_STEPS,\n",
    "    save_strategy=\"steps\",\n",
    "    eval_strategy=\"steps\",\n",
    "    greater_is_better=False,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    optim=\"adamw_torch\",\n",
    "    use_mps_device=True,\n",
    ")\n",
    "\n",
    "optimizer = RAdam(classifier_model.parameters(), lr=training_args.learning_rate)\n",
    "\n",
    "trainer = CosineSimilarityTrainer(\n",
    "    model=classifier_model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_eval_dataset,\n",
    "    compute_metrics=compute_classifier_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=PATIENCE)],\n",
    "    optimizers=(optimizer, None),\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ce2275-6f76-4454-863a-1a3b8adcd829",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Best model checkpoint path: {trainer.state.best_model_checkpoint}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693e3cc0-8844-43af-a738-cc25f7778ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "pd.DataFrame([trainer.evaluate()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a393084f-aa67-48ad-ad08-93aaea71fb3b",
   "metadata": {},
   "source": [
    "### Save the Best Model\n",
    "\n",
    "Because we used `load_best_model_at_end=True`, our model is now the best one we fine-tuned. Save it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70abb3b9-a9e3-4280-a659-728aeec6c52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.save_model(MODEL_OUTPUT_FOLDER)\n",
    "save_custom_model(classifier_model, \"data/classifier_model_for_tanmoy.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22cd20c-61be-47c4-9eba-eac14a1cc23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abab52e-f77c-4fe9-8c99-9bc8d77adcb9",
   "metadata": {},
   "source": [
    "### Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8112c70-6bbe-4ee1-bc0f-cacc51aa472c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier_model = load_custom_model(CosineSentenceBERT, \"data/classifier_model_for_tanmoy.pt\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b6b68f-c85f-4753-ace8-0a74e3471d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_model.predict(\"3413 Sean Way, Lawrenceville, GA 30044\", \"3413 Sean Way, Lawrenceville, GA 30044\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387a0065-5412-48e3-b5cb-d146aa4cd528",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_model.predict(\"101 Oak Ct.,\", \"101 Oak Street\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4265009-bf3e-467c-84fd-27d202cf5c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_model.predict(\"101 Oak Pl.\", \"101 Oak Place\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3d4025-ec9b-45cd-a3fd-b764ab1b9920",
   "metadata": {},
   "source": [
    "### Probability and Boolean Prediction Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808a4f57-c875-4ec2-9bf1-4fc2a1971afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_match(row: pd.Series) -> pd.Series:\n",
    "    \"\"\"classifier_match - Sentence-BERT address matching, float output\"\"\"\n",
    "    return classifier_model.predict(row[\"Address1\"], row[\"Address2\"])\n",
    "\n",
    "\n",
    "def classifier_match_boolean(row: pd.Series, threshold=0.5) -> pd.Series:\n",
    "    \"\"\"classifier_match_binary - Sentence-BERT address matching, boolean output\"\"\"\n",
    "    return 1 if classifier_model.predict(row[\"Address1\"], row[\"Address2\"]) > threshold else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5f79c9-a93e-4d5c-ae1f-bc819e89847a",
   "metadata": {},
   "source": [
    "### Synthetic Data Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6d6951-b186-40f0-913b-2e209b376439",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = test_df[\"Label\"]\n",
    "y_scores = test_df.apply(classifier_match, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d13decc-0983-4dac-936e-1c38c9e4eadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute precision-recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_true, y_scores)\n",
    "\n",
    "# Compute F1 score for each threshold\n",
    "f1_scores = [f1_score(y_true, y_scores >= t) for t in thresholds]\n",
    "\n",
    "# Find the threshold that maximizes the F1 score\n",
    "best_threshold_index = np.argmax(f1_scores)\n",
    "best_threshold = thresholds[best_threshold_index]\n",
    "best_f1_score = f1_scores[best_threshold_index]\n",
    "\n",
    "print(f'Best Threshold: {best_threshold}')\n",
    "print(f'Best F1 Score: {best_f1_score}')\n",
    "\n",
    "roc_auc = roc_auc_score(y_true, y_scores)\n",
    "print(f'AUC-ROC: {roc_auc}')\n",
    "\n",
    "# Create a DataFrame for Seaborn\n",
    "pr_data = pd.DataFrame({\n",
    "    'Precision': precision[:-1],\n",
    "    'Recall': recall[:-1],\n",
    "    'F1 Score': f1_scores\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b571184-2b27-4a40-9969-02fec11c4e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Precision-Recall curve using Seaborn\n",
    "sns.lineplot(data=pr_data, x='Recall', y='Precision', marker='o')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Augmented Test Set Precision-Recall Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f55d107-561c-4bf7-afe4-f78172c16ae2",
   "metadata": {},
   "source": [
    "### Gold Label Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b262d8-346d-4d14-8947-7c3f61302c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = gold_df[\"Label\"]\n",
    "y_scores = gold_df.apply(classifier_match, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af49aa98-4a18-4389-bf00-ee6d10948dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute precision-recall curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_true, y_scores)\n",
    "\n",
    "# Compute F1 score for each threshold\n",
    "f1_scores = [f1_score(y_true, y_scores >= t) for t in thresholds]\n",
    "\n",
    "# Find the threshold that maximizes the F1 score\n",
    "best_threshold_index = np.argmax(f1_scores)\n",
    "best_threshold = thresholds[best_threshold_index]\n",
    "best_f1_score = f1_scores[best_threshold_index]\n",
    "\n",
    "print(f'Best Threshold: {best_threshold}')\n",
    "print(f'Best F1 Score: {best_f1_score}')\n",
    "\n",
    "roc_auc = roc_auc_score(y_true, y_scores)\n",
    "print(f'AUC-ROC: {roc_auc}')\n",
    "\n",
    "# Create a DataFrame for Seaborn\n",
    "pr_data = pd.DataFrame({\n",
    "    'Precision': precision[:-1],\n",
    "    'Recall': recall[:-1],\n",
    "    'F1 Score': f1_scores\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b672998-93d9-4091-959d-203002de9a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Precision-Recall curve using Seaborn\n",
    "sns.lineplot(data=pr_data, x='Recall', y='Precision', marker='o')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Gold Label Precision-Recall Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e135a0db-3cdb-4d1e-a0ce-9ccf97ca2b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df, grouped_df = gold_label_report(\n",
    "    gold_df,\n",
    "    [\n",
    "        # sbert_match_binary,\n",
    "        classifier_match_boolean,\n",
    "    ],\n",
    "    threshold=best_threshold\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087f4277-693a-44d1-b7b2-81895d7b4100",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cde90e-b2db-401a-8a7b-0dd3e24edb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Truthiness analysis\n",
    "correct_df = raw_df[raw_df[\"classifier_match_boolean_correct\"]].reset_index(drop=True)\n",
    "print(f\"Number correct: {len(correct_df):,}\")\n",
    "\n",
    "correct_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ed830e-88ff-4c92-addb-ea73f60a5edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error analysis\n",
    "wrong_df = raw_df[raw_df[\"classifier_match_boolean_correct\"] == False].reset_index()\n",
    "print(f\"Number wrong: {len(wrong_df):,}\")\n",
    "\n",
    "wrong_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54205060-4522-4bea-840a-fc0aede13d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_model.predict(\n",
    "    \"101 Oak Lane, Atlanta, GA 30308\",\n",
    "    \"102 Oak Lane, Atlanta, GA 30308\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37beb453-3084-4e3f-b635-c4f9882f12e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_model.predict(\n",
    "    \"101 Oak Lane, Macon, GA 30308\",\n",
    "    \"101 Oak Lane, Atlanta, GA 30408\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29452c9c-abb1-49b7-819e-b0a42ede9440",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_model.predict(\n",
    "    \"101 Oak Lane, Atlanta, GA 30308\",\n",
    "    \"101 Oak Ln., Atlanta, GA 30308\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d97d1c0-4e93-47a2-b52d-7c5be5ce555d",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_model.predict(\n",
    "    \"3413 Sean Way, Lawrenceville, GA 30044\",\n",
    "    \"1202 Oak Rd., Lawrenceville, GA 30304\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4972bc19-ba6b-4e0b-80cc-80baf013ce49",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_model.predict(\n",
    "    \"3413 Sean Way, Lawrenceville, GA 30044\",\n",
    "    \"3413 Sean Way, Lawrenceville, GA 30044, USA\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3a3f91-9a58-4a7b-986c-9d27d23dd98a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
